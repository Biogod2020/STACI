{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e8e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xinyiz/pamrats')\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import average_precision_score\n",
    "import image.loadImage as loadImage\n",
    "\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN,MiniBatchKMeans,AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e86612b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "ifplot=True\n",
    "ifcluster=True\n",
    "byCT=True\n",
    "\n",
    "logitL1=0.5 #smaller is sparser\n",
    "geneThresh=2.5 #times std above mean\n",
    "\n",
    "inverseAct=None\n",
    "# inverseAct=None\n",
    "plottype='umap'\n",
    "pca=PCA()\n",
    "minCells=15 #min number of cells for analysis\n",
    "minCell_clusterDE=5\n",
    "# clustermethod=['leiden']\n",
    "clustermethod=['leiden','agglomerative','kmeanbatch']\n",
    "#umap/leiden clustering parameters\n",
    "n_neighbors=10\n",
    "min_dist=0.25\n",
    "n_pcs=40 #for clustering\n",
    "# resolution=[0.5,0.8,1,1.5]\n",
    "resolution=[0.05,0.1,0.2,0.3,0.5,0.8,1,1.5]\n",
    "plotepoch=140\n",
    "savenameAdd=''\n",
    "#DBscan\n",
    "epslist= [6,8,10]\n",
    "min_sampleslist=[15,30,45] \n",
    "#agglomerative\n",
    "nclusterlist=[2,3,4,5,8,10,15]\n",
    "aggMetric=['euclidean']\n",
    "\n",
    "\n",
    "combineCelltype={'glia':['Astro','Micro', 'OPC', 'Oligo'],'CA':['CA1', 'CA2', 'CA3']}\n",
    "\n",
    "use_cuda=True\n",
    "fastmode=False #Validate during training pass\n",
    "seed=3\n",
    "\n",
    "protein=None #'scaled_binary'\n",
    "# proteinWeights=0.05\n",
    "# randFeatureSubset=None\n",
    "plot_samples={'disease13':'AD_mouse9494','control13':'AD_mouse9498','disease8':'AD_mouse9723','control8':'AD_mouse9735'}\n",
    "plot_sample_X=['logminmax']\n",
    "plotRecon='' #'meanRecon'\n",
    "diamThresh_mul=512\n",
    "minThresh_mul=6\n",
    "name='all_thresh12min6_02'\n",
    "logsavepath='/mnt/external_ssd/xinyi/log/train_cnn_starmap/'+name\n",
    "modelsavepath='/mnt/external_ssd/xinyi/models/train_cnn_starmap/'+name\n",
    "plotsavepath='/mnt/external_ssd/xinyi/plots/train_cnn_starmap/'+name\n",
    "datadir='/home/xinyiz/2021-01-13-mAD-test-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1261fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cuda and seed\n",
    "np.random.seed(seed)\n",
    "if use_cuda and (not torch.cuda.is_available()):\n",
    "    print('cuda not available')\n",
    "    use_cuda=False\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbc6281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "imageslist={}\n",
    "for s in plot_samples.keys():\n",
    "    imageslist[s]=loadImage.loadandsplit(plot_samples[s],datadir,diamThresh_mul,0,0,ifFlip=True,minCutoff=minThresh_mul,seed=seed,split=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4832e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleCluster(labels,imginput,nsample,savepath,savenamecluster,addname=''):\n",
    "    imgsavepath=os.path.join(savepath,savenamecluster+'example')\n",
    "    if not os.path.exists(imgsavepath):\n",
    "        os.mkdir(imgsavepath)\n",
    "    np.random.seed(3)\n",
    "    for l in np.unique(labels):\n",
    "        clusteridx=(labels==l)\n",
    "        idx=np.random.choice(np.sum(clusteridx),nsample,False)\n",
    "        for i in idx:\n",
    "#             print(np.arange(imginput.shape[0])[clusteridx][idx])\n",
    "            imgplot=imginput[np.arange(imginput.shape[0])[clusteridx][i]][0]\n",
    "#             imgplot=imgplot.reshape((416,416))\n",
    "            plt.imsave(os.path.join(imgsavepath,'cluster'+str(l)+'_'+str(i)+'.jpg'),imgplot)\n",
    "\n",
    "def sampleLeiden(imginput,nsample,n_neighbors,n_pcs,min_dist,resolution,addName=''):\n",
    "    for r in resolution:\n",
    "        savenamecluster='leiden_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'n_pcs'+str(n_pcs)+'res'+str(r)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        labels=np.array(labels)\n",
    "        if np.unique(labels).shape[0]==1:\n",
    "            continue\n",
    "        \n",
    "        savepath=clustersavedir\n",
    "        sampleCluster(labels,imginput,nsample,savepath,savenamecluster,addName)\n",
    "\n",
    "def sampleAgg(imginput,nsample,nclusterL,aggmetricL,n_pcs,addName=''):\n",
    "    for ncluster in nclusterL:\n",
    "        for aggmetric in aggmetricL:\n",
    "            savenamecluster='agg_ncluster'+str(ncluster)+aggmetric+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "            if not os.path.exists(readpath):\n",
    "                print('DNE: '+readpath)\n",
    "                continue\n",
    "            with open(readpath, 'rb') as input:\n",
    "                labels = pickle.load(input)\n",
    "            labels=np.array(labels)\n",
    "            if np.unique(labels).shape[0]==1:\n",
    "                continue\n",
    "            savepath=clustersavedir\n",
    "            sampleCluster(labels,imginput,nsample,savepath,savenamecluster,addName)\n",
    "            \n",
    "        \n",
    "def sampleMinibatchKmean(imginput,nsample,nclusterL,n_pcs,addName=''):\n",
    "    for ncluster in nclusterL:\n",
    "        savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        labels=np.array(labels)\n",
    "        if np.unique(labels).shape[0]==1:\n",
    "            continue\n",
    "            \n",
    "        savepath=clustersavedir\n",
    "        sampleCluster(labels,imginput,nsample,savepath,savenamecluster,addName)\n",
    "        \n",
    "        \n",
    "def plotCTcomp(labels,ctlist,savepath,savenamecluster,addname=''):\n",
    "    res=np.zeros((np.unique(labels).size,np.unique(ctlist).size))\n",
    "    for li in range(res.shape[0]):\n",
    "        l=np.unique(labels)[li]\n",
    "        nl=np.sum(labels==l)\n",
    "        ctlist_l=ctlist[labels==l]\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=np.unique(ctlist)[ci]\n",
    "            res[li,ci]=np.sum(ctlist_l==c)\n",
    "#             res[li,ci]=np.sum(ctlist_l==c)/nl\n",
    "    if not byCT:\n",
    "        addname+=''\n",
    "        for li in range(res.shape[0]):\n",
    "            l=np.unique(labels)[li]\n",
    "            nl=np.sum(labels==l)\n",
    "            res[li]=res[li]/nl\n",
    "    else:\n",
    "        addname+='_normbyCT'\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=np.unique(ctlist)[ci]\n",
    "            nc=np.sum(ctlist==c)\n",
    "            res[:,ci]=res[:,ci]/nc\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(res,cmap='binary')\n",
    "    ax.set_yticks(np.arange(np.unique(labels).size))\n",
    "    ax.set_yticklabels(np.unique(labels))\n",
    "    ax.set_xticks(np.arange(np.unique(ctlist).size))\n",
    "    ax.set_xticklabels(np.unique(ctlist))\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(savepath,savenamecluster+'_ctComposition'+addname+'.jpg'))\n",
    "    plt.close()\n",
    "        \n",
    "        \n",
    "\n",
    "def compLeiden(ctlist,n_neighbors,n_pcs,min_dist,resolution,addName=''):\n",
    "    for r in resolution:\n",
    "        savenamecluster='leiden_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'n_pcs'+str(n_pcs)+'res'+str(r)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        labels=np.array(labels)\n",
    "        if np.unique(labels).shape[0]==1:\n",
    "            continue\n",
    "        \n",
    "        savepath=clustersavedir\n",
    "        plotCTcomp(labels,ctlist,savepath,savenamecluster,addName)\n",
    "\n",
    "def compDBscan(ctlist,epsL,min_samplesL,n_pcs,addName=''):\n",
    "    for eps in epsL:\n",
    "        for min_samples in min_samplesL:\n",
    "            savenamecluster='dbscan_eps'+str(eps)+'msamples'+str(min_samples)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "            if not os.path.exists(readpath):\n",
    "                print('DNE: '+readpath)\n",
    "                continue\n",
    "            with open(readpath, 'rb') as input:\n",
    "                labels = pickle.load(input)\n",
    "            labels=np.array(labels)\n",
    "            if np.unique(labels).shape[0]==1:\n",
    "                continue\n",
    "            \n",
    "            savepath=clustersavedir\n",
    "            plotCTcomp(labels,ctlist,savepath,savenamecluster,addName)\n",
    "                \n",
    "def compAgg(ctlist,nclusterL,aggmetricL,n_pcs,addName=''):\n",
    "    for ncluster in nclusterL:\n",
    "        for aggmetric in aggmetricL:\n",
    "            savenamecluster='agg_ncluster'+str(ncluster)+aggmetric+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "            if not os.path.exists(readpath):\n",
    "                print('DNE: '+readpath)\n",
    "                continue\n",
    "            with open(readpath, 'rb') as input:\n",
    "                labels = pickle.load(input)\n",
    "            labels=np.array(labels)\n",
    "            if np.unique(labels).shape[0]==1:\n",
    "                continue\n",
    "            savepath=clustersavedir\n",
    "            plotCTcomp(labels,ctlist,savepath,savenamecluster,addName)\n",
    "            \n",
    "def compMinibatchKmean(ctlist,nclusterL,n_pcs,addName=''):\n",
    "    for ncluster in nclusterL:\n",
    "        savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        labels=np.array(labels)\n",
    "        if np.unique(labels).shape[0]==1:\n",
    "            continue\n",
    "            \n",
    "        savepath=clustersavedir\n",
    "        plotCTcomp(labels,ctlist,savepath,savenamecluster,addName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a895660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all cells\n",
    "for s in plot_samples.keys():\n",
    "    sampleidx=plot_samples[s]\n",
    "    \n",
    "    celltype_broad=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']\n",
    "    celltype_sub=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'cell_type_label']\n",
    "    region=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']\n",
    "#     sobj_coord_np=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,['x','y']].to_numpy()\n",
    "    for xcorr in plot_sample_X:\n",
    "        samplename=s+'X_'+xcorr\n",
    "        \n",
    "        if inverseAct:\n",
    "            samplename+='_beforeAct'\n",
    "       \n",
    "        sampledir=os.path.join(plotsavepath,samplename)\n",
    "        clustersavedir=os.path.join(plotsavepath,samplename,'cluster')\n",
    "\n",
    "        if 'leiden' in clustermethod:\n",
    "            compLeiden(celltype_broad,n_neighbors,n_pcs,min_dist,resolution)\n",
    "        if 'dbscan' in clustermethod:\n",
    "            compDBscan(celltype_broad,epslist,min_sampleslist,n_pcs)\n",
    "        if 'agglomerative' in clustermethod:\n",
    "            compAgg(celltype_broad,nclusterlist,aggMetric,n_pcs)\n",
    "        if 'kmeanbatch' in clustermethod:\n",
    "            compMinibatchKmean(celltype_broad,nclusterlist,n_pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c259687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all latents to one plot \n",
    "nsample=8\n",
    "\n",
    "np.random.seed(seed)\n",
    "latents=None\n",
    "samplenameList=None\n",
    "\n",
    "for s in plot_samples.keys():\n",
    "    sampleidx=plot_samples[s]        \n",
    "    samplename=s\n",
    "    muplot,_,_=imageslist[samplename]\n",
    "\n",
    "    if latents is None:\n",
    "        latents=muplot\n",
    "        samplenameList=np.repeat(s,muplot.shape[0])\n",
    "    else:\n",
    "        latents=np.vstack((latents,muplot))\n",
    "        samplenameList=np.concatenate((samplenameList,np.repeat(s,muplot.shape[0])),axis=None)\n",
    "\n",
    "sampledir=os.path.join(plotsavepath,'combined')\n",
    "if inverseAct:\n",
    "    sampledir+='_beforeAct'\n",
    "savedir=os.path.join(sampledir,'embedding_'+plottype)\n",
    "clustersavedir=os.path.join(sampledir,'cluster')\n",
    "\n",
    "if 'leiden' in clustermethod:\n",
    "    sampleLeiden(latents,nsample,n_neighbors,n_pcs,min_dist,resolution)\n",
    "if 'dbscan' in clustermethod:\n",
    "    sampleDBscan(latents,nsample,epslist,min_sampleslist,n_pcs)\n",
    "if 'agglomerative' in clustermethod:\n",
    "    sampleAgg(latents,nsample,nclusterlist,aggMetric,n_pcs)\n",
    "if 'kmeanbatch' in clustermethod:\n",
    "    sampleMinibatchKmean(latents,nsample,nclusterlist,n_pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65659e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CortexMicro\n",
      "HippocampusMicro\n",
      "White MatterMicro\n"
     ]
    }
   ],
   "source": [
    "# combine all latents to one plot -- by samples\n",
    "np.random.seed(seed)\n",
    "for xcorr in plot_sample_X:\n",
    "    samplenameList=None\n",
    "    celltype_broad=None\n",
    "    region=None\n",
    "\n",
    "    for s in plot_samples.keys():\n",
    "        sampleidx=plot_samples[s]        \n",
    "        samplename=s+'X_'+xcorr\n",
    "            \n",
    "        if samplenameList is None:\n",
    "            samplenameList=np.repeat(s,np.sum(scaleddata.obs['sample']==sampleidx))\n",
    "            celltype_broad=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']\n",
    "            region=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']            \n",
    "        else:\n",
    "            celltype_broad=np.concatenate((celltype_broad,scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']),axis=None)\n",
    "            samplenameList=np.concatenate((samplenameList,np.repeat(s,np.sum(scaleddata.obs['sample']==sampleidx))),axis=None)\n",
    "            region=np.concatenate((region,scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']),axis=None)\n",
    "\n",
    "    origCT=np.unique(celltype_broad)\n",
    "    celltypeplot=np.concatenate((origCT,list(combineCelltype.keys())),axis=None)\n",
    "    sampledir=os.path.join(plotsavepath,'combined'+xcorr)\n",
    "    if inverseAct:\n",
    "        sampledir+='_beforeAct'\n",
    "    clustersavedir=os.path.join(sampledir,'cluster')\n",
    "\n",
    "    if 'leiden' in clustermethod:\n",
    "        compLeiden(samplenameList,n_neighbors,n_pcs,min_dist,resolution,'Sample')\n",
    "    if 'dbscan' in clustermethod:\n",
    "        compDBscan(samplenameList,epslist,min_sampleslist,n_pcs,'Sample')\n",
    "    if 'agglomerative' in clustermethod:\n",
    "        compAgg(samplenameList,nclusterlist,aggMetric,n_pcs,'Sample')\n",
    "    if 'kmeanbatch' in clustermethod:\n",
    "        compMinibatchKmean(samplenameList,nclusterlist,n_pcs,'Sample')\n",
    "    #by region\n",
    "    for reg in np.unique(region):\n",
    "        savedir=os.path.join(sampledir,'embedding_'+plottype+'_'+reg)\n",
    "        clustersavedir=os.path.join(sampledir,'cluster'+'_'+reg)\n",
    "\n",
    "        reg_idx=region==reg\n",
    "\n",
    "        #by region and celltype\n",
    "        for ct in celltypeplot:\n",
    "#             if not ((reg=='Cortex' and ct in ['Ex']) or (reg=='Hippocampus' and ct in ['CA1','DG','Micro','CA'])):\n",
    "            if not (ct in ['Micro']):\n",
    "                continue\n",
    "            print(reg+ct)\n",
    "            clustersavedir=os.path.join(sampledir,'cluster'+'_'+reg+ct)\n",
    "            \n",
    "            if ct in origCT:\n",
    "                ct_idx=celltype_broad==ct\n",
    "            else:\n",
    "                ct_idx=False\n",
    "                for i in combineCelltype[ct]:\n",
    "                    ct_idx=np.logical_or(ct_idx,celltype_broad==i)\n",
    "            ct_idx=np.logical_and(reg_idx,ct_idx)      \n",
    "            \n",
    "            if np.sum(ct_idx)<3:\n",
    "                continue\n",
    "            \n",
    "            if 'leiden' in clustermethod:\n",
    "                compLeiden(celltype_sub[ct_idx],n_neighbors,n_pcs,min_dist,resolution,'Sample')\n",
    "            if 'dbscan' in clustermethod:\n",
    "                compDBscan(celltype_sub[ct_idx],epslist,min_sampleslist,n_pcs,'Sample')\n",
    "            if 'agglomerative' in clustermethod:\n",
    "                compAgg(celltype_sub[ct_idx],nclusterlist,aggMetric,n_pcs,'Sample')\n",
    "            if 'kmeanbatch' in clustermethod:\n",
    "                compMinibatchKmean(celltype_sub[ct_idx],nclusterlist,n_pcs,'Sample')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
