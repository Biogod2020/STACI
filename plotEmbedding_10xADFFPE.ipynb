{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xinyiz/pamrats')\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import scanpy \n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import average_precision_score\n",
    "\n",
    "import gae.gae.optimizer as optimizer\n",
    "import gae.gae.model\n",
    "import gae.gae.preprocessing as preprocessing\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN,MiniBatchKMeans,AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "import anndata as ad\n",
    "import gc\n",
    "\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "from skimage import io\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=3\n",
    "\n",
    "np.random.seed(seed)\n",
    "def plotembeddingbyCT(ctlist,savename,excludelist,embedding,savepath,plotname,plotdimx=0,plotdimy=1,savenameAdd='',img=None,ncolors=None):\n",
    "    \n",
    "    celltypes=np.unique(ctlist)\n",
    "# #     print(celltypes)\n",
    "#     celltypes_dict={}\n",
    "#     idx=0\n",
    "#     for ct in celltypes:\n",
    "#         celltypes_dict[ct]=idx\n",
    "#         idx+=1\n",
    "    if ncolors is None:\n",
    "        colortest=sns.color_palette(\"husl\", celltypes.size)\n",
    "    else:\n",
    "        colortest=sns.color_palette(\"husl\", ncolors)\n",
    "#     colortest=sns.color_palette(\"husl\", 9)\n",
    "#     np.random.shuffle(colortest)\n",
    "    fig, ax = plt.subplots(dpi=400)\n",
    "    if not img is None:\n",
    "        plt.imshow(img)\n",
    "    for ct in celltypes:\n",
    "        if ct in excludelist:\n",
    "            continue\n",
    "        idx=(ctlist==ct)\n",
    "        if not img is None:\n",
    "            ax.scatter(\n",
    "                embedding[idx, plotdimy],\n",
    "                embedding[idx, plotdimx],\n",
    "#                 color=colortest[celltypes_dict[ct]],label=ct,s=1.5,alpha=0.5\n",
    "                color=colortest[int(ct)],label=ct,s=1.5,alpha=0.5\n",
    "                )\n",
    "        else:\n",
    "            ax.scatter(\n",
    "                embedding[idx, plotdimx],\n",
    "                embedding[idx, plotdimy],\n",
    "#                 color=colortest[celltypes_dict[ct]],label=ct,s=1.5,alpha=0.5\n",
    "                color=colortest[int(ct)],label=ct,s=2.5,alpha=1\n",
    "                )\n",
    "\n",
    "    plt.gca().set_aspect('equal', 'datalim')\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(5)\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "    # Put a legend below current axis\n",
    "#     ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "#               fancybox=True, shadow=True, ncol=2,prop={'size': 6})\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "              fancybox=True,ncol=5, shadow=True,prop={'size': 6})\n",
    "#     ax.legend(ncol=3)\n",
    "    plt.title(plotname+' embedding', fontsize=12)\n",
    "    plt.savefig(os.path.join(savepath,savename+savenameAdd+'.jpg'))\n",
    "#     plt.show()\n",
    "    \n",
    "#     fig.clf()\n",
    "    plt.close('all')\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "def plotembeddingbyCT_contrast(ctlist,savename,excludelist,embedding,savepath,plotname,plotdimx=0,plotdimy=1,savenameAdd='',maxplot=None): \n",
    "    celltypes=np.unique(ctlist)\n",
    "    celltypes_dict={}\n",
    "    idx=0\n",
    "    for ct in celltypes:\n",
    "        celltypes_dict[ct]=idx\n",
    "        idx+=1\n",
    "\n",
    "    colortest=sns.color_palette(\"tab10\")\n",
    "    if not os.path.exists(os.path.join(savepath)):\n",
    "        os.makedirs(savepath)\n",
    "\n",
    "    for ct in celltypes:\n",
    "        if maxplot and int(ct)>maxplot:\n",
    "            continue\n",
    "        fig, ax = plt.subplots()\n",
    "        if ct == 'Unassigned':\n",
    "            continue\n",
    "\n",
    "        idx=(ctlist!=ct)\n",
    "        ax.scatter(\n",
    "            embedding[idx, plotdimx],\n",
    "            embedding[idx, plotdimy],\n",
    "            color=colortest[1],label='others',s=1,alpha=0.5\n",
    "            )\n",
    "\n",
    "        idx=(ctlist==ct)\n",
    "        ax.scatter(\n",
    "            embedding[idx, plotdimx],\n",
    "            embedding[idx, plotdimy],\n",
    "            color=colortest[0],label=ct,s=3,alpha=0.5\n",
    "            )\n",
    "\n",
    "        plt.gca().set_aspect('equal', 'datalim')\n",
    "        fig.set_figheight(10)\n",
    "        fig.set_figwidth(10)\n",
    "        ax.legend()\n",
    "        plt.title(plotname+' embedding', fontsize=24)\n",
    "        plt.gcf().savefig(os.path.join(savepath,savename+'_'+str(ct)+savenameAdd+'.jpg'))\n",
    "#         plt.show()\n",
    "#         nplot+=1\n",
    "        \n",
    "    \n",
    "#         fig.clf()\n",
    "        plt.close('all')\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCTcomp(labels,ctlist,savepath,savenamecluster,addname=''):\n",
    "    res=np.zeros((np.unique(labels).size,np.unique(ctlist).size))\n",
    "    for li in range(res.shape[0]):\n",
    "        l=np.unique(labels)[li]\n",
    "        nl=np.sum(labels==l)\n",
    "        ctlist_l=ctlist[labels==l]\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=np.unique(ctlist)[ci]\n",
    "            res[li,ci]=np.sum(ctlist_l==c)\n",
    "#             res[li,ci]=np.sum(ctlist_l==c)/nl\n",
    "    if not byCT:\n",
    "        addname+=''\n",
    "        for li in range(res.shape[0]):\n",
    "            l=np.unique(labels)[li]\n",
    "            nl=np.sum(labels==l)\n",
    "            res[li]=res[li]/nl\n",
    "    else:\n",
    "        addname+='_normbyCT'\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=np.unique(ctlist)[ci]\n",
    "            nc=np.sum(ctlist==c)\n",
    "            res[:,ci]=res[:,ci]/nc\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(res,cmap='binary')\n",
    "    ax.set_yticks(np.arange(np.unique(labels).size))\n",
    "    ax.set_yticklabels(np.unique(labels))\n",
    "    ax.set_xticks(np.arange(np.unique(ctlist).size))\n",
    "    ax.set_xticklabels(np.unique(ctlist))\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(savepath,savenamecluster+'_ctComposition'+addname+'.jpg'))\n",
    "    plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot gene expression clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='/mnt/external_ssd/xinyi/staci_validation/10xVisiumADFFPE/'\n",
    "tissuepospath='VisiumFFPE_Mouse_Brain_Alzheimers_AppNote_aggr_tissue_positions_list.csv'\n",
    "cluster10xpath='analysis/clustering/graphclust/clusters.csv'\n",
    "tissuepos=pd.read_csv(os.path.join(datadir,tissuepospath),header=None)\n",
    "cluster10x=pd.read_csv(os.path.join(datadir,cluster10xpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster10x['tissueID']=cluster10x['Barcode'].apply(lambda x: x.split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissuepos.index=tissuepos.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalefactor=0.150015\n",
    "libraryID=pd.read_csv(os.path.join(datadir,'VisiumFFPE_Mouse_Brain_Alzheimers_AppNote_aggregation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in np.unique(cluster10x['tissueID']):\n",
    "    clusterRes=cluster10x['Cluster'][cluster10x['tissueID']==s].to_numpy().astype(int)\n",
    "    sobj_coord_np=tissuepos.loc[cluster10x['Barcode'][cluster10x['tissueID']==s],4:6].to_numpy()*scalefactor\n",
    "    \n",
    "    samplename=libraryID['library_id'][int(s)-1]\n",
    "    img=mpimg.imread(os.path.join(datadir,'spatial',samplename,'tissue_hires_image.png'))\n",
    "    plotembeddingbyCT(clusterRes,samplename+'_clustering',[],sobj_coord_np,os.path.join(datadir,'plots'),'location'+' of '+s,img=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplenameList=cluster10x['tissueID'].to_numpy()\n",
    "for s in np.unique(samplenameList):\n",
    "    samplenameList[samplenameList==s]=libraryID['library_id'][int(s)-1]\n",
    "byCT=False\n",
    "plotCTcomp(cluster10x['Cluster'],samplenameList,os.path.join(datadir,'plots'),'cluster')\n",
    "byCT=True\n",
    "plotCTcomp(cluster10x['Cluster'],samplenameList,os.path.join(datadir,'plots'),'cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=scanpy.read_10x_h5(os.path.join(datadir,'VisiumFFPE_Mouse_Brain_Alzheimers_AppNote_filtered_feature_bc_matrix.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot DE gene expression across STACI clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurenames=features.var.index.to_numpy()[np.array(np.sum(features.X,axis=0)>3).flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rawcounts=features.X.toarray()[:,np.array(np.sum(features.X,axis=0)>3).flatten()]\n",
    "#normalize\n",
    "scalefactor={}\n",
    "libsizeSum=0\n",
    "scaledCounts=np.zeros_like(rawcounts)\n",
    "for s in np.unique(samplenameList):\n",
    "    print(s)\n",
    "    scaleddata_train=rawcounts[samplenameList==s]\n",
    "\n",
    "    libsizeS=np.sum(scaleddata_train,axis=1)\n",
    "    scalefactorS=np.median(libsizeS)\n",
    "    libsizeSum+=scalefactorS\n",
    "    scalefactor[s]=scalefactorS\n",
    "    gc.collect()\n",
    "    \n",
    "sizeFactor=libsizeSum/len(np.unique(samplenameList))\n",
    "for s in np.unique(samplenameList):\n",
    "    print(s)\n",
    "    scaleddata_train=rawcounts[samplenameList==s]\n",
    "    \n",
    "    scaleddata_train=np.log2(scaleddata_train*(sizeFactor/scalefactor[s])+1) #changed from 1/2 to 1 to avoid negatives\n",
    "    scaledCounts[samplenameList==s]=scaleddata_train\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEsavedir='/mnt/external_ssd/xinyi/plots/train_gae_starmap/allk20XA_02_dca_over/combinedlogminmax_beforeAct/de'\n",
    "dename='leiden_nn10mdist025n_pcs40res0.1epoch9990_clusters013'\n",
    "thresh='fc1.1pvalue0.05'\n",
    "clusterDE=['0','1','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot DEG exprs over DAPI\n",
    "scalefactor=0.150015\n",
    "samplelist=np.unique(samplenameList)\n",
    "for s in samplelist:\n",
    "    print(s)\n",
    "    sidx=samplenameList==s\n",
    "    xpos=tissuepos.loc[cluster10x['Barcode'][cluster10x['tissueID']==s],4].to_numpy()*scalefactor\n",
    "    ypos=tissuepos.loc[cluster10x['Barcode'][cluster10x['tissueID']==s],5].to_numpy()*scalefactor\n",
    "    \n",
    "    spath=os.path.join(datadir,'plots',s)\n",
    "    if not os.path.exists(spath):\n",
    "        os.mkdir(spath)\n",
    "    d1=io.imread(os.path.join(datadir,'spatial',s,'tissue_hires_image.png'))\n",
    "    \n",
    "    for c in clusterDE:\n",
    "        degup=pd.read_csv(os.path.join(DEsavedir,dename+'UP_'+c+'_'+thresh+'.csv')).to_numpy()\n",
    "        degdown=pd.read_csv(os.path.join(DEsavedir,dename+'DOWN_'+c+'_'+thresh+'.csv')).to_numpy()\n",
    "        if degup.size+degdown.size==0:\n",
    "            continue\n",
    "        heatmap=np.zeros((d1.shape[0],d1.shape[1],3))\n",
    "        heatmap[:,:,0]=(d1[:,:,2]-np.min(d1[:,:,2]))/(np.max(d1[:,:,2])-np.min(d1[:,:,2]))\n",
    "\n",
    "        degup=degup.flatten()\n",
    "        degdown=degdown.flatten()\n",
    "        _,degupidx,_=np.intersect1d(np.char.upper(featurenames.astype(str)),degup,return_indices=True)\n",
    "        _,degdownidx,_=np.intersect1d(np.char.upper(featurenames.astype(str)),degdown,return_indices=True)\n",
    "        for i in range(np.sum(sidx)):\n",
    "            heatmap[int(xpos[i]-5):int(xpos[i]+5),int(ypos[i]-5):int(ypos[i]+5),1]=np.sum(scaledCounts[sidx][i,degupidx])-np.sum(scaledCounts[sidx][i,degdownidx])\n",
    "        heatmapmin=np.min(heatmap[:,:,1])\n",
    "        heatmapmax=np.max(heatmap[:,:,1])\n",
    "        heatmap[:,:,1][heatmap[:,:,1]==0]=heatmapmin-10\n",
    "        heatmapmin-=10\n",
    "        heatmap[:,:,1]=(heatmap[:,:,1]-heatmapmin)/(heatmapmax-heatmapmin)\n",
    "        \n",
    "        fig = plt.figure(frameon=False)\n",
    "        fig.set_size_inches(d1.shape[0]/1000,d1.shape[1]/1000)\n",
    "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "        ax.set_axis_off()\n",
    "        fig.add_axes(ax)\n",
    "        ax.imshow(heatmap,aspect='auto')\n",
    "        \n",
    "        plt.savefig(os.path.join(spath,'DEGheatmap_'+c+'.png'),dpi=1000)\n",
    "        plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 18))\n",
    "ax.imshow(d1[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 18))\n",
    "\n",
    "plt.imshow(d1[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 18))\n",
    "\n",
    "\n",
    "plt.imshow(d1[:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot STACI clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n"
     ]
    }
   ],
   "source": [
    "datadir='/home/xinyi/staci_validation/10xVisiumADFFPE/'\n",
    "tissuepospath='VisiumFFPE_Mouse_Brain_Alzheimers_AppNote_aggr_tissue_positions_list.csv'\n",
    "tissuepos=pd.read_csv(os.path.join(datadir,tissuepospath),header=None)\n",
    "\n",
    "tissuepos.index=tissuepos.iloc[:,0]\n",
    "scalefactor=0.150015\n",
    "libraryID=pd.read_csv(os.path.join(datadir,'VisiumFFPE_Mouse_Brain_Alzheimers_AppNote_aggregation.csv'))\n",
    "features=scanpy.read_10x_h5(os.path.join(datadir,'VisiumFFPE_Mouse_Brain_Alzheimers_AppNote_filtered_feature_bc_matrix.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.obs['x']=tissuepos.loc[features.obs.index,4]*scalefactor\n",
    "features.obs['y']=tissuepos.loc[features.obs.index,5]*scalefactor\n",
    "features.obs['barcodes']=features.obs.index\n",
    "sampleidx=features.obs['barcodes'].apply(lambda x: x.split('-')[1])\n",
    "samplenameList=np.zeros(sampleidx.size).astype(str)\n",
    "for s in np.unique(sampleidx):\n",
    "    samplenameList[sampleidx==s]=libraryID['library_id'][int(s)-1]\n",
    "features.obs['samplename']=samplenameList\n",
    "features.var_names_make_unique()\n",
    "features=features[:,np.array(np.sum(features.X,axis=0)>3).flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples=np.unique(samplenameList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifplot=True\n",
    "ifcluster=True\n",
    "\n",
    "inverseAct='leakyRelu'\n",
    "# inverseAct=None\n",
    "plottype='umap'\n",
    "pca=PCA()\n",
    "npc=50 #for pca var ration\n",
    "npc_plot=10 #for pairwise pc plots\n",
    "\n",
    "minCells=15 #min number of cells for analysis\n",
    "clustermethod=['leiden']\n",
    "# clustermethod=['leiden','agglomerative','kmeanbatch']\n",
    "#umap/leiden clustering parameters\n",
    "n_neighbors=10\n",
    "min_dist=0.25\n",
    "n_pcs=40 #for clustering\n",
    "resolution=[0.025,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.8,1]\n",
    "# resolution=[0.025,0.05,0.1,0.2]\n",
    "plotepoch=9310\n",
    "savenameAdd=''\n",
    "#DBscan\n",
    "epslist= [6,8,10]\n",
    "min_sampleslist=[15,30,45] \n",
    "#agglomerative\n",
    "nclusterlist=[2,3,4,5,8,10,15]\n",
    "aggMetric=['euclidean']\n",
    "\n",
    "\n",
    "use_cuda=True\n",
    "fastmode=False #Validate during training pass\n",
    "seed=3\n",
    "useSavedMaskedEdges=False\n",
    "maskedgeName='knn6_connectivity'\n",
    "nneighbors=6\n",
    "hidden1=30000 #Number of units in hidden layer 1\n",
    "hidden2=30000 #Number of units in hidden layer 2\n",
    "fc_dim1=30000\n",
    "\n",
    "protein=None #'scaled_binary'\n",
    "# proteinWeights=0.05\n",
    "dropout=0.01\n",
    "# randFeatureSubset=None\n",
    "model_str='gcn_vae_xa_e2_d1_dca_sharded'\n",
    "adj_decodeName=None #gala or None\n",
    "plot_sample_X=['logminmax']\n",
    "plotRecon='' #'meanRecon'\n",
    "# plot_sample_X=['corrected','scaled']\n",
    "standardizeX=False\n",
    "name='10xAD_01_dca_over' \n",
    "logsavepath='/data/xinyi/log/train_gae_visium_validation/'+name\n",
    "modelsavepath='/data/xinyi/models/train_gae_visium_validation/'+name\n",
    "plotsavepath='/data/xinyi/plots/train_gae_visium_validation/'+name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getA_knn(samplename,k,a_mode,savepath=None):\n",
    "    sobj_coord_np=features.obs.loc[features.obs.index[features.obs['samplename']==samplename],['x','y']].to_numpy()\n",
    "    nbrs = NearestNeighbors(n_neighbors=k, algorithm='ball_tree').fit(sobj_coord_np)\n",
    "    a=nbrs.kneighbors_graph(sobj_coord_np,mode=a_mode)\n",
    "    if a_mode=='connectivity':\n",
    "        a=a-sp.identity(sobj_coord_np.shape[0],format='csr')\n",
    "    if a_mode=='distance':\n",
    "        a[a!=0]=1/a[a!=0]\n",
    "    if savepath !=None:\n",
    "        sp.save_npz(savepath,a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transgenic_17p9_rep1\n",
      "Transgenic_17p9_rep2\n",
      "Transgenic_2p5_rep1\n",
      "Transgenic_2p5_rep2\n",
      "Transgenic_5p7_rep1\n",
      "Transgenic_5p7_rep2\n",
      "Wildtype_13p4_rep1\n",
      "Wildtype_13p4_rep2\n",
      "Wildtype_2p5_rep1\n",
      "Wildtype_2p5_rep2\n",
      "Wildtype_5p7_rep1\n",
      "Wildtype_5p7_rep2\n",
      "17186\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "savedirlist={}\n",
    "featureslist={}\n",
    "features_raw_list={}\n",
    "adj_list={}\n",
    "commonGenes=[]\n",
    "    \n",
    "for samplename in np.unique(features.obs['samplename']):\n",
    "    print(samplename)\n",
    "    \n",
    "    adj_list[samplename]=getA_knn(samplename,nneighbors+1,'connectivity')\n",
    "    if plot_sample_X[0]=='logminmax':\n",
    "        featurelog_train=np.log2(features.X[features.obs['samplename']==samplename].toarray()+1/2)\n",
    "        scaler = MinMaxScaler()\n",
    "        featurelog_train_minmax=np.transpose(scaler.fit_transform(np.transpose(featurelog_train)))\n",
    "        featureslist[samplename+'X_'+plot_sample_X[0]]=torch.tensor(featurelog_train_minmax)\n",
    "    features_raw_list[samplename+'X_'+'raw']=torch.tensor(features.X[features.obs['samplename']==samplename].toarray())\n",
    "\n",
    "    \n",
    "num_features=features.shape[1]\n",
    "print(num_features)\n",
    "adjnormlist={}\n",
    "pos_weightlist={}\n",
    "normlist={}\n",
    "for ai in adj_list.keys():\n",
    "    adjnormlist[ai]=preprocessing.preprocess_graph(adj_list[ai])\n",
    "    \n",
    "    pos_weightlist[ai] = torch.tensor(float(adj_list[ai].shape[0] * adj_list[ai].shape[0] - adj_list[ai].sum()) / adj_list[ai].sum()) #using full unmasked adj\n",
    "    normlist[ai] = adj_list[ai].shape[0] * adj_list[ai].shape[0] / float((adj_list[ai].shape[0] * adj_list[ai].shape[0] - adj_list[ai].sum()) * 2)\n",
    "    \n",
    "    adj_label=adj_list[ai] + sp.eye(adj_list[ai].shape[0])\n",
    "    adj_list[ai]=torch.tensor(adj_label.toarray())\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "num_nodes,num_features = list(featureslist.values())[0].shape\n",
    "if model_str=='gcn_vae_xa':\n",
    "    model  = gae.gae.model.GCNModelVAE_XA(num_features, hidden1, hidden2,fc_dim1,fc_dim2,fc_dim3,fc_dim4, dropout)\n",
    "elif model_str=='fc1':\n",
    "    model  = gae.gae.model.FCVAE1(num_features, hidden1,dropout)\n",
    "elif model_str == 'gcn_vae_xa_e2_d1':\n",
    "    model  = gae.gae.model.GCNModelVAE_XA_e2_d1(num_features, hidden1,hidden2, dropout)\n",
    "elif model_str == 'gcn_vae_gcnX_inprA':\n",
    "    model = gae.gae.model.GCNModelVAE_gcnX_inprA(num_features, hidden1, hidden2,gcn_dim1, dropout)\n",
    "elif model_str=='fc1_dca':\n",
    "    model = gae.gae.model.FCVAE1_DCA(num_features, hidden1,fc_dim1, dropout)\n",
    "elif model_str=='fc1_dca_sharded':\n",
    "    model = gae.gae.model.FCVAE1_DCA_sharded(num_features, hidden1,fc_dim1, dropout)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dca':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dca_sharded':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA_sharded(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaFork':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCAfork(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaElemPi':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCAelemPi(num_features, hidden1,hidden2,fc_dim1, dropout,shareGenePi)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaConstantDisp':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA_constantDisp(num_features, hidden1,hidden2,fc_dim1, dropout,shareGenePi)\n",
    "else:\n",
    "    print('model not found')\n",
    "model.load_state_dict(torch.load(os.path.join(modelsavepath,str(plotepoch)+'.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "def inverseLeakyRelu(v,slope=0.01):\n",
    "    vnegidx=(v<0)\n",
    "    v[vnegidx]=1/slope*v[vnegidx]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "def clusterLeiden_single(inArray,n_neighbors,n_pcs,min_dist,resolution,randseed=seed):\n",
    "    n_pcs=np.min([inArray.shape[0]-1,inArray.shape[1]-1,n_pcs])\n",
    "    adata=ad.AnnData(inArray)\n",
    "    scanpy.tl.pca(adata, svd_solver='arpack')\n",
    "    scanpy.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=n_pcs)\n",
    "    scanpy.tl.umap(adata,min_dist=min_dist,random_state=randseed)\n",
    "    scanpy.tl.leiden(adata,resolution=resolution,random_state=randseed)\n",
    "    return adata.obs['leiden'].to_numpy()\n",
    "\n",
    "def clusterLeiden(inArray,n_neighbors,n_pcs,min_dist,resolution,sobj_coord_np,randseed=seed):\n",
    "    for r in resolution:\n",
    "        clusterRes=clusterLeiden_single(inArray,n_neighbors,n_pcs,min_dist,r,randseed=seed)\n",
    "#         print(clusterRes.shape)\n",
    "        savenamecluster='leiden_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'n_pcs'+str(n_pcs)+'res'+str(r)+'epoch'+str(plotepoch)\n",
    "        with open(os.path.join(clustersavedir,savenamecluster), 'wb') as output:\n",
    "            pickle.dump(clusterRes, output, pickle.HIGHEST_PROTOCOL)\n",
    "        plotembeddingbyCT(clusterRes,'leiden',[],embedding,savedir,plottype+' of '+s,savenameAdd=savenamecluster)\n",
    "        plotembeddingbyCT_contrast(clusterRes,'leiden',[],embedding,os.path.join(savedir,'contrast'),plottype+' of '+s,savenameAdd=savenamecluster)\n",
    "\n",
    "        plotembeddingbyCT(clusterRes,'leiden_location',[],sobj_coord_np,savedir,'location'+' of '+s,savenameAdd=savenamecluster)\n",
    "        plotembeddingbyCT_contrast(clusterRes,'leiden_location',[],sobj_coord_np,os.path.join(savedir,'contrast'),'location'+' of '+s,savenameAdd=savenamecluster)\n",
    "\n",
    "def clusterLeiden_allsample(embedding,savedir,clustersavedir,inArray,n_neighbors,n_pcs,min_dist,resolution,sobj_coord_np,samplenameList,randseed=seed):\n",
    "    for r in resolution:\n",
    "        clusterRes=clusterLeiden_single(inArray,n_neighbors,n_pcs,min_dist,r,randseed=seed)\n",
    "        savenamecluster='leiden_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'n_pcs'+str(n_pcs)+'res'+str(r)+'epoch'+str(plotepoch)\n",
    "#         with open(os.path.join(clustersavedir,savenamecluster), 'wb') as output:\n",
    "#             pickle.dump(clusterRes, output, pickle.HIGHEST_PROTOCOL)\n",
    "#         plotembeddingbyCT(clusterRes,'leiden',[],embedding,savedir,plottype+' of all samples',savenameAdd=savenamecluster)\n",
    "#         plotembeddingbyCT_contrast(clusterRes,'leiden',[],embedding,os.path.join(savedir,'contrast'),plottype+' of all samples',savenameAdd=savenamecluster,maxplot=50)\n",
    "\n",
    "        with open(os.path.join(clustersavedir,savenamecluster), 'rb') as output:\n",
    "            clusterRes=pickle.load(output)\n",
    "        for s in plot_samples:\n",
    "            sidx=(samplenameList==s)\n",
    "            img=None\n",
    "#             img=mpimg.imread(os.path.join(datadir,'spatial',s,'tissue_hires_image.png'))\n",
    "            plotembeddingbyCT(clusterRes[sidx],'leiden_location'+s,[],sobj_coord_np[sidx],savedir,'location'+' of '+s,savenameAdd=savenamecluster+'_noImg',img=img,ncolors=np.unique(clusterRes).size)\n",
    "#             plotembeddingbyCT_contrast(clusterRes[sidx],'leiden_location'+s,[],sobj_coord_np[sidx],os.path.join(savedir,'contrast'),'location'+' of '+s,savenameAdd=savenamecluster,maxplot=50)\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "def clusterDBscan_single(inArray,eps,min_samples,n_pcs):\n",
    "    n_pcs=np.min([inArray.shape[0]-1,inArray.shape[1]-1,n_pcs])\n",
    "    inArray=pca.fit_transform(inArray)\n",
    "    labels = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(inArray[:,:n_pcs])\n",
    "#     db = DBSCAN(eps=eps, min_samples=min_samples).fit(inArray[:,:n_pcs])\n",
    "#     core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "#     core_samples_mask[db.core_sample_indices_] = True\n",
    "#     labels = db.labels_\n",
    "    return labels\n",
    "\n",
    "def clusterDBscan(inArray,epsL,min_samplesL,n_pcs,sobj_coord_np):\n",
    "    for eps in epsL:\n",
    "        for min_samples in min_samplesL:\n",
    "            clusterRes=clusterDBscan_single(inArray,eps,min_samples,n_pcs)\n",
    "    #         print(clusterRes.shape)\n",
    "            savenamecluster='dbscan_eps'+str(eps)+'msamples'+str(min_samples)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            with open(os.path.join(clustersavedir,savenamecluster), 'wb') as output:\n",
    "                pickle.dump(clusterRes, output, pickle.HIGHEST_PROTOCOL)\n",
    "            plotembeddingbyCT(clusterRes,'dbscan',[],embedding,savedir,plottype+' of '+s,savenameAdd=savenamecluster)\n",
    "            plotembeddingbyCT_contrast(clusterRes,'dbscan',[],embedding,os.path.join(savedir,'contrast'),plottype+' of '+s,savenameAdd=savenamecluster)\n",
    "\n",
    "            plotembeddingbyCT(clusterRes,'dbscan_location',[],sobj_coord_np,savedir,'location'+' of '+s,savenameAdd=savenamecluster)\n",
    "            plotembeddingbyCT_contrast(clusterRes,'dbscan_location',[],sobj_coord_np,os.path.join(savedir,'contrast'),'location'+' of '+s,savenameAdd=savenamecluster)\n",
    "\n",
    "def clusterDBscan_allsample(embedding,savedir,clustersavedir,inArray,epsL,min_samplesL,n_pcs,sobj_coord_np,samplenameList):\n",
    "    for eps in epsL:\n",
    "        for min_samples in min_samplesL:\n",
    "            clusterRes=clusterDBscan_single(inArray,eps,min_samples,n_pcs)\n",
    "            savenamecluster='dbscan_eps'+str(eps)+'msample'+str(min_samples)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            with open(os.path.join(clustersavedir,savenamecluster), 'wb') as output:\n",
    "                pickle.dump(clusterRes, output, pickle.HIGHEST_PROTOCOL)\n",
    "            plotembeddingbyCT(clusterRes,'dbscan',[],embedding,savedir,plottype+' of all samples',savenameAdd=savenamecluster)\n",
    "            plotembeddingbyCT_contrast(clusterRes,'dbscan',[],embedding,os.path.join(savedir,'contrast'),plottype+' of all samples',savenameAdd=savenamecluster,maxplot=50)\n",
    "\n",
    "            for s in plot_samples:\n",
    "                sidx=(samplenameList==s)\n",
    "                img=mpimg.imread(os.path.join(datadir,s,'spatial','detected_tissue_image.jpg'))\n",
    "                plotembeddingbyCT(clusterRes[sidx],'dbscan_location'+s,[],sobj_coord_np[sidx],savedir,'location'+' of '+s,savenameAdd=savenamecluster,img=img)\n",
    "                plotembeddingbyCT_contrast(clusterRes[sidx],'dbscan_location'+s,[],sobj_coord_np[sidx],os.path.join(savedir,'contrast'),'location'+' of '+s,savenameAdd=savenamecluster,maxplot=50)\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "def clusterAgg_single(inArray,ncluster,aggmetric,n_pcs):\n",
    "    n_pcs=np.min([inArray.shape[0]-1,inArray.shape[1]-1,n_pcs])\n",
    "    inArray=pca.fit_transform(inArray)\n",
    "    labels = AgglomerativeClustering(n_clusters=ncluster,affinity=aggmetric).fit_predict(inArray[:,:n_pcs])\n",
    "#     labels = agg.labels_\n",
    "    return labels\n",
    "\n",
    "def clusterAgg(inArray,nclusterL,aggmetricL,n_pcs,sobj_coord_np):\n",
    "    for ncluster in nclusterL:\n",
    "        for aggmetric in aggmetricL:\n",
    "            clusterRes=clusterAgg_single(inArray,ncluster,aggmetric,n_pcs)\n",
    "    #         print(clusterRes.shape)\n",
    "            savenamecluster='agg_ncluster'+str(ncluster)+aggmetric+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            with open(os.path.join(clustersavedir,savenamecluster), 'wb') as output:\n",
    "                pickle.dump(clusterRes, output, pickle.HIGHEST_PROTOCOL)\n",
    "            plotembeddingbyCT(clusterRes,'agg',[],embedding,savedir,plottype+' of '+s,savenameAdd=savenamecluster)\n",
    "            plotembeddingbyCT_contrast(clusterRes,'agg',[],embedding,os.path.join(savedir,'contrast'),plottype+' of '+s,savenameAdd=savenamecluster)\n",
    "\n",
    "            plotembeddingbyCT(clusterRes,'agg_location',[],sobj_coord_np,savedir,'location'+' of '+s,savenameAdd=savenamecluster)\n",
    "            plotembeddingbyCT_contrast(clusterRes,'agg_location',[],sobj_coord_np,os.path.join(savedir,'contrast'),'location'+' of '+s,savenameAdd=savenamecluster)\n",
    "\n",
    "def clusterAgg_allsample(embedding,savedir,clustersavedir,inArray,nclusterL,aggmetricL,n_pcs,sobj_coord_np,samplenameList):\n",
    "    for ncluster in nclusterL:\n",
    "        for aggmetric in aggmetricL:\n",
    "            clusterRes=clusterAgg_single(inArray,ncluster,aggmetric,n_pcs)\n",
    "            savenamecluster='agg_ncluster'+str(ncluster)+aggmetric+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            with open(os.path.join(clustersavedir,savenamecluster), 'wb') as output:\n",
    "                pickle.dump(clusterRes, output, pickle.HIGHEST_PROTOCOL)\n",
    "            plotembeddingbyCT(clusterRes,'agg',[],embedding,savedir,plottype+' of all samples',savenameAdd=savenamecluster)\n",
    "            plotembeddingbyCT_contrast(clusterRes,'agg',[],embedding,os.path.join(savedir,'contrast'),plottype+' of all samples',savenameAdd=savenamecluster,maxplot=50)\n",
    "\n",
    "            for s in plot_samples:\n",
    "                sidx=(samplenameList==s)\n",
    "                img=mpimg.imread(os.path.join(datadir,s,'spatial','detected_tissue_image.jpg'))\n",
    "                plotembeddingbyCT(clusterRes[sidx],'agg_location'+s,[],sobj_coord_np[sidx],savedir,'location'+' of '+s,savenameAdd=savenamecluster,img=img)\n",
    "                plotembeddingbyCT_contrast(clusterRes[sidx],'agg_location'+s,[],sobj_coord_np[sidx],os.path.join(savedir,'contrast'),'location'+' of '+s,savenameAdd=savenamecluster,maxplot=50)\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "def clusterMinibatchKmean_single(inArray,ncluster,n_pcs,batchsize=100):\n",
    "    n_pcs=np.min([inArray.shape[0]-1,inArray.shape[1]-1,n_pcs])\n",
    "    batchsize=int(np.min([(inArray.shape[0]-1)/3,(inArray.shape[1]-1)/3,batchsize]))\n",
    "    inArray=pca.fit_transform(inArray)\n",
    "    labels = MiniBatchKMeans(n_clusters=ncluster,random_state=seed,batch_size=batchsize).fit_predict(inArray[:,:n_pcs])\n",
    "    return labels\n",
    "\n",
    "def clusterMinibatchKmean(inArray,nclusterL,n_pcs,sobj_coord_np):\n",
    "    for ncluster in nclusterL:\n",
    "        clusterRes=clusterMinibatchKmean_single(inArray,ncluster,n_pcs)\n",
    "#         print(clusterRes.shape)\n",
    "        savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "        with open(os.path.join(clustersavedir,savenamecluster), 'wb') as output:\n",
    "            pickle.dump(clusterRes, output, pickle.HIGHEST_PROTOCOL)\n",
    "        plotembeddingbyCT(clusterRes,'minibatchkmean',[],embedding,savedir,plottype+' of '+s,savenameAdd=savenamecluster)\n",
    "        plotembeddingbyCT_contrast(clusterRes,'minibatchkmean',[],embedding,os.path.join(savedir,'contrast'),plottype+' of '+s,savenameAdd=savenamecluster)\n",
    "\n",
    "        plotembeddingbyCT(clusterRes,'minibatchkmean_location',[],sobj_coord_np,savedir,'location'+' of '+s,savenameAdd=savenamecluster)\n",
    "        plotembeddingbyCT_contrast(clusterRes,'minibatchkmean_location',[],sobj_coord_np,os.path.join(savedir,'contrast'),'location'+' of '+s,savenameAdd=savenamecluster)\n",
    "\n",
    "def clusterMinibatchKmean_allsample(embedding,savedir,clustersavedir,inArray,nclusterL,n_pcs,sobj_coord_np,samplenameList):\n",
    "    for ncluster in nclusterL:\n",
    "        clusterRes=clusterMinibatchKmean_single(inArray,ncluster,n_pcs)\n",
    "        savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "        with open(os.path.join(clustersavedir,savenamecluster), 'wb') as output:\n",
    "            pickle.dump(clusterRes, output, pickle.HIGHEST_PROTOCOL)\n",
    "        plotembeddingbyCT(clusterRes,'minibatchkmean',[],embedding,savedir,plottype+' of all samples',savenameAdd=savenamecluster)\n",
    "        plotembeddingbyCT_contrast(clusterRes,'minibatchkmean',[],embedding,os.path.join(savedir,'contrast'),plottype+' of all samples',savenameAdd=savenamecluster,maxplot=50)\n",
    "\n",
    "        for s in plot_samples:\n",
    "            sidx=(samplenameList==s)\n",
    "            img=mpimg.imread(os.path.join(datadir,s,'spatial','detected_tissue_image.jpg'))\n",
    "            plotembeddingbyCT(clusterRes[sidx],'minibatchkmean_location'+s,[],sobj_coord_np[sidx],savedir,'location'+' of '+s,savenameAdd=savenamecluster,img=img)\n",
    "            plotembeddingbyCT_contrast(clusterRes[sidx],'minibatchkmean_location'+s,[],sobj_coord_np[sidx],os.path.join(savedir,'contrast'),'location'+' of '+s,savenameAdd=savenamecluster,maxplot=50)\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#compute embeddings\n",
    "mulist={}\n",
    "for s in np.unique(samplenameList):\n",
    "    adj=adj_list[s]\n",
    "    adj_norm = preprocessing.preprocess_graph(adj)\n",
    "    adj_decode=None\n",
    "    if adj_decodeName == 'gala':\n",
    "        adj_decode=preprocessing.preprocess_graph_sharp(adj)\n",
    "    for xcorr in plot_sample_X:\n",
    "        samplename=s+'X_'+xcorr\n",
    "        features_s=featureslist[samplename]\n",
    "#         if standardizeX:\n",
    "#             features=torch.tensor(scale(features,axis=0, with_mean=True, with_std=True, copy=True))\n",
    "#         if use_cuda:\n",
    "#             model.cuda()\n",
    "#             features = features.cuda().float()\n",
    "#             adj_norm=adj_norm.cuda()\n",
    "#             if adj_decodeName:\n",
    "#                 adj_decode=adj_decode.cuda()\n",
    "        \n",
    "        model.eval()\n",
    "        if adj_decodeName==None:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features_s, adj_norm)\n",
    "        else:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features_s, adj_norm,adj_decode)\n",
    "        if inverseAct=='leakyRelu':\n",
    "            muplot=inverseLeakyRelu(mu.cpu().detach().numpy())\n",
    "        else:\n",
    "            muplot=mu.cpu().detach().numpy()\n",
    "        if plotRecon:\n",
    "            if plotRecon=='meanRecon':\n",
    "                mulist[samplename]=features_recon[3].cpu().detach().numpy()\n",
    "        else:\n",
    "            mulist[samplename]=muplot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/xinyi/pamrats/latent/10xAD_01_dca_over', 'wb') as output:\n",
    "    pickle.dump(mulist,output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/xinyi/pamrats/latent/10xAD_01_dca_over', 'rb') as output:\n",
    "    mulist=pickle.load(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all latents to one plot \n",
    "np.random.seed(seed)\n",
    "for xcorr in plot_sample_X:\n",
    "    latents=None\n",
    "    samplenameList_plot=None\n",
    "    sobj_coord_np=None\n",
    "    \n",
    "    for s in np.unique(samplenameList):\n",
    "        samplename=s+'X_'+xcorr\n",
    "        muplot=np.copy(mulist[samplename])\n",
    "            \n",
    "        if latents is None:\n",
    "            latents=muplot\n",
    "            sobj_coord_np=features.obs.loc[:,('x','y')].to_numpy()[samplenameList==s]\n",
    "            samplenameList_plot=np.repeat(s,muplot.shape[0])\n",
    "        else:\n",
    "            latents=np.vstack((latents,muplot))\n",
    "            sobj_coord_np=np.concatenate((sobj_coord_np,features.obs.loc[:,('x','y')].to_numpy()[samplenameList==s]),axis=0)\n",
    "            samplenameList_plot=np.concatenate((samplenameList_plot,np.repeat(s,muplot.shape[0])),axis=None)\n",
    "\n",
    "    sampledir=os.path.join(plotsavepath,'combined'+xcorr)\n",
    "    if inverseAct:\n",
    "        sampledir+='_beforeAct'\n",
    "    savedir=os.path.join(sampledir,'embedding_'+plottype)\n",
    "    clustersavedir=os.path.join(sampledir,'cluster')\n",
    "    if not os.path.exists(sampledir):\n",
    "        os.mkdir(sampledir)\n",
    "    if not os.path.exists(savedir):\n",
    "        os.mkdir(savedir)\n",
    "    if not os.path.exists(clustersavedir):\n",
    "        os.mkdir(clustersavedir)\n",
    "    \n",
    "    if plottype=='umap':\n",
    "        npc_plot=2\n",
    "        reducer = umap.UMAP(n_neighbors=n_neighbors,min_dist=min_dist,random_state=seed)\n",
    "        embedding = reducer.fit_transform(latents)\n",
    "        savenameAdd='_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'epoch'+str(plotepoch)\n",
    "    elif plottype=='pca':\n",
    "        pca.fit(latents)\n",
    "        fig, ax = plt.subplots(dpi=400)\n",
    "        fig.set_figheight(2.5)\n",
    "        fig.set_figwidth(10)\n",
    "        plt.bar(np.arange(npc),pca.explained_variance_ratio_[:npc])\n",
    "        plt.savefig(os.path.join(savedir,'varRatio_'+str(npc)+'_epoch'+str(plotepoch)+'.jpg'))\n",
    "        plt.close()\n",
    "        fig, ax = plt.subplots(dpi=400)\n",
    "        fig.set_figheight(2.5)\n",
    "        fig.set_figwidth(10)\n",
    "        plt.bar(np.arange(npc),pca.explained_variance_[:npc])\n",
    "        plt.savefig(os.path.join(savedir,'var_'+str(npc)+'_epoch'+str(plotepoch)+'.jpg'))\n",
    "        plt.close()\n",
    "        embedding=pca.transform(latents)\n",
    "#         embedding=pca.fit_transform(latents)\n",
    "        savenameAdd='_epoch'+str(plotepoch)\n",
    "    if ifplot:\n",
    "        for dim1 in range(npc_plot-1):\n",
    "            for dim2 in range(dim1+1,npc_plot):\n",
    "                plotembeddingbyCT(samplenameList,'sample',[],embedding,savedir,plottype+'of all samples',plotdimx=dim1,plotdimy=dim2,savenameAdd=savenameAdd+'_pc'+str(dim1)+'pc'+str(dim2))\n",
    "        #         plotembeddingbyCT(celltype_broad,'celltype_broad',[],embedding,savedir,plottype+'all samples',plotdimx=dim1,plotdimy=dim2,savenameAdd=savenameAdd+'_pc'+str(dim1)+'pc'+str(dim2))\n",
    "        #             plotembeddingbyCT(celltype_sub,'celltype_sub',[],embedding,savedir,plottype+'all samples',savenameAdd=savenameAdd)\n",
    "        #         plotembeddingbyCT(region,'region',[],embedding,savedir,plottype+'all samples',plotdimx=dim1,plotdimy=dim2,savenameAdd=savenameAdd+'_pc'+str(dim1)+'pc'+str(dim2))\n",
    "\n",
    "        #             plotembeddingbyCT_contrast(celltype_sub,'celltype_sub',[],embedding,os.path.join(savedir,'contrast'),plottype+'all samples',savenameAdd=savenameAdd)    \n",
    "    \n",
    "    if embedding.shape[0]<minCells:\n",
    "        continue\n",
    "    if ifcluster:\n",
    "        if 'leiden' in clustermethod:\n",
    "            clusterLeiden_allsample(embedding,savedir,clustersavedir,latents,n_neighbors,n_pcs,min_dist,resolution,sobj_coord_np,samplenameList,randseed=seed)\n",
    "            assert np.sum(muplot-np.copy(mulist[s+'X_'+xcorr]))==0\n",
    "        if 'dbscan' in clustermethod:\n",
    "            clusterDBscan_allsample(embedding,savedir,clustersavedir,latents,epslist,min_sampleslist,n_pcs,sobj_coord_np,samplenameList)\n",
    "            assert np.sum(muplot-np.copy(mulist[s+'X_'+xcorr]))==0\n",
    "        if 'agglomerative' in clustermethod:\n",
    "            clusterAgg_allsample(embedding,savedir,clustersavedir,latents,nclusterlist,aggMetric,n_pcs,sobj_coord_np,samplenameList)\n",
    "            assert np.sum(muplot-np.copy(mulist[s+'X_'+xcorr]))==0\n",
    "        if 'kmeanbatch' in clustermethod:\n",
    "            clusterMinibatchKmean_allsample(embedding,savedir,clustersavedir,latents,nclusterlist,n_pcs,sobj_coord_np,samplenameList)\n",
    "            assert np.sum(muplot-np.copy(mulist[s+'X_'+xcorr]))==0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "# combine all latents to one plot -- subcluster \n",
    "np.random.seed(seed)\n",
    "\n",
    "ifplot=True\n",
    "ifcluster=True\n",
    "\n",
    "#leiden\n",
    "subResolution=[0.2,0.3,0.4]\n",
    "\n",
    "plottype='umap'\n",
    "pca=PCA()\n",
    "minCells_sub=10 #min number of cells for analysis\n",
    "# clustermethod=['leiden','agglomerative','kmeanbatch']\n",
    "clustermethod=['leiden']\n",
    "#umap/leiden clustering parameters\n",
    "n_neighbors_sub=5\n",
    "min_dist_sub=0.25\n",
    "n_pcs_sub=10 #for clustering\n",
    "resolution_sub=[0.025,0.05,0.1,0.15]\n",
    "# resolution_sub=[0.005,0.0075,0.01,0.015]\n",
    "#DBscan\n",
    "epslist_sub= [6,8,10]\n",
    "min_sampleslist_sub=[15,30,45] \n",
    "#agglomerative\n",
    "nclusterlist_sub=[2,4,8,12]\n",
    "aggMetric_sub=['euclidean']\n",
    "\n",
    "xcorr=plot_sample_X[0]\n",
    "sampledir=os.path.join(plotsavepath,'combined'+xcorr)\n",
    "if inverseAct:\n",
    "    sampledir+='_beforeAct'\n",
    "savedir=os.path.join(sampledir,'embedding_'+plottype)\n",
    "clustersavedir=os.path.join(sampledir,'cluster')\n",
    "\n",
    "def subcluster(clustermethod,labels,savepath,addname):\n",
    "    latents=None\n",
    "    celltype_broad=None\n",
    "    celltype_sub=None\n",
    "    region=None\n",
    "    samplenameList_plot=None\n",
    "    sobj_coord_np=None\n",
    "    for s in plot_samples:\n",
    "        samplename=s+'X_'+xcorr\n",
    "        muplot=np.copy(mulist[samplename])\n",
    "\n",
    "        if latents is None:\n",
    "            latents=muplot\n",
    "            sobj_coord_np=features.obs.loc[:,('x','y')].to_numpy()[samplenameList==s]\n",
    "            samplenameList_plot=np.repeat(s,muplot.shape[0])\n",
    "        else:\n",
    "            latents=np.vstack((latents,muplot))\n",
    "            sobj_coord_np=np.concatenate((sobj_coord_np,features.obs.loc[:,('x','y')].to_numpy()[samplenameList==s]),axis=0)\n",
    "            samplenameList_plot=np.concatenate((samplenameList_plot,np.repeat(s,muplot.shape[0])),axis=None)\n",
    "\n",
    "    sampledir=os.path.join(savepath,'combined')\n",
    "    savedir_all=os.path.join(sampledir,'embedding_'+plottype)\n",
    "    clustersavedir_all=os.path.join(sampledir,'cluster')\n",
    "    if not os.path.exists(savepath):\n",
    "        os.mkdir(savepath)\n",
    "    if not os.path.exists(sampledir):\n",
    "        os.mkdir(sampledir)\n",
    "    if not os.path.exists(savedir_all):\n",
    "        os.mkdir(savedir_all)\n",
    "    if not os.path.exists(clustersavedir_all):\n",
    "        os.mkdir(clustersavedir_all)\n",
    "    \n",
    "    for l in np.unique(labels):\n",
    "        clusteridx=(labels==l)\n",
    "#         origCT=np.unique(celltype_broad)\n",
    "#         celltypeplot=np.concatenate((origCT,list(combineCelltype.keys())),axis=None)\n",
    "        savedir=os.path.join(savedir_all,l)\n",
    "        clustersavedir=os.path.join(clustersavedir_all,l)\n",
    "        if not os.path.exists(savedir):\n",
    "            os.mkdir(savedir)\n",
    "        if not os.path.exists(clustersavedir):\n",
    "            os.mkdir(clustersavedir)\n",
    "\n",
    "        if plottype=='umap':\n",
    "            reducer = umap.UMAP(n_neighbors=n_neighbors,min_dist=min_dist,random_state=seed)\n",
    "            embedding = reducer.fit_transform(latents[clusteridx])\n",
    "            savenameAdd='_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'epoch'+str(plotepoch)\n",
    "        elif plottype=='pca':\n",
    "            embedding=pca.fit_transform(latents[clusteridx])\n",
    "            savenameAdd='_epoch'+str(plotepoch)\n",
    "#         if ifplot:\n",
    "#             plotembeddingbyCT(samplenameList[clusteridx],'sample',[],embedding,savedir,plottype+'of all samples',savenameAdd=savenameAdd)\n",
    "\n",
    "        if embedding.shape[0]<minCells_sub:\n",
    "            continue\n",
    "        if ifcluster:\n",
    "            if clustermethod=='leiden':\n",
    "                clusterLeiden_allsample(embedding,savedir,clustersavedir,latents[clusteridx],n_neighbors_sub,n_pcs_sub,min_dist_sub,resolution_sub,sobj_coord_np[clusteridx],samplenameList[clusteridx],randseed=seed)\n",
    "            elif clustermethod=='dbscan':\n",
    "                clusterDBscan_allsample(embedding,savedir,clustersavedir,latents[clusteridx],epslist_sub,min_sampleslist_sub,n_pcs_sub,sobj_coord_np[clusteridx],samplenameList[clusteridx])\n",
    "            elif clustermethod=='agglomerative':\n",
    "                clusterAgg_allsample(embedding,savedir,clustersavedir,latents[clusteridx],nclusterlist_sub,aggMetric_sub,n_pcs_sub,sobj_coord_np[clusteridx],samplenameList[clusteridx])\n",
    "            elif clustermethod=='kmeanbatch':\n",
    "                clusterMinibatchKmean_allsample(embedding,savedir,clustersavedir,latents[clusteridx],nclusterlist_sub,n_pcs_sub,sobj_coord_np[clusteridx],samplenameList[clusteridx])\n",
    "\n",
    "def subclusterLeiden(n_neighbors,n_pcs,min_dist,resolution,addname=''):\n",
    "    for r in resolution:\n",
    "        savenamecluster='leiden_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'n_pcs'+str(n_pcs)+'res'+str(r)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        labels=np.array(labels)\n",
    "        if np.unique(labels).shape[0]==1:\n",
    "            continue\n",
    "        \n",
    "        savepath=os.path.join(clustersavedir,savenamecluster+'_subcluster')\n",
    "        subcluster('leiden',labels,savepath,addname)\n",
    "\n",
    "def subclusterDBscan(epsL,min_samplesL,n_pcs,addname=''):\n",
    "    for eps in epsL:\n",
    "        for min_samples in min_samplesL:\n",
    "            savenamecluster='dbscan_eps'+str(eps)+'msamples'+str(min_samples)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "            if not os.path.exists(readpath):\n",
    "                print('DNE: '+readpath)\n",
    "                continue\n",
    "            with open(readpath, 'rb') as input:\n",
    "                labels = pickle.load(input)\n",
    "            labels=np.array(labels)\n",
    "            if np.unique(labels).shape[0]==1:\n",
    "                continue\n",
    "            \n",
    "            savepath=os.path.join(clustersavedir,savenamecluster+'_subcluster')\n",
    "            subcluster('dbscan',labels,savepath,addname)\n",
    "\n",
    "def subclusterAgg(nclusterL,aggmetricL,n_pcs,addname=''):\n",
    "    for ncluster in nclusterL:\n",
    "        for aggmetric in aggmetricL:\n",
    "            savenamecluster='agg_ncluster'+str(ncluster)+aggmetric+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "            if not os.path.exists(readpath):\n",
    "                print('DNE: '+readpath)\n",
    "                continue\n",
    "            with open(readpath, 'rb') as input:\n",
    "                labels = pickle.load(input)\n",
    "            labels=np.array(labels)\n",
    "            if np.unique(labels).shape[0]==1:\n",
    "                continue\n",
    "            savepath=os.path.join(clustersavedir,savenamecluster+'_subcluster')\n",
    "            subcluster('agglomerative',labels,savepath,addname)\n",
    "            \n",
    "def subclusterMinibatchKmean(nclusterL,n_pcs,addname=''):\n",
    "    for ncluster in nclusterL:\n",
    "        savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        labels=np.array(labels)\n",
    "        if np.unique(labels).shape[0]==1:\n",
    "            continue\n",
    "            \n",
    "        savepath=os.path.join(clustersavedir,savenamecluster+'_subcluster')\n",
    "        subcluster('kmeanbatch',labels,savepath,addname)\n",
    "        \n",
    "subclusterLeiden(n_neighbors,n_pcs,min_dist,subResolution,addname='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/external_ssd/xinyi/plots/train_gae_visium/colonk20XA_02_dca_over/combinedlogminmax_beforeAct/cluster'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustersavedir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
