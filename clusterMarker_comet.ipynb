{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compliant-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xinyiz/pamrats')\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scanpy\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import average_precision_score\n",
    "\n",
    "import gae.gae.optimizer as optimizer\n",
    "import gae.gae.model\n",
    "import gae.gae.preprocessing as preprocessing\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN,MiniBatchKMeans,AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "import anndata as ad\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prescription-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "ifplot=True\n",
    "ifcluster=True\n",
    "\n",
    "inverseAct='leakyRelu'\n",
    "# inverseAct=None\n",
    "plottype='umap'\n",
    "pca=PCA()\n",
    "minCells=15 #min number of cells for analysis\n",
    "# clustermethod=['kmeanbatch']\n",
    "clustermethod=['leiden','dbscan','agglomerative','kmeanbatch']\n",
    "#umap/leiden clustering parameters\n",
    "n_neighbors=10\n",
    "min_dist=0.25\n",
    "n_pcs=40 #for clustering\n",
    "# resolution=[0.5,1,1.5,2]\n",
    "resolution=[0.05,0.1,0.2,0.3]\n",
    "plotepoch=9990\n",
    "savenameAdd=''\n",
    "#DBscan\n",
    "epslist= [6,8,10]\n",
    "min_sampleslist=[15,30,45] \n",
    "#agglomerative\n",
    "nclusterlist=[2,3,4,5,8,10]\n",
    "aggMetric=['euclidean']\n",
    "\n",
    "\n",
    "combineCelltype={'glia':['Astro','Micro', 'OPC', 'Oligo'],'CA':['CA1', 'CA2', 'CA3']}\n",
    "\n",
    "use_cuda=True\n",
    "fastmode=False #Validate during training pass\n",
    "seed=3\n",
    "useSavedMaskedEdges=False\n",
    "maskedgeName='knn20_connectivity'\n",
    "hidden1=1024 #Number of units in hidden layer 1\n",
    "hidden2=1024 #Number of units in hidden layer 2\n",
    "# hidden3=16\n",
    "fc_dim1=1024\n",
    "# fc_dim2=2112\n",
    "# fc_dim3=2112\n",
    "# fc_dim4=2112\n",
    "# gcn_dim1=2048\n",
    "\n",
    "protein=None #'scaled_binary'\n",
    "# proteinWeights=0.05\n",
    "dropout=0.01\n",
    "# randFeatureSubset=None\n",
    "model_str='gcn_vae_xa_e2_d1_dca'\n",
    "adj_decodeName=None #gala or None\n",
    "plot_samples={'disease13':'AD_mouse9494','control13':'AD_mouse9498','disease8':'AD_mouse9723','control8':'AD_mouse9735'}\n",
    "plot_sample_X=['logminmax']\n",
    "# plot_sample_X=['corrected','scaled']\n",
    "standardizeX=False\n",
    "name='allk20XA_01_dca'\n",
    "logsavepath='/mnt/xinyi/pamrats/log/train_gae_starmap/'+name\n",
    "modelsavepath='/mnt/xinyi/pamrats/models/train_gae_starmap/'+name\n",
    "plotsavepath='/mnt/xinyi/pamrats/plots/train_gae_starmap/'+name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "planned-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cuda and seed\n",
    "np.random.seed(seed)\n",
    "if use_cuda and (not torch.cuda.is_available()):\n",
    "    print('cuda not available')\n",
    "    use_cuda=False\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cooperative-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "savedir=os.path.join('/mnt/xinyi/','starmap')\n",
    "adj_dir=os.path.join(savedir,'a')\n",
    "\n",
    "featureslist={}\n",
    "if plot_sample_X[0] in ['corrected','scaled']:\n",
    "    scaleddata=scanpy.read_h5ad('/mnt/xinyi/2021-01-13-mAD-test-dataset/2020-12-27-starmap-mAD-scaled.h5ad')\n",
    "    \n",
    "    for s in plot_samples.keys():\n",
    "        featureslist[s+'X_'+'corrected']=torch.tensor(scaleddata.layers['corrected'][scaleddata.obs['sample']==plot_samples[s]])\n",
    "        featureslist[s+'X_'+'scaled']=torch.tensor(scaleddata.layers['scaled'][scaleddata.obs['sample']==plot_samples[s]])\n",
    "    \n",
    "else:\n",
    "    scaleddata=scanpy.read_h5ad('/mnt/xinyi/2021-01-13-mAD-test-dataset/2020-12-27-starmap-mAD-raw.h5ad')\n",
    "    \n",
    "    for s in plot_samples.keys():\n",
    "        scaleddata_train=scaleddata.X[scaleddata.obs['sample']==plot_samples[s]]\n",
    "\n",
    "        if plot_sample_X[0]=='logminmax':\n",
    "            featurelog_train=np.log2(scaleddata_train+1/2)\n",
    "            scaler = MinMaxScaler()\n",
    "            featurelog_train_minmax=np.transpose(scaler.fit_transform(np.transpose(featurelog_train)))\n",
    "            featureslist[s+'X_'+plot_sample_X[0]]=torch.tensor(featurelog_train_minmax)\n",
    "\n",
    "if protein: ##adjust for scaled/corrected\n",
    "    proteinsavepath=os.path.join('/mnt/xinyi/','starmap','protein')\n",
    "    for s in plot_samples.keys():\n",
    "        pmtx=sp.load_npz(os.path.join(proteinsavepath,plot_samples[s]+'_'+protein+'.npz'))\n",
    "        pmtx=preprocessing.sparse_mx_to_torch_sparse_tensor(pmtx)\n",
    "        pmtx=pmtx.to_dense()\n",
    "        scalefactor=torch.sum(featureslist[s+'X_'+plot_sample_X[0]])/torch.sum(pmtx)*proteinWeights\n",
    "        featureslist[s+'X_'+plot_sample_X[0]]=torch.cat((featureslist[s+'X_'+plot_sample_X[0]],pmtx*scalefactor),dim=1)\n",
    "\n",
    "adj_list={}\n",
    "adj_list['disease13']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9494.npz'))\n",
    "adj_list['control13']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9498.npz'))\n",
    "adj_list['disease8']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9723.npz'))\n",
    "adj_list['control8']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9735.npz'))\n",
    "\n",
    "feature_names=scaleddata.var.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grateful-farming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "num_nodes,num_features = list(featureslist.values())[0].shape\n",
    "if model_str=='gcn_vae_xa':\n",
    "    model  = gae.gae.model.GCNModelVAE_XA(num_features, hidden1, hidden2,fc_dim1,fc_dim2,fc_dim3,fc_dim4, dropout)\n",
    "elif model_str=='fc1':\n",
    "    model  = gae.gae.model.FCVAE1(num_features, hidden1,dropout)\n",
    "elif model_str == 'gcn_vae_xa_e2_d1':\n",
    "    model  = gae.gae.model.GCNModelVAE_XA_e2_d1(num_features, hidden1,hidden2, dropout)\n",
    "elif model_str == 'gcn_vae_gcnX_inprA':\n",
    "    model = gae.gae.model.GCNModelVAE_gcnX_inprA(num_features, hidden1, hidden2,gcn_dim1, dropout)\n",
    "elif model_str=='fc1_dca':\n",
    "    model = gae.gae.model.FCVAE1_DCA(num_features, hidden1,fc_dim1, dropout)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dca':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaFork':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCAfork(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaElemPi':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCAelemPi(num_features, hidden1,hidden2,fc_dim1, dropout,shareGenePi)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaConstantDisp':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA_constantDisp(num_features, hidden1,hidden2,fc_dim1, dropout,shareGenePi)\n",
    "else:\n",
    "    print('model not found')\n",
    "model.load_state_dict(torch.load(os.path.join(modelsavepath,str(plotepoch)+'.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "essential-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "def inverseLeakyRelu(v,slope=0.01):\n",
    "    vnegidx=(v<0)\n",
    "    v[vnegidx]=1/slope*v[vnegidx]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d465aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMinibatchKmean(nclusterL,n_pcs):\n",
    "    for ncluster in nclusterL:\n",
    "        savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        res=np.reshape(labels,(-1,1))\n",
    "        res=np.hstack((np.reshape(cellidx,(-1,1)),res))\n",
    "        np.savetxt(os.path.join(cometsavedir,savenamecluster+'.txt'),res,delimiter='\\t',fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exact-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute embeddings\n",
    "mulist={}\n",
    "for s in plot_samples.keys():\n",
    "    adj=adj_list[s]\n",
    "    adj_norm = preprocessing.preprocess_graph(adj)\n",
    "    adj_decode=None\n",
    "    if adj_decodeName == 'gala':\n",
    "        adj_decode=preprocessing.preprocess_graph_sharp(adj)\n",
    "    for xcorr in plot_sample_X:\n",
    "        samplename=s+'X_'+xcorr\n",
    "        features=featureslist[samplename]\n",
    "        if standardizeX:\n",
    "            features=torch.tensor(scale(features,axis=0, with_mean=True, with_std=True, copy=True))\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "            features = features.cuda().float()\n",
    "            adj_norm=adj_norm.cuda()\n",
    "            if adj_decodeName:\n",
    "                adj_decode=adj_decode.cuda()\n",
    "        \n",
    "        model.eval()\n",
    "        if adj_decodeName==None:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm)\n",
    "        else:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm,adj_decode)\n",
    "        if inverseAct=='leakyRelu':\n",
    "            muplot=inverseLeakyRelu(mu.cpu().detach().numpy())\n",
    "        else:\n",
    "            muplot=mu.cpu().detach().numpy()\n",
    "        mulist[samplename]=muplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rising-session",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease13\n",
      "Cortex\n",
      "Ex\n",
      "Hippocampus\n",
      "CA1\n",
      "DG\n",
      "Micro\n",
      "White Matter\n",
      "control13\n",
      "Cortex\n",
      "Ex\n",
      "Hippocampus\n",
      "CA1\n",
      "DG\n",
      "Micro\n",
      "White Matter\n",
      "disease8\n",
      "Cortex\n",
      "Ex\n",
      "Hippocampus\n",
      "CA1\n",
      "DG\n",
      "Micro\n",
      "White Matter\n",
      "control8\n",
      "Cortex\n",
      "Ex\n",
      "Hippocampus\n",
      "CA1\n",
      "DG\n",
      "Micro\n",
      "White Matter\n"
     ]
    }
   ],
   "source": [
    "plot_samples={'disease13':'AD_mouse9494','control13':'AD_mouse9498','disease8':'AD_mouse9723','control8':'AD_mouse9735'}\n",
    "\n",
    "ifcluster=True\n",
    "# separate plots by region and cell types\n",
    "np.random.seed(seed)\n",
    "for s in plot_samples.keys():\n",
    "#     if s in ['disease13']:\n",
    "#         continue\n",
    "    print(s)\n",
    "    sampleidx=plot_samples[s]\n",
    "    celltype_broad=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']\n",
    "    celltype_sub=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'cell_type_label']\n",
    "    region=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']\n",
    "    sobj_coord_np=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,['x','y']].to_numpy()\n",
    "    \n",
    "    origCT=np.unique(celltype_broad)\n",
    "    celltypeplot=np.concatenate((origCT,list(combineCelltype.keys())),axis=None)\n",
    "    for xcorr in plot_sample_X:\n",
    "        samplename=s+'X_'+xcorr\n",
    "        muplot=np.copy(mulist[samplename])\n",
    "        featureDE=np.copy(featureslist[samplename])*1000\n",
    "\n",
    "        if inverseAct:\n",
    "            samplename+='_beforeAct'\n",
    "        sampledir=os.path.join(plotsavepath,samplename)\n",
    "        if not os.path.exists(sampledir):\n",
    "            os.mkdir(sampledir)\n",
    "            \n",
    "        for r in np.unique(region):\n",
    "            print(r)\n",
    "            ridx=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']==r\n",
    "            for reg in celltypeplot:\n",
    "                if not ((r=='Cortex' and reg in ['Ex']) or (r=='Hippocampus' and reg in ['CA1','DG','Micro'])):\n",
    "                    continue\n",
    "#                 if not (r=='Hippocampus' and reg in ['CA']):\n",
    "#                     continue\n",
    "#                 if s=='disease8' and r=='Cortex' and (reg in ['Astro','CA1','CA2','CA3','DG','Endo','Ex','Inhi','LHb','Micro','OPC','Oligo','SMC']):\n",
    "#                     continue\n",
    "                print(reg)\n",
    "                clustersavedir=os.path.join(plotsavepath,samplename,'cluster'+'_'+reg,r)\n",
    "                cometsavedir=os.path.join(clustersavedir,'cometMarker')\n",
    "                if not os.path.exists(cometsavedir):\n",
    "                    os.mkdir(cometsavedir)\n",
    "\n",
    "                if reg in origCT:\n",
    "                    ct_idx=celltype_broad==reg\n",
    "                else:\n",
    "                    ct_idx=False\n",
    "                    for i in combineCelltype[reg]:\n",
    "                        ct_idx=np.logical_or(ct_idx,celltype_broad==i)\n",
    "                \n",
    "                reg_idx=np.logical_and(ridx,ct_idx)\n",
    "                if np.sum(reg_idx)<=3:\n",
    "                    print('skipped')\n",
    "                    continue\n",
    "                \n",
    "                if plottype=='umap':\n",
    "                    reducer = umap.UMAP(n_neighbors=n_neighbors,min_dist=min_dist,random_state=seed)\n",
    "                    embedding = reducer.fit_transform(muplot[reg_idx])\n",
    "                    savenameAdd='_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'epoch'+str(plotepoch)\n",
    "                elif plottype=='pca':\n",
    "                    embedding=pca.fit_transform(muplot[reg_idx])\n",
    "                    savenameAdd='_epoch'+str(plotepoch)\n",
    "                cellidx=np.core.defchararray.add('cell',np.arange(np.sum(reg_idx),dtype='int').astype(str))\n",
    "                embeddingsave=np.reshape(embedding,(-1,2))\n",
    "                embeddingsave=np.hstack((np.reshape(cellidx,(-1,1)),embeddingsave))\n",
    "                np.savetxt(os.path.join(cometsavedir,'umapCoord'+savenameAdd+'.txt'),embeddingsave,delimiter='\\t',fmt=\"%s\")\n",
    "                \n",
    "                featuresave=np.transpose(featureDE[reg_idx])\n",
    "                featuresave=np.hstack((np.reshape(feature_names,(-1,1)),featuresave))\n",
    "                featuresave=np.vstack((np.concatenate(([''],cellidx)),featuresave))\n",
    "                featuresave=featuresave.astype(str)\n",
    "                np.savetxt(os.path.join(cometsavedir,'features1000'+'.txt'),featuresave,delimiter='\\t',fmt=\"%s\")\n",
    "                if embedding.shape[0]<minCells:\n",
    "                    continue\n",
    "                if ifcluster:\n",
    "#                     if 'leiden' in clustermethod:\n",
    "#                         clusterLeiden(muplot[reg_idx],n_neighbors,n_pcs,min_dist,resolution,sobj_coord_np[reg_idx],randseed=seed)\n",
    "#                         assert np.sum(muplot-np.copy(mulist[s+'X_'+xcorr]))==0\n",
    "#                     if 'dbscan' in clustermethod:\n",
    "#                         readDBscan(epslist,min_sampleslist,n_pcs)\n",
    "#                     if 'agglomerative' in clustermethod:\n",
    "#                         clusterAgg(muplot[reg_idx],nclusterlist,aggMetric,n_pcs,sobj_coord_np[reg_idx])\n",
    "#                         assert np.sum(muplot-np.copy(mulist[s+'X_'+xcorr]))==0\n",
    "                    if 'kmeanbatch' in clustermethod:\n",
    "                        readMinibatchKmean(nclusterlist,n_pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4638e87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cell0', 'cell1', 'cell2'], dtype='<U25')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.core.defchararray.add('cell',np.arange(3,dtype='int').astype(str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
