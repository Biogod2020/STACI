{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xinyiz/pamrats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is adapted from https://github.com/tkipf/gae/blob/master/gae/train.py and https://github.com/tkipf/pygcn/blob/master/pygcn/train.py##\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Train on CPU (hide GPU) due to memory constraints\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import average_precision_score\n",
    "\n",
    "import gae.gae.optimizer as optimizer\n",
    "import gae.gae.model\n",
    "import gae.gae.preprocessing as preprocessing\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "use_cuda=True\n",
    "fastmode=False #Validate during training pass\n",
    "seed=3\n",
    "useSavedMaskedEdges=True\n",
    "maskedgeName='knn20_connectivity'\n",
    "epochs=10000\n",
    "saveFreq=10\n",
    "lr=0.001 #initial learning rate\n",
    "lr_adv=0.001\n",
    "weight_decay=0 #Weight for L2 loss on embedding matrix.\n",
    "\n",
    "hidden1=4096 #Number of units in hidden layer 1\n",
    "hidden2=4096 #Number of units in hidden layer 2\n",
    "# hidden3=2048\n",
    "# hidden4=2048\n",
    "# hidden5=128\n",
    "fc_dim1=4096\n",
    "# fc_dim2=128\n",
    "# fc_dim3=128\n",
    "# fc_dim4=128\n",
    "# gcn_dim1=2600\n",
    "# clf_hidden=256\n",
    "adv_hidden=128\n",
    "\n",
    "dropout=0.01\n",
    "testNodes=0.1 #fraction of total nodes for testing\n",
    "valNodes=0.05 #fraction of total nodes for validation\n",
    "XreconWeight=20\n",
    "# clfweight=20\n",
    "advWeight=2\n",
    "# randFeatureSubset=None\n",
    "model_str='gcn_vae_xa_e2_d1_dca'\n",
    "clf=None\n",
    "adv=None #'clf_fc1_control_eq' #'clf_fc1'\n",
    "protein=None #'scaled_binary'\n",
    "proteinWeights=0.05\n",
    "adj_decodeName=None #gala or None\n",
    "ridgeL=0.01\n",
    "shareGenePi=True\n",
    "\n",
    "pretrainedAE=None #{'name':'controlphy5XAbin_01_dca','epoch':9990}\n",
    "num_features=2112\n",
    "# training_samples=['control13','disease13','disease8']###rename and retrain C8\n",
    "training_samples=['control13','disease13','disease8','control8']\n",
    "# training_samples=['control13','control8']\n",
    "targetBatch=None #'control13'\n",
    "training_sample_X='logminmax'\n",
    "switchFreq=100\n",
    "standardizeX=False\n",
    "# name='allk20XA_01_dca_noD8' ###rename and retrain D8 C8\n",
    "name='allk20XA_01_dca_over'\n",
    "logsavepath='/mnt/xinyi/pamrats/log/train_gae_starmap/'+name\n",
    "modelsavepath='/mnt/xinyi/pamrats/models/train_gae_starmap/'+name\n",
    "plotsavepath='/mnt/xinyi/pamrats/plots/train_gae_starmap/'+name\n",
    "\n",
    "#Load data\n",
    "sampleidx={'disease13':'AD_mouse9494','control13':'AD_mouse9498','disease8':'AD_mouse9723','control8':'AD_mouse9735'}\n",
    "savedir=os.path.join('/mnt/xinyi/','starmap')\n",
    "adj_dir=os.path.join(savedir,'a')\n",
    "\n",
    "featureslist={}\n",
    "if training_sample_X in ['corrected','scaled']:\n",
    "    scaleddata=scanpy.read_h5ad('/mnt/xinyi/2021-01-13-mAD-test-dataset/2020-12-27-starmap-mAD-scaled.h5ad')\n",
    "    \n",
    "    for s in sampleidx.keys():\n",
    "        featureslist[s+'X_'+'corrected']=torch.tensor(scaleddata.layers['corrected'][scaleddata.obs['sample']==sampleidx[s]])\n",
    "        featureslist[s+'X_'+'scaled']=torch.tensor(scaleddata.layers['scaled'][scaleddata.obs['sample']==sampleidx[s]])\n",
    "\n",
    "else:\n",
    "    scaleddata=scanpy.read_h5ad('/mnt/xinyi/2021-01-13-mAD-test-dataset/2020-12-27-starmap-mAD-raw.h5ad')\n",
    "    \n",
    "    for s in sampleidx.keys():\n",
    "        scaleddata_train=scaleddata.X[scaleddata.obs['sample']==sampleidx[s]]\n",
    "\n",
    "        if training_sample_X=='logminmax':\n",
    "            featurelog_train=np.log2(scaleddata_train+1/2)\n",
    "            scaler = MinMaxScaler()\n",
    "            featurelog_train_minmax=np.transpose(scaler.fit_transform(np.transpose(featurelog_train)))\n",
    "            featureslist[s+'X_'+training_sample_X]=torch.tensor(featurelog_train_minmax)\n",
    "        elif training_sample_X=='logminmax10':\n",
    "            featurelog_train=np.log2(scaleddata_train+1/2)\n",
    "            scaler = MinMaxScaler(feature_range=(0,10))\n",
    "            featurelog_train_minmax=np.transpose(scaler.fit_transform(np.transpose(featurelog_train)))\n",
    "            featureslist[s+'X_'+training_sample_X]=torch.tensor(featurelog_train_minmax)\n",
    "\n",
    "if protein:\n",
    "    proteinsavepath=os.path.join('/mnt/xinyi/','starmap','protein')\n",
    "    for s in sampleidx.keys():\n",
    "        pmtx=sp.load_npz(os.path.join(proteinsavepath,sampleidx[s]+'_'+protein+'.npz'))\n",
    "        pmtx=preprocessing.sparse_mx_to_torch_sparse_tensor(pmtx)\n",
    "        pmtx=pmtx.to_dense()\n",
    "        scalefactor=torch.sum(featureslist[s+'X_'+training_sample_X])/torch.sum(pmtx)*proteinWeights\n",
    "        featureslist[s+'X_'+training_sample_X]=torch.cat((featureslist[s+'X_'+training_sample_X],pmtx*scalefactor),dim=1)\n",
    "            \n",
    "if clf:\n",
    "    ctlist={}\n",
    "    ctlist['disease13']=scaleddata.obs.loc[scaleddata.obs['sample']=='AD_mouse9494','top_level'].to_numpy()\n",
    "    ctlist['control13']=scaleddata.obs.loc[scaleddata.obs['sample']=='AD_mouse9498','top_level'].to_numpy()\n",
    "    ctlist['disease8']=scaleddata.obs.loc[scaleddata.obs['sample']=='AD_mouse9723','top_level'].to_numpy()\n",
    "    ctlist['control8']=scaleddata.obs.loc[scaleddata.obs['sample']=='AD_mouse9735','top_level'].to_numpy()\n",
    "    ct_unique=np.unique(scaleddata.obs.loc[scaleddata.obs['sample']=='AD_mouse9735','top_level'])\n",
    "    for k in ctlist.keys():\n",
    "        for i in range(ct_unique.size):\n",
    "            ctlist[k][ctlist[k]==ct_unique[i]]=i\n",
    "    \n",
    "adj_list={}\n",
    "adj_list['disease13']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9494.npz'))\n",
    "adj_list['control13']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9498.npz'))\n",
    "adj_list['disease8']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9723.npz'))\n",
    "adj_list['control8']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9735.npz'))\n",
    "\n",
    "adjnormlist={}\n",
    "pos_weightlist={}\n",
    "normlist={}\n",
    "for ai in adj_list.keys():\n",
    "    adjnormlist[ai]=preprocessing.preprocess_graph(adj_list[ai])\n",
    "    \n",
    "    pos_weightlist[ai] = torch.tensor(float(adj_list[ai].shape[0] * adj_list[ai].shape[0] - adj_list[ai].sum()) / adj_list[ai].sum()) #using full unmasked adj\n",
    "    normlist[ai] = adj_list[ai].shape[0] * adj_list[ai].shape[0] / float((adj_list[ai].shape[0] * adj_list[ai].shape[0] - adj_list[ai].sum()) * 2)\n",
    "    \n",
    "    adj_label=adj_list[ai] + sp.eye(adj_list[ai].shape[0])\n",
    "    adj_list[ai]=torch.tensor(adj_label.todense())\n",
    "    \n",
    "if adv:\n",
    "    if 'control_eq' in adv:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['control13']=torch.tensor([0.5,0.5]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([0.5,0.5]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['control13']=torch.tensor([1,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,1]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "    elif 'control' in adv:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['control13']=torch.tensor([0,1]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([1,0]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['control13']=torch.tensor([1,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,1]).expand(adjnormlist['control8'].shape[0],-1)        \n",
    "    else:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['disease13']=torch.tensor([0,1,1,1]).expand(adjnormlist['disease13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control13']=torch.tensor([1,0,1,1]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['disease8']=torch.tensor([1,1,0,1]).expand(adjnormlist['disease8'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([1,1,1,0]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['disease13']=torch.tensor([1,0,0,0]).expand(adjnormlist['disease13'].shape[0],-1)\n",
    "        sampleLabellist_d['control13']=torch.tensor([0,1,0,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['disease8']=torch.tensor([0,0,1,0]).expand(adjnormlist['disease8'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,0,0,1]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "# adj_decode=None\n",
    "# if adj_decodeName == 'gala':\n",
    "#     adj_decode=preprocessing.preprocess_graph_sharp(adj_train)\n",
    "\n",
    "\n",
    "\n",
    "if 'dca' in model_str:\n",
    "    rawdata=scanpy.read_h5ad('/mnt/xinyi/2021-01-13-mAD-test-dataset/2020-12-27-starmap-mAD-raw.h5ad')\n",
    "    features_raw_list={}\n",
    "    for s in sampleidx.keys():\n",
    "#         features_raw_list[s+'X_'+'raw']=torch.tensor(rawdata.X[rawdata.obs['sample']==sampleidx[s]]).cuda()\n",
    "        features_raw_list[s+'X_'+'raw']=torch.tensor(rawdata.X[rawdata.obs['sample']==sampleidx[s]])\n",
    "        if protein:\n",
    "            proteinsavepath=os.path.join('/mnt/xinyi/','starmap','protein')\n",
    "            pmtx=sp.load_npz(os.path.join(proteinsavepath,sampleidx[s]+'_'+protein+'.npz'))\n",
    "            pmtx=preprocessing.sparse_mx_to_torch_sparse_tensor(pmtx)\n",
    "            pmtx=pmtx.to_dense()\n",
    "            scalefactor=torch.sum(features_raw_list[s+'X_raw'])/torch.sum(pmtx)*proteinWeights\n",
    "            features_raw_list[s+'X_raw']=torch.cat((features_raw_list[s+'X_raw'],pmtx*scalefactor),dim=1)\n",
    "\n",
    "if clf:\n",
    "    ct_train=ctlist[training_samples].astype(int)\n",
    "# features=torch.tensor(np.identity(7000)).float()\n",
    "# features=features[0:10,:]\n",
    "if standardizeX:\n",
    "    features=torch.tensor(scale(features,axis=0, with_mean=True, with_std=True, copy=True))\n",
    "\n",
    "# Set cuda and seed\n",
    "np.random.seed(seed)\n",
    "if use_cuda and (not torch.cuda.is_available()):\n",
    "    print('cuda not available')\n",
    "    use_cuda=False\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "# Load data\n",
    "# if randFeatureSubset != None:\n",
    "#     idx=np.random.choice(features.shape[1],randFeatureSubset,replace=False)\n",
    "#     features=features[:,idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(logsavepath):\n",
    "    os.mkdir(logsavepath)\n",
    "if not os.path.exists(modelsavepath):\n",
    "    os.mkdir(modelsavepath)\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all train/validation sets\n",
    "\n",
    "mse=torch.nn.MSELoss()\n",
    "# mse=torch.nn.MSELoss(reduction=None)\n",
    "# Create model\n",
    "if model_str=='gcn_vae_xa':\n",
    "    model = gae.gae.model.GCNModelVAE_XA(num_features, hidden1, hidden2,fc_dim1,fc_dim2,fc_dim3,fc_dim4, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "elif model_str == 'gcn_vae_gcnX_inprA':\n",
    "    model = gae.gae.model.GCNModelVAE_gcnX_inprA(num_features, hidden1, hidden2,gcn_dim1, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "    \n",
    "elif model_str == 'gcn_vae_gcnX_inprA_w':\n",
    "    model = gae.gae.model.GCNModelVAE_gcnX_inprA_w(num_features, hidden1, hidden2,gcn_dim1, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "    loss_a=optimizer.optimizer_CE    \n",
    "    \n",
    "elif model_str=='gcn_vae_xa_e3':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e3(num_features, hidden1, hidden2,hidden3,fc_dim1,fc_dim2,fc_dim3,fc_dim4, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "    \n",
    "elif model_str == 'gcn_vae_xa_e1':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e1(num_features, hidden1, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "\n",
    "elif model_str == 'gcn_vae_xa_e2_d1':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1(num_features, hidden1,hidden2, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "    \n",
    "elif model_str=='gcn_vae_xa_e2_d1_dca':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_zinb\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "    \n",
    "elif model_str=='gcn_vae_xa_e2_d1_dca_fca':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA_fca(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_zinb\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaFork':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCAfork(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_zinb\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaElemPi':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCAelemPi(num_features, hidden1,hidden2,fc_dim1, dropout,shareGenePi)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_zinb\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaConstantDisp':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA_constantDisp(num_features, hidden1,hidden2,fc_dim1, dropout,shareGenePi)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_zinb\n",
    "    loss_a=optimizer.optimizer_CE    \n",
    "    \n",
    "elif model_str == 'gcn_vae_xa_e4_d1':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e4_d1(num_features, hidden1,hidden2,hidden3,hidden4, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "    loss_a=optimizer.optimizer_CE    \n",
    "    \n",
    "elif model_str=='fc':\n",
    "    model = gae.gae.model.FCVAE(num_features, hidden1, hidden2,hidden3,hidden4,hidden5,fc_dim1,fc_dim2,fc_dim3,fc_dim4, dropout)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "#     loss_x=mse\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "elif model_str=='fcae':\n",
    "    model = gae.gae.model.FCAE(num_features, hidden1, hidden2,hidden3,hidden4,hidden5,fc_dim1,fc_dim2,fc_dim3,fc_dim4, dropout)\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "#     loss_x=mse\n",
    "\n",
    "elif model_str=='fcae1':\n",
    "    model = gae.gae.model.FCAE1(num_features, dropout,hidden1)\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "#     loss_x=mse\n",
    "elif model_str=='fcae2':\n",
    "    model = gae.gae.model.FCAE2(num_features, dropout,hidden1,hidden2)\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "\n",
    "elif model_str=='fc1':\n",
    "    model = gae.gae.model.FCVAE1(num_features, hidden1,dropout)\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "\n",
    "elif model_str=='fc1_fca':\n",
    "    model = gae.gae.model.FCVAE1_fca(num_features, hidden1,dropout)\n",
    "    loss_x=optimizer.optimizer_MSE\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "    \n",
    "elif model_str=='fc1_dca':\n",
    "    model = gae.gae.model.FCVAE1_DCA(num_features, hidden1,fc_dim1, dropout)\n",
    "    loss_x=optimizer.optimizer_zinb\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_a=optimizer.optimizer_CE\n",
    "\n",
    "if clf=='clf_fc1':\n",
    "    modelClf=gae.gae.model.Clf_fc1(hidden2, dropout,clf_hidden,ct_unique.size)\n",
    "    loss_clf=torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "if adv=='clf_fc1' or adv=='clf_fc1_control' or adv=='clf_fc1_control_eq':\n",
    "    modelAdv=gae.gae.model.Clf_fc1(hidden2, dropout,adv_hidden,sampleLabellist_ae['control13'].size()[1])\n",
    "    loss_adv=optimizer.optimizer_CEclf\n",
    "    \n",
    "\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    if clf:\n",
    "        modelClf.cuda()\n",
    "        ct_train=torch.tensor(ct_train).cuda()\n",
    "    if adv:\n",
    "        modelAdv.cuda()\n",
    "#         for sk in sampleLabellist_ae.keys():\n",
    "#             sampleLabellist_ae[sk]=sampleLabellist_ae[sk].cuda().float()\n",
    "#             sampleLabellist_d[sk]=sampleLabellist_d[sk].cuda().float()\n",
    "#     for fk in featureslist.keys():\n",
    "#         featureslist[fk] = featureslist[fk].cuda().float()\n",
    "#     for ak in adj_list.keys():\n",
    "#         adjnormlist[ak] =adjnormlist[ak].cuda()\n",
    "#         adj_list[ak] = adj_list[ak].cuda().float()\n",
    "#     if adj_decode is not None:\n",
    "#         adj_decode=adj_decode.cuda()\n",
    "    \n",
    "\n",
    "optimizerVAEXA = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "if clf:\n",
    "    optimizerClf=optim.Adam(modelClf.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "if adv:\n",
    "    optimizerAdv=optim.Adam(modelAdv.parameters(), lr=lr_adv, weight_decay=weight_decay)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease13\n",
      "control13\n",
      "disease8\n",
      "control8\n"
     ]
    }
   ],
   "source": [
    "testepoch=9360\n",
    "model.load_state_dict(torch.load(os.path.join(modelsavepath,str(testepoch)+'.pt')))\n",
    "model.eval()\n",
    "for s in sampleidx.keys():\n",
    "    print(s)\n",
    "    celltype_broad=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx[s],'top_level']\n",
    "    \n",
    "    adj_norm=adjnormlist[s].cuda().float()\n",
    "    adj_label=adj_list[s].cuda().float()\n",
    "    features=featureslist[s+'X_'+training_sample_X].cuda().float()\n",
    "    pos_weight=pos_weightlist[s]\n",
    "    norm=normlist[s]\n",
    "    \n",
    "    if 'dca' in model_str:\n",
    "        features_raw=features_raw_list[s+'X_raw'].cuda()\n",
    "    num_nodes,num_features = features.shape\n",
    "        \n",
    "#     adj_decode=None\n",
    "#     if adj_decodeName == 'gala':\n",
    "#         adj_decode=preprocessing.preprocess_graph_sharp(adj)\n",
    "    xloss=[]\n",
    "    aloss=[]\n",
    "    for ct in np.unique(celltype_broad):    \n",
    "        if adj_decodeName==None:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm)\n",
    "        else:\n",
    "            adj_decode=adj_decode.cuda()\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm,adj_decode)\n",
    "        \n",
    "        ct_idx=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx[s],'top_level']==ct\n",
    "#         test_nodes_idx_s=np.arange(np.sum(ct_idx))\n",
    "    \n",
    "        if 'dca' in model_str:\n",
    "            loss_x_test=loss_x(features_recon, features,ct_idx,XreconWeight,ridgeL,features_raw)\n",
    "        else:\n",
    "            loss_x_test=loss_x(features_recon, features,ct_idx,XreconWeight,mse)\n",
    "        features_recon=None\n",
    "        torch.cuda.empty_cache()\n",
    "        loss_a_test=loss_a(adj_recon[ct_idx], adj_label[ct_idx], pos_weight, norm)\n",
    "        xloss.append(loss_x_test.item())\n",
    "        aloss.append(loss_a_test.item())\n",
    "        adj_recon=None\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    xloss=np.array(xloss)/np.sum(xloss)\n",
    "    aloss=np.array(aloss)/np.sum(aloss)\n",
    "    \n",
    "    x_pos = np.arange(np.unique(celltype_broad).size)\n",
    "\n",
    "    plt.bar(x_pos, xloss)\n",
    "    plt.title(\"%loss of each cell type\")\n",
    "    plt.xticks(x_pos, np.unique(celltype_broad))\n",
    "    plt.savefig(os.path.join(plotsavepath,'loss_x_byCT.jpg'))\n",
    "    plt.close()\n",
    "    \n",
    "    plt.bar(x_pos, aloss)\n",
    "    plt.title(\"%loss of each cell type\")\n",
    "    plt.xticks(x_pos, np.unique(celltype_broad))\n",
    "    plt.savefig(os.path.join(plotsavepath,'loss_a_byCT.jpg'))\n",
    "    plt.close()\n",
    "    if 'dca' in model_str:\n",
    "        features_raw=features_raw.cpu()\n",
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
