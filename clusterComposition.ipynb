{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e8e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xinyiz/pamrats')\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "import gae.gae.optimizer as optimizer\n",
    "import gae.gae.model\n",
    "import gae.gae.preprocessing as preprocessing\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN,MiniBatchKMeans,AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86612b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "ifplot=True\n",
    "ifcluster=True\n",
    "byCT=False\n",
    "\n",
    "logitL1=0.5 #smaller is sparser\n",
    "geneThresh=2.5 #times std above mean\n",
    "\n",
    "inverseAct='leakyRelu'\n",
    "# inverseAct=None\n",
    "plottype='umap'\n",
    "pca=PCA()\n",
    "minCells=15 #min number of cells for analysis\n",
    "minCell_clusterDE=5\n",
    "# clustermethod=['leiden']\n",
    "clustermethod=['leiden','agglomerative','kmeanbatch']\n",
    "#umap/leiden clustering parameters\n",
    "n_neighbors=10\n",
    "min_dist=0.25\n",
    "n_pcs=40 #for clustering\n",
    "# resolution=[0.5,0.8,1,1.5]\n",
    "resolution=[0.05,0.1,0.2,0.3,0.5,0.8,1,1.5]\n",
    "plotepoch=9990\n",
    "savenameAdd=''\n",
    "#DBscan\n",
    "epslist= [6,8,10]\n",
    "min_sampleslist=[15,30,45] \n",
    "#agglomerative\n",
    "nclusterlist=[2,3,4,5,8,10,15]\n",
    "aggMetric=['euclidean']\n",
    "\n",
    "\n",
    "combineCelltype={'glia':['Astro','Micro', 'OPC', 'Oligo'],'CA':['CA1', 'CA2', 'CA3']}\n",
    "\n",
    "use_cuda=True\n",
    "fastmode=False #Validate during training pass\n",
    "seed=3\n",
    "\n",
    "protein=None #'scaled_binary'\n",
    "# proteinWeights=0.05\n",
    "# randFeatureSubset=None\n",
    "plot_samples={'disease13':'AD_mouse9494','control13':'AD_mouse9498','disease8':'AD_mouse9723','control8':'AD_mouse9735'}\n",
    "plot_sample_X=['logminmax']\n",
    "plotRecon='' #'meanRecon'\n",
    "# plot_sample_X=['corrected','scaled']\n",
    "standardizeX=False\n",
    "name='allk20XA_05_dca_over'\n",
    "logsavepath='/mnt/external_ssd/xinyi/log/train_gae_starmap/'+name\n",
    "modelsavepath='/mnt/external_ssd/xinyi/models/train_gae_starmap/'+name\n",
    "plotsavepath='/mnt/external_ssd/xinyi/plots/train_gae_starmap/'+name\n",
    "datadir='/home/xinyiz/2021-01-13-mAD-test-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1261fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cuda and seed\n",
    "np.random.seed(seed)\n",
    "if use_cuda and (not torch.cuda.is_available()):\n",
    "    print('cuda not available')\n",
    "    use_cuda=False\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbc6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "savedir=os.path.join('/mnt/xinyi/','starmap')\n",
    "adj_dir=os.path.join(savedir,'a')\n",
    "\n",
    "featureslist={}\n",
    "if plot_sample_X[0] in ['corrected','scaled']:\n",
    "    scaleddata=scanpy.read_h5ad(datadir+'/2020-12-27-starmap-mAD-scaled.h5ad')\n",
    "    \n",
    "    for s in plot_samples.keys():\n",
    "        featureslist[s+'X_'+'corrected']=torch.tensor(scaleddata.layers['corrected'][scaleddata.obs['sample']==plot_samples[s]])\n",
    "        featureslist[s+'X_'+'scaled']=torch.tensor(scaleddata.layers['scaled'][scaleddata.obs['sample']==plot_samples[s]])\n",
    "    \n",
    "else:\n",
    "    scaleddata=scanpy.read_h5ad(datadir+'/2020-12-27-starmap-mAD-raw.h5ad')\n",
    "    \n",
    "    for s in plot_samples.keys():\n",
    "        scaleddata_train=scaleddata.X[scaleddata.obs['sample']==plot_samples[s]]\n",
    "\n",
    "        if plot_sample_X[0]=='logminmax':\n",
    "            featurelog_train=np.log2(scaleddata_train+1/2)\n",
    "            scaler = MinMaxScaler()\n",
    "            featurelog_train_minmax=np.transpose(scaler.fit_transform(np.transpose(featurelog_train)))\n",
    "            featureslist[s+'X_'+plot_sample_X[0]]=torch.tensor(featurelog_train_minmax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4832e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCTcomp(labels,ctlist,savepath,savenamecluster,addname=''):\n",
    "    res=np.zeros((np.unique(labels).size,np.unique(ctlist).size))\n",
    "    for li in range(res.shape[0]):\n",
    "        l=np.unique(labels)[li]\n",
    "        nl=np.sum(labels==l)\n",
    "        ctlist_l=ctlist[labels==l]\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=np.unique(ctlist)[ci]\n",
    "            res[li,ci]=np.sum(ctlist_l==c)\n",
    "#             res[li,ci]=np.sum(ctlist_l==c)/nl\n",
    "    if not byCT:\n",
    "        addname+=''\n",
    "        for li in range(res.shape[0]):\n",
    "            l=np.unique(labels)[li]\n",
    "            nl=np.sum(labels==l)\n",
    "            res[li]=res[li]/nl\n",
    "    else:\n",
    "        addname+='_normbyCT'\n",
    "        for ci in range(res.shape[1]):\n",
    "            c=np.unique(ctlist)[ci]\n",
    "            nc=np.sum(ctlist==c)\n",
    "            res[:,ci]=res[:,ci]/nc\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.imshow(res,cmap='binary')\n",
    "    ax.set_yticks(np.arange(np.unique(labels).size))\n",
    "    ax.set_yticklabels(np.unique(labels))\n",
    "    ax.set_xticks(np.arange(np.unique(ctlist).size))\n",
    "    ax.set_xticklabels(np.unique(ctlist))\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(savepath,savenamecluster+'_ctComposition'+addname+'.jpg'))\n",
    "    plt.close()\n",
    "        \n",
    "        \n",
    "\n",
    "def compLeiden(ctlist,n_neighbors,n_pcs,min_dist,resolution,addName=''):\n",
    "    for r in resolution:\n",
    "        savenamecluster='leiden_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'n_pcs'+str(n_pcs)+'res'+str(r)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        labels=np.array(labels)\n",
    "        if np.unique(labels).shape[0]==1:\n",
    "            continue\n",
    "        \n",
    "        savepath=clustersavedir\n",
    "        plotCTcomp(labels,ctlist,savepath,savenamecluster,addName)\n",
    "\n",
    "def compDBscan(ctlist,epsL,min_samplesL,n_pcs,addName=''):\n",
    "    for eps in epsL:\n",
    "        for min_samples in min_samplesL:\n",
    "            savenamecluster='dbscan_eps'+str(eps)+'msamples'+str(min_samples)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "            if not os.path.exists(readpath):\n",
    "                print('DNE: '+readpath)\n",
    "                continue\n",
    "            with open(readpath, 'rb') as input:\n",
    "                labels = pickle.load(input)\n",
    "            labels=np.array(labels)\n",
    "            if np.unique(labels).shape[0]==1:\n",
    "                continue\n",
    "            \n",
    "            savepath=clustersavedir\n",
    "            plotCTcomp(labels,ctlist,savepath,savenamecluster,addName)\n",
    "                \n",
    "def compAgg(ctlist,nclusterL,aggmetricL,n_pcs,addName=''):\n",
    "    for ncluster in nclusterL:\n",
    "        for aggmetric in aggmetricL:\n",
    "            savenamecluster='agg_ncluster'+str(ncluster)+aggmetric+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "            if not os.path.exists(readpath):\n",
    "                print('DNE: '+readpath)\n",
    "                continue\n",
    "            with open(readpath, 'rb') as input:\n",
    "                labels = pickle.load(input)\n",
    "            labels=np.array(labels)\n",
    "            if np.unique(labels).shape[0]==1:\n",
    "                continue\n",
    "            savepath=clustersavedir\n",
    "            plotCTcomp(labels,ctlist,savepath,savenamecluster,addName)\n",
    "            \n",
    "def compMinibatchKmean(ctlist,nclusterL,n_pcs,addName=''):\n",
    "    for ncluster in nclusterL:\n",
    "        savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        labels=np.array(labels)\n",
    "        if np.unique(labels).shape[0]==1:\n",
    "            continue\n",
    "            \n",
    "        savepath=clustersavedir\n",
    "        plotCTcomp(labels,ctlist,savepath,savenamecluster,addName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd232a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all latents to one plot \n",
    "np.random.seed(seed)\n",
    "for xcorr in plot_sample_X:\n",
    "    celltype_broad=None\n",
    "    celltype_sub=None\n",
    "    region=None\n",
    "    samplenameList=None\n",
    "    sobj_coord_np=None\n",
    "    \n",
    "    for s in plot_samples.keys():\n",
    "        sampleidx=plot_samples[s]        \n",
    "        samplename=s+'X_'+xcorr\n",
    "            \n",
    "        if celltype_broad is None:\n",
    "            celltype_broad=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']\n",
    "            celltype_sub=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'cell_type_label']\n",
    "            region=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']\n",
    "            sobj_coord_np=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,['x','y']].to_numpy()\n",
    "        else:\n",
    "            celltype_broad=np.concatenate((celltype_broad,scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']),axis=None)\n",
    "            celltype_sub=np.concatenate((celltype_sub,scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'cell_type_label']),axis=None)\n",
    "            region=np.concatenate((region,scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']),axis=None)\n",
    "            sobj_coord_np=np.concatenate((sobj_coord_np,scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,['x','y']].to_numpy()),axis=0)\n",
    "       \n",
    "    origCT=np.unique(celltype_broad)\n",
    "    celltypeplot=np.concatenate((origCT,list(combineCelltype.keys())),axis=None)\n",
    "    sampledir=os.path.join(plotsavepath,'combined'+xcorr)\n",
    "    if inverseAct:\n",
    "        sampledir+='_beforeAct'\n",
    "    clustersavedir=os.path.join(sampledir,'cluster')\n",
    "\n",
    "    if 'leiden' in clustermethod:\n",
    "        compLeiden(celltype_broad,n_neighbors,n_pcs,min_dist,resolution)\n",
    "    if 'dbscan' in clustermethod:\n",
    "        compDBscan(celltype_broad,epslist,min_sampleslist,n_pcs)\n",
    "    if 'agglomerative' in clustermethod:\n",
    "        compAgg(celltype_broad,nclusterlist,aggMetric,n_pcs)\n",
    "    if 'kmeanbatch' in clustermethod:\n",
    "        compMinibatchKmean(celltype_broad,nclusterlist,n_pcs)\n",
    "#     #by region\n",
    "#     for reg in np.unique(region):\n",
    "#         savedir=os.path.join(sampledir,'embedding_'+plottype+'_'+reg)\n",
    "#         clustersavedir=os.path.join(sampledir,'cluster'+'_'+reg)\n",
    "\n",
    "#         reg_idx=region==reg\n",
    "\n",
    "#         #by region and celltype\n",
    "#         for ct in celltypeplot:\n",
    "# #             if not ((reg=='Cortex' and ct in ['Ex']) or (reg=='Hippocampus' and ct in ['CA1','DG','Micro','CA'])):\n",
    "#             if not (ct in ['Micro']):\n",
    "#                 continue\n",
    "#             print(reg+ct)\n",
    "#             clustersavedir=os.path.join(sampledir,'cluster'+'_'+reg+ct)\n",
    "            \n",
    "#             if ct in origCT:\n",
    "#                 ct_idx=celltype_broad==ct\n",
    "#             else:\n",
    "#                 ct_idx=False\n",
    "#                 for i in combineCelltype[ct]:\n",
    "#                     ct_idx=np.logical_or(ct_idx,celltype_broad==i)\n",
    "#             ct_idx=np.logical_and(reg_idx,ct_idx)      \n",
    "            \n",
    "#             if np.sum(ct_idx)<3:\n",
    "#                 continue\n",
    "            \n",
    "#             if 'leiden' in clustermethod:\n",
    "#                 compLeiden(celltype_sub[ct_idx],n_neighbors,n_pcs,min_dist,resolution)\n",
    "#             if 'dbscan' in clustermethod:\n",
    "#                 compDBscan(celltype_sub[ct_idx],epslist,min_sampleslist,n_pcs)\n",
    "#             if 'agglomerative' in clustermethod:\n",
    "#                 compAgg(celltype_sub[ct_idx],nclusterlist,aggMetric,n_pcs)\n",
    "#             if 'kmeanbatch' in clustermethod:\n",
    "#                 compMinibatchKmean(celltype_sub[ct_idx],nclusterlist,n_pcs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
