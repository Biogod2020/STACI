{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xinyiz/pamrats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import image.loadImage as loadImage\n",
    "import gae.gae.optimizer as optimizer\n",
    "import image.modelsCNN as modelsCNN\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n",
      "no cells\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "use_cuda=True\n",
    "fastmode=False #Validate during training pass\n",
    "seed=3\n",
    "epochs=5000\n",
    "saveFreq=20\n",
    "lr=0.00001 #initial learning rate\n",
    "lr_adv=0.001\n",
    "weight_decay=0 #Weight for L2 loss on embedding matrix.\n",
    "\n",
    "batchsize=16\n",
    "kernel_size=4\n",
    "stride=2\n",
    "padding=1\n",
    "\n",
    "hidden1=128 #Number of channels in hidden layer 1\n",
    "hidden2=256 \n",
    "hidden3=512\n",
    "hidden4=1024\n",
    "hidden5=1024\n",
    "fc_dim1=1024*16*16\n",
    "fc_dim2=1024\n",
    "# fc_dim3=128\n",
    "# fc_dim4=128\n",
    "# gcn_dim1=2600\n",
    "adv_hidden=128\n",
    "\n",
    "dropout=0.01\n",
    "testNodes=0.1 #fraction of total nodes for testing\n",
    "valNodes=0.05 #fraction of total nodes for validation\n",
    "# clfweight=20\n",
    "advWeight=2\n",
    "# randFeatureSubset=None\n",
    "kl_weight=0.0000001\n",
    "model_str='cnn_vae'\n",
    "adv=None  #'clf_fc1_eq'  #'clf_fc1_control_eq' #'clf_fc1_control'  #'clf_fc1'\n",
    "\n",
    "pretrainedAE=None #{'name':'controlphy5XAbin_01_dca','epoch':9990}\n",
    "training_samples=['control13','disease13','disease8','control8']\n",
    "# training_samples=['control13','control8']\n",
    "targetBatch=None\n",
    "switchFreq=20\n",
    "diamThresh_mul=512\n",
    "minThresh_mul=6\n",
    "overlap=int(diamThresh_mul*0.15)\n",
    "name='all_thresh12min6_02_overlap15'\n",
    "logsavepath='/mnt/external_ssd/xinyi/log/train_cnn_starmap/'+name\n",
    "modelsavepath='/mnt/external_ssd/xinyi/models/train_cnn_starmap/'+name\n",
    "plotsavepath='/mnt/external_ssd/xinyi/plots/train_cnn_starmap/'+name\n",
    "\n",
    "#Load data\n",
    "sampleidx={'disease13':'AD_mouse9494','control13':'AD_mouse9498','disease8':'AD_mouse9723','control8':'AD_mouse9735'}\n",
    "datadir='/home/xinyiz/2021-01-13-mAD-test-dataset'\n",
    "\n",
    "imageslist={}\n",
    "for s in sampleidx.keys():\n",
    "    imageslist[s]=loadImage.loadandsplit(sampleidx[s],datadir,diamThresh_mul,overlap,valNodes,testNodes,ifFlip=True,minCutoff=minThresh_mul,seed=seed)\n",
    "    \n",
    "if adv:\n",
    "    if 'control_eq' in adv:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['control13']=torch.tensor([0.5,0.5]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([0.5,0.5]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['control13']=torch.tensor([1,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,1]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "    elif 'control' in adv:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['control13']=torch.tensor([0,1]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([1,0]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['control13']=torch.tensor([1,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,1]).expand(adjnormlist['control8'].shape[0],-1)        \n",
    "    elif 'eq' in adv:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['disease13']=torch.tensor([0.5,0.5,0.5,0.5]).expand(adjnormlist['disease13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control13']=torch.tensor([0.5,0.5,0.5,0.5]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['disease8']=torch.tensor([0.5,0.5,0.5,0.5]).expand(adjnormlist['disease8'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([0.5,0.5,0.5,0.5]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['disease13']=torch.tensor([1,0,0,0]).expand(adjnormlist['disease13'].shape[0],-1)\n",
    "        sampleLabellist_d['control13']=torch.tensor([0,1,0,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['disease8']=torch.tensor([0,0,1,0]).expand(adjnormlist['disease8'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,0,0,1]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "    else:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['disease13']=torch.tensor([0,1,1,1]).expand(adjnormlist['disease13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control13']=torch.tensor([1,0,1,1]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['disease8']=torch.tensor([1,1,0,1]).expand(adjnormlist['disease8'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([1,1,1,0]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['disease13']=torch.tensor([1,0,0,0]).expand(adjnormlist['disease13'].shape[0],-1)\n",
    "        sampleLabellist_d['control13']=torch.tensor([0,1,0,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['disease8']=torch.tensor([0,0,1,0]).expand(adjnormlist['disease8'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,0,0,1]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "        \n",
    "# Set cuda and seed\n",
    "np.random.seed(seed)\n",
    "if use_cuda and (not torch.cuda.is_available()):\n",
    "    print('cuda not available')\n",
    "    use_cuda=False\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "# Load data\n",
    "# if randFeatureSubset != None:\n",
    "#     idx=np.random.choice(features.shape[1],randFeatureSubset,replace=False)\n",
    "#     features=features[:,idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(logsavepath):\n",
    "    os.mkdir(logsavepath)\n",
    "if not os.path.exists(modelsavepath):\n",
    "    os.mkdir(modelsavepath)\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=torch.nn.MSELoss()\n",
    "# mse=torch.nn.MSELoss(reduction=None)\n",
    "# Create model\n",
    "if model_str=='cnn_vae':\n",
    "    model = modelsCNN.CNN_VAE(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,fc_dim2)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=mse\n",
    "\n",
    "if adv=='clf_fc1' or adv=='clf_fc1_eq' or adv=='clf_fc1_control' or adv=='clf_fc1_control_eq':\n",
    "    modelAdv=gae.gae.model.Clf_fc1(hidden2, dropout,adv_hidden,sampleLabellist_ae['control13'].size()[1])\n",
    "    loss_adv=optimizer.optimizer_CEclf\n",
    "    \n",
    "if adv=='clf_linear1' or adv=='clf_linear1_control':\n",
    "    modelAdv=gae.gae.model.Clf_linear1(hidden2, dropout,sampleLabellist_ae['control13'].size()[1])\n",
    "    loss_adv=optimizer.optimizer_CEclf\n",
    "        \n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    if adv:\n",
    "        modelAdv.cuda()\n",
    "    \n",
    "\n",
    "optimizerVAEXA = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "if adv:\n",
    "    optimizerAdv=optim.Adam(modelAdv.parameters(), lr=lr_adv, weight_decay=weight_decay)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control13 Epoch: 0000 loss_train: 0.2321 loss_kl_train: 2238994.7747 loss_x_train: 0.0082 loss_x_val: 0.0015 time: 76.4208s\n",
      "control13 Epoch: 0001 loss_train: 7.6978 loss_kl_train: 76939333.7182 loss_x_train: 0.0039 loss_x_val: 0.0014 time: 77.4557s\n",
      "control13 Epoch: 0002 loss_train: 17.0957 loss_kl_train: 170914354.2235 loss_x_train: 0.0043 loss_x_val: 0.0014 time: 77.8888s\n",
      "control13 Epoch: 0003 loss_train: 6.1585 loss_kl_train: 61546367.3963 loss_x_train: 0.0038 loss_x_val: 0.0015 time: 78.0398s\n",
      "control13 Epoch: 0004 loss_train: 0.0037 loss_kl_train: 2726.9174 loss_x_train: 0.0035 loss_x_val: 0.0016 time: 78.1402s\n",
      "control13 Epoch: 0005 loss_train: 2026.3750 loss_kl_train: 20263720045.0246 loss_x_train: 0.0030 loss_x_val: 0.0015 time: 78.1390s\n",
      "control13 Epoch: 0006 loss_train: 4.1305 loss_kl_train: 41282106.0346 loss_x_train: 0.0023 loss_x_val: 0.0014 time: 78.1377s\n",
      "control13 Epoch: 0007 loss_train: 11108.2715 loss_kl_train: 111082688874.1597 loss_x_train: 0.0022 loss_x_val: 0.0014 time: 78.1366s\n",
      "control13 Epoch: 0008 loss_train: 670.1291 loss_kl_train: 6701270348.9232 loss_x_train: 0.0021 loss_x_val: 0.0014 time: 78.1193s\n",
      "control13 Epoch: 0009 loss_train: 2.2438 loss_kl_train: 22417832.0700 loss_x_train: 0.0020 loss_x_val: 0.0015 time: 78.1173s\n",
      "control13 Epoch: 0010 loss_train: 0.0177 loss_kl_train: 158045.3278 loss_x_train: 0.0019 loss_x_val: 0.0014 time: 78.0965s\n",
      "control13 Epoch: 0011 loss_train: 0.0158 loss_kl_train: 139440.7053 loss_x_train: 0.0019 loss_x_val: 0.0014 time: 78.0879s\n",
      "control13 Epoch: 0012 loss_train: 0.0186 loss_kl_train: 167071.8440 loss_x_train: 0.0018 loss_x_val: 0.0014 time: 78.0748s\n",
      "control13 Epoch: 0013 loss_train: 0.0356 loss_kl_train: 338481.3729 loss_x_train: 0.0017 loss_x_val: 0.0014 time: 78.0992s\n",
      "control13 Epoch: 0014 loss_train: 104.1540 loss_kl_train: 1041523066.8602 loss_x_train: 0.0016 loss_x_val: 0.0014 time: 78.0692s\n",
      "control13 Epoch: 0015 loss_train: 0.0255 loss_kl_train: 238600.7555 loss_x_train: 0.0017 loss_x_val: 0.0014 time: 78.0756s\n",
      "control13 Epoch: 0016 loss_train: 0.0893 loss_kl_train: 876536.9181 loss_x_train: 0.0016 loss_x_val: 0.0014 time: 78.0677s\n",
      "control13 Epoch: 0017 loss_train: 642396.0444 loss_kl_train: 6423960542042.6357 loss_x_train: 0.0014 loss_x_val: 0.0014 time: 78.1141s\n",
      "control13 Epoch: 0018 loss_train: 44.0588 loss_kl_train: 440573574.4037 loss_x_train: 0.0014 loss_x_val: 0.0014 time: 78.0985s\n",
      "control13 Epoch: 0019 loss_train: 247.6738 loss_kl_train: 2476723291.9672 loss_x_train: 0.0014 loss_x_val: 0.0015 time: 78.0744s\n",
      "disease13 Epoch: 0020 loss_train: 0.0075 loss_kl_train: 60383.4022 loss_x_train: 0.0015 loss_x_val: 0.0013 time: 88.6836s\n",
      "disease13 Epoch: 0021 loss_train: 563091.2025 loss_kl_train: 5630911743953.5264 loss_x_train: 0.0014 loss_x_val: 0.0020 time: 88.4619s\n",
      "disease13 Epoch: 0022 loss_train: 0.0013 loss_kl_train: 191.7067 loss_x_train: 0.0013 loss_x_val: 0.0027 time: 88.6230s\n",
      "disease13 Epoch: 0023 loss_train: 0.0011 loss_kl_train: 43.2550 loss_x_train: 0.0011 loss_x_val: 0.0016 time: 88.6739s\n",
      "disease13 Epoch: 0024 loss_train: 0.0009 loss_kl_train: 576.9410 loss_x_train: 0.0008 loss_x_val: 0.0007 time: 88.6436s\n",
      "disease13 Epoch: 0025 loss_train: 0.9378 loss_kl_train: 9366813.5914 loss_x_train: 0.0011 loss_x_val: 0.0014 time: 88.5732s\n",
      "disease13 Epoch: 0026 loss_train: 3703.3378 loss_kl_train: 37033370433.8329 loss_x_train: 0.0009 loss_x_val: 0.0018 time: 88.5640s\n",
      "disease13 Epoch: 0027 loss_train: 8.4804 loss_kl_train: 84797303.0884 loss_x_train: 0.0007 loss_x_val: 0.0019 time: 88.5531s\n",
      "disease13 Epoch: 0028 loss_train: 3.8672 loss_kl_train: 38666031.9817 loss_x_train: 0.0006 loss_x_val: 0.0015 time: 88.5501s\n",
      "disease13 Epoch: 0029 loss_train: 0.0848 loss_kl_train: 842310.0591 loss_x_train: 0.0005 loss_x_val: 0.0011 time: 88.5211s\n",
      "disease13 Epoch: 0030 loss_train: 0.0005 loss_kl_train: 339.9317 loss_x_train: 0.0004 loss_x_val: 0.0004 time: 88.5507s\n",
      "disease13 Epoch: 0031 loss_train: 0.0004 loss_kl_train: 331.0727 loss_x_train: 0.0004 loss_x_val: 0.0004 time: 88.5753s\n",
      "disease13 Epoch: 0032 loss_train: 0.0020 loss_kl_train: 15600.7406 loss_x_train: 0.0004 loss_x_val: 0.0011 time: 88.5359s\n",
      "disease13 Epoch: 0033 loss_train: 1731.8473 loss_kl_train: 17318470378.1092 loss_x_train: 0.0003 loss_x_val: 0.0014 time: 88.5884s\n",
      "disease13 Epoch: 0034 loss_train: 0.0003 loss_kl_train: 198.6376 loss_x_train: 0.0003 loss_x_val: 0.0007 time: 88.6397s\n",
      "disease13 Epoch: 0035 loss_train: 0.0003 loss_kl_train: 156.4438 loss_x_train: 0.0003 loss_x_val: 0.0003 time: 88.6586s\n",
      "disease13 Epoch: 0036 loss_train: 0.0296 loss_kl_train: 292781.8227 loss_x_train: 0.0003 loss_x_val: 0.0012 time: 88.6392s\n",
      "disease13 Epoch: 0037 loss_train: 0.0003 loss_kl_train: 139.2641 loss_x_train: 0.0003 loss_x_val: 0.0003 time: 88.6306s\n",
      "disease13 Epoch: 0038 loss_train: 0.0003 loss_kl_train: 131.7396 loss_x_train: 0.0002 loss_x_val: 0.0003 time: 88.6672s\n",
      "disease13 Epoch: 0039 loss_train: 0.0003 loss_kl_train: 478.1208 loss_x_train: 0.0002 loss_x_val: 0.0004 time: 88.6831s\n",
      "disease8 Epoch: 0040 loss_train: 0.0003 loss_kl_train: 144.8933 loss_x_train: 0.0003 loss_x_val: 0.0003 time: 78.2656s\n",
      "disease8 Epoch: 0041 loss_train: 0.0003 loss_kl_train: 145.5963 loss_x_train: 0.0003 loss_x_val: 0.0003 time: 78.0962s\n",
      "disease8 Epoch: 0042 loss_train: 0.0003 loss_kl_train: 142.7107 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.2769s\n",
      "disease8 Epoch: 0043 loss_train: 0.0002 loss_kl_train: 137.1397 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.3015s\n",
      "disease8 Epoch: 0044 loss_train: 0.0002 loss_kl_train: 188.7993 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.2915s\n",
      "disease8 Epoch: 0045 loss_train: 0.0002 loss_kl_train: 131.1875 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.3101s\n",
      "disease8 Epoch: 0046 loss_train: 0.0002 loss_kl_train: 128.1535 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.2964s\n",
      "disease8 Epoch: 0047 loss_train: 0.0002 loss_kl_train: 125.3049 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.2968s\n",
      "disease8 Epoch: 0048 loss_train: 0.0002 loss_kl_train: 122.9570 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.3038s\n",
      "disease8 Epoch: 0049 loss_train: 0.0002 loss_kl_train: 120.1808 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.3052s\n",
      "disease8 Epoch: 0050 loss_train: 0.0002 loss_kl_train: 119.2904 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.3146s\n",
      "disease8 Epoch: 0051 loss_train: 0.0002 loss_kl_train: 116.7889 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.3258s\n",
      "disease8 Epoch: 0052 loss_train: 0.0002 loss_kl_train: 114.8845 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.3009s\n",
      "disease8 Epoch: 0053 loss_train: 0.0002 loss_kl_train: 114.3006 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.3308s\n",
      "disease8 Epoch: 0054 loss_train: 0.0002 loss_kl_train: 115.0472 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3052s\n",
      "disease8 Epoch: 0055 loss_train: 0.0002 loss_kl_train: 112.6436 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2901s\n",
      "disease8 Epoch: 0056 loss_train: 0.0002 loss_kl_train: 111.6422 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2463s\n",
      "disease8 Epoch: 0057 loss_train: 0.0001 loss_kl_train: 112.3334 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2756s\n",
      "disease8 Epoch: 0058 loss_train: 0.0001 loss_kl_train: 109.9133 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2945s\n",
      "disease8 Epoch: 0059 loss_train: 0.0001 loss_kl_train: 109.4605 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2762s\n",
      "control8 Epoch: 0060 loss_train: 0.0002 loss_kl_train: 176.6792 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 80.0652s\n",
      "control8 Epoch: 0061 loss_train: 0.0002 loss_kl_train: 279.1634 loss_x_train: 0.0002 loss_x_val: 0.0003 time: 79.8502s\n",
      "control8 Epoch: 0062 loss_train: 0.0003 loss_kl_train: 1856.5456 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 80.0291s\n",
      "control8 Epoch: 0063 loss_train: 0.0002 loss_kl_train: 168.5638 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0560s\n",
      "control8 Epoch: 0064 loss_train: 0.0002 loss_kl_train: 168.9028 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1151s\n",
      "control8 Epoch: 0065 loss_train: 0.0075 loss_kl_train: 73543.2889 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 80.0520s\n",
      "control8 Epoch: 0066 loss_train: 0.9154 loss_kl_train: 9152802.0734 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 80.0719s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control8 Epoch: 0067 loss_train: 0.0003 loss_kl_train: 1283.5311 loss_x_train: 0.0001 loss_x_val: 0.0005 time: 80.0552s\n",
      "control8 Epoch: 0068 loss_train: 0.0001 loss_kl_train: 166.2301 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0588s\n",
      "control8 Epoch: 0069 loss_train: 0.0001 loss_kl_train: 164.4862 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0745s\n",
      "control8 Epoch: 0070 loss_train: 0.0001 loss_kl_train: 165.6381 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0652s\n",
      "control8 Epoch: 0071 loss_train: 0.0001 loss_kl_train: 162.6936 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0597s\n",
      "control8 Epoch: 0072 loss_train: 0.0002 loss_kl_train: 1344.6745 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0290s\n",
      "control8 Epoch: 0073 loss_train: 0.0002 loss_kl_train: 507.3046 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0773s\n",
      "control8 Epoch: 0074 loss_train: 0.0003 loss_kl_train: 1457.7959 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0938s\n",
      "control8 Epoch: 0075 loss_train: 0.0001 loss_kl_train: 162.6490 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0630s\n",
      "control8 Epoch: 0076 loss_train: 0.0001 loss_kl_train: 161.0603 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0557s\n",
      "control8 Epoch: 0077 loss_train: 0.0001 loss_kl_train: 160.0717 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0529s\n",
      "control8 Epoch: 0078 loss_train: 0.0001 loss_kl_train: 159.0472 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 80.0949s\n",
      "control8 Epoch: 0079 loss_train: 0.0001 loss_kl_train: 158.8480 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 80.0582s\n",
      "control13 Epoch: 0080 loss_train: 0.0003 loss_kl_train: 349.8284 loss_x_train: 0.0003 loss_x_val: 0.0002 time: 78.0526s\n",
      "control13 Epoch: 0081 loss_train: 0.0002 loss_kl_train: 169.2019 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 77.8563s\n",
      "control13 Epoch: 0082 loss_train: 0.0002 loss_kl_train: 134.3050 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.0143s\n",
      "control13 Epoch: 0083 loss_train: 0.0003 loss_kl_train: 940.4436 loss_x_train: 0.0002 loss_x_val: 0.0003 time: 78.0638s\n",
      "control13 Epoch: 0084 loss_train: 0.0002 loss_kl_train: 164.9946 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.0827s\n",
      "control13 Epoch: 0085 loss_train: 0.0002 loss_kl_train: 139.9875 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0759s\n",
      "control13 Epoch: 0086 loss_train: 0.6896 loss_kl_train: 6893910.4270 loss_x_train: 0.0002 loss_x_val: 0.0013 time: 78.0962s\n",
      "control13 Epoch: 0087 loss_train: 0.1254 loss_kl_train: 1252290.8597 loss_x_train: 0.0002 loss_x_val: 0.0013 time: 78.0843s\n",
      "control13 Epoch: 0088 loss_train: 0.0002 loss_kl_train: 646.6088 loss_x_train: 0.0002 loss_x_val: 0.0003 time: 78.0860s\n",
      "control13 Epoch: 0089 loss_train: 0.0005 loss_kl_train: 3544.9585 loss_x_train: 0.0002 loss_x_val: 0.0003 time: 78.0635s\n",
      "control13 Epoch: 0090 loss_train: 0.0003 loss_kl_train: 1249.1183 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.0848s\n",
      "control13 Epoch: 0091 loss_train: 0.0002 loss_kl_train: 991.0377 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1295s\n",
      "control13 Epoch: 0092 loss_train: 0.0002 loss_kl_train: 854.8713 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0947s\n",
      "control13 Epoch: 0093 loss_train: 0.0002 loss_kl_train: 745.6666 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1368s\n",
      "control13 Epoch: 0094 loss_train: 0.0002 loss_kl_train: 709.8752 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1369s\n",
      "control13 Epoch: 0095 loss_train: 0.0002 loss_kl_train: 653.4134 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1106s\n",
      "control13 Epoch: 0096 loss_train: 0.0003 loss_kl_train: 1298.6577 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1298s\n",
      "control13 Epoch: 0097 loss_train: 0.0002 loss_kl_train: 573.2574 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1416s\n",
      "control13 Epoch: 0098 loss_train: 0.0002 loss_kl_train: 498.8727 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1674s\n",
      "control13 Epoch: 0099 loss_train: 0.0001 loss_kl_train: 471.2054 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1601s\n",
      "disease13 Epoch: 0100 loss_train: 0.0002 loss_kl_train: 280.9923 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 88.7722s\n",
      "disease13 Epoch: 0101 loss_train: 0.0003 loss_kl_train: 1894.8302 loss_x_train: 0.0002 loss_x_val: 0.0008 time: 88.5508s\n",
      "disease13 Epoch: 0102 loss_train: 0.0136 loss_kl_train: 133510.8125 loss_x_train: 0.0002 loss_x_val: 0.0012 time: 88.6968s\n",
      "disease13 Epoch: 0103 loss_train: 13810.2421 loss_kl_train: 138102417184.9813 loss_x_train: 0.0002 loss_x_val: 0.0013 time: 88.7438s\n",
      "disease13 Epoch: 0104 loss_train: 0.9770 loss_kl_train: 9768210.7950 loss_x_train: 0.0002 loss_x_val: 0.0013 time: 88.7485s\n",
      "disease13 Epoch: 0105 loss_train: 0.9027 loss_kl_train: 9025418.3749 loss_x_train: 0.0002 loss_x_val: 0.0014 time: 88.7302s\n",
      "disease13 Epoch: 0106 loss_train: 2759242.3100 loss_kl_train: 27592423833346.6992 loss_x_train: 0.0002 loss_x_val: 0.0013 time: 88.7516s\n",
      "disease13 Epoch: 0107 loss_train: 0.0001 loss_kl_train: 125.6701 loss_x_train: 0.0001 loss_x_val: 0.0013 time: 88.7277s\n",
      "disease13 Epoch: 0108 loss_train: 4.3813 loss_kl_train: 43811644.8568 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 88.7487s\n",
      "disease13 Epoch: 0109 loss_train: 0.5573 loss_kl_train: 5571017.3616 loss_x_train: 0.0002 loss_x_val: 0.0003 time: 88.7168s\n",
      "disease13 Epoch: 0110 loss_train: 0.0002 loss_kl_train: 967.2072 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7159s\n",
      "disease13 Epoch: 0111 loss_train: 0.0002 loss_kl_train: 751.5852 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7357s\n",
      "disease13 Epoch: 0112 loss_train: 2.0560 loss_kl_train: 20558335.4885 loss_x_train: 0.0002 loss_x_val: 0.0013 time: 88.7280s\n",
      "disease13 Epoch: 0113 loss_train: 0.0003 loss_kl_train: 1475.9404 loss_x_train: 0.0001 loss_x_val: 0.0007 time: 88.7047s\n",
      "disease13 Epoch: 0114 loss_train: 0.0168 loss_kl_train: 166802.5177 loss_x_train: 0.0001 loss_x_val: 0.0011 time: 88.6876s\n",
      "disease13 Epoch: 0115 loss_train: 0.0004 loss_kl_train: 3268.1033 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 88.6735s\n",
      "disease13 Epoch: 0116 loss_train: 0.0082 loss_kl_train: 80590.3150 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 88.6890s\n",
      "disease13 Epoch: 0117 loss_train: 0.0008 loss_kl_train: 7144.3983 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7019s\n",
      "disease13 Epoch: 0118 loss_train: 0.0001 loss_kl_train: 123.0590 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7095s\n",
      "disease13 Epoch: 0119 loss_train: 0.0001 loss_kl_train: 198.3594 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6909s\n",
      "disease8 Epoch: 0120 loss_train: 0.0002 loss_kl_train: 99.1716 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.3139s\n",
      "disease8 Epoch: 0121 loss_train: 0.0003 loss_kl_train: 799.5264 loss_x_train: 0.0002 loss_x_val: 0.0002 time: 78.0519s\n",
      "disease8 Epoch: 0122 loss_train: 0.0002 loss_kl_train: 984.6464 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2426s\n",
      "disease8 Epoch: 0123 loss_train: 66342.5305 loss_kl_train: 663425321278.4850 loss_x_train: 0.0001 loss_x_val: 0.0015 time: 78.3049s\n",
      "disease8 Epoch: 0124 loss_train: 0.0001 loss_kl_train: 123.8919 loss_x_train: 0.0001 loss_x_val: 0.0015 time: 78.3039s\n",
      "disease8 Epoch: 0125 loss_train: 0.0852 loss_kl_train: 851225.8743 loss_x_train: 0.0001 loss_x_val: 0.0006 time: 78.3208s\n",
      "disease8 Epoch: 0126 loss_train: 0.0002 loss_kl_train: 833.0687 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3070s\n",
      "disease8 Epoch: 0127 loss_train: 0.0001 loss_kl_train: 206.4320 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2940s\n",
      "disease8 Epoch: 0128 loss_train: 0.0001 loss_kl_train: 117.1377 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2947s\n",
      "disease8 Epoch: 0129 loss_train: 0.0001 loss_kl_train: 148.6531 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2636s\n",
      "disease8 Epoch: 0130 loss_train: 0.0001 loss_kl_train: 133.4620 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2660s\n",
      "disease8 Epoch: 0131 loss_train: 0.0001 loss_kl_train: 111.2563 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2624s\n",
      "disease8 Epoch: 0132 loss_train: 0.0001 loss_kl_train: 110.4277 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2625s\n",
      "disease8 Epoch: 0133 loss_train: 0.0005 loss_kl_train: 3655.0604 loss_x_train: 0.0001 loss_x_val: 0.0005 time: 78.2829s\n",
      "disease8 Epoch: 0134 loss_train: 0.0001 loss_kl_train: 113.3250 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2923s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease8 Epoch: 0135 loss_train: 0.0001 loss_kl_train: 124.5857 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2813s\n",
      "disease8 Epoch: 0136 loss_train: 0.8511 loss_kl_train: 8509935.7520 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2564s\n",
      "disease8 Epoch: 0137 loss_train: 0.0372 loss_kl_train: 370903.4827 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.2778s\n",
      "disease8 Epoch: 0138 loss_train: 0.0001 loss_kl_train: 328.2971 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.2749s\n",
      "disease8 Epoch: 0139 loss_train: 0.0001 loss_kl_train: 121.3459 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2933s\n",
      "control8 Epoch: 0140 loss_train: 0.0004 loss_kl_train: 2331.6603 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1084s\n",
      "control8 Epoch: 0141 loss_train: 5.2930 loss_kl_train: 52928764.8919 loss_x_train: 0.0001 loss_x_val: 0.0015 time: 79.8931s\n",
      "control8 Epoch: 0142 loss_train: 0.0048 loss_kl_train: 46541.2174 loss_x_train: 0.0001 loss_x_val: 0.0013 time: 80.0782s\n",
      "control8 Epoch: 0143 loss_train: 0.0001 loss_kl_train: 185.7183 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1491s\n",
      "control8 Epoch: 0144 loss_train: 0.0001 loss_kl_train: 187.9048 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1602s\n",
      "control8 Epoch: 0145 loss_train: 0.0001 loss_kl_train: 170.4472 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.2192s\n",
      "control8 Epoch: 0146 loss_train: 0.0001 loss_kl_train: 538.6126 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 80.2077s\n",
      "control8 Epoch: 0147 loss_train: 1.2296 loss_kl_train: 12295249.7050 loss_x_train: 0.0001 loss_x_val: 0.0011 time: 80.1748s\n",
      "control8 Epoch: 0148 loss_train: 0.8078 loss_kl_train: 8076566.0836 loss_x_train: 0.0001 loss_x_val: 0.0011 time: 80.2039s\n",
      "control8 Epoch: 0149 loss_train: 0.0669 loss_kl_train: 668334.4375 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 80.1635s\n",
      "control8 Epoch: 0150 loss_train: 0.0054 loss_kl_train: 53059.8764 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 80.1542s\n",
      "control8 Epoch: 0151 loss_train: 0.0001 loss_kl_train: 180.2993 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1545s\n",
      "control8 Epoch: 0152 loss_train: 0.0001 loss_kl_train: 348.7118 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1766s\n",
      "control8 Epoch: 0153 loss_train: 0.0001 loss_kl_train: 190.9443 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1459s\n",
      "control8 Epoch: 0154 loss_train: 4.5096 loss_kl_train: 45095041.1874 loss_x_train: 0.0001 loss_x_val: 0.0015 time: 80.1582s\n",
      "control8 Epoch: 0155 loss_train: 0.0001 loss_kl_train: 166.7713 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 80.2058s\n",
      "control8 Epoch: 0156 loss_train: 0.0001 loss_kl_train: 332.0022 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1737s\n",
      "control8 Epoch: 0157 loss_train: 0.0821 loss_kl_train: 820144.9244 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 80.1460s\n",
      "control8 Epoch: 0158 loss_train: 0.0001 loss_kl_train: 166.1092 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1864s\n",
      "control8 Epoch: 0159 loss_train: 0.0001 loss_kl_train: 202.2373 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1700s\n",
      "control13 Epoch: 0160 loss_train: 0.0069 loss_kl_train: 67231.5930 loss_x_train: 0.0002 loss_x_val: 0.0011 time: 78.1010s\n",
      "control13 Epoch: 0161 loss_train: 2.8081 loss_kl_train: 28079524.0658 loss_x_train: 0.0002 loss_x_val: 0.0014 time: 77.8786s\n",
      "control13 Epoch: 0162 loss_train: 0.0005 loss_kl_train: 3802.7744 loss_x_train: 0.0002 loss_x_val: 0.0010 time: 78.0556s\n",
      "control13 Epoch: 0163 loss_train: 0.0003 loss_kl_train: 1586.5255 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1102s\n",
      "control13 Epoch: 0164 loss_train: 0.0029 loss_kl_train: 27961.0830 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.0958s\n",
      "control13 Epoch: 0165 loss_train: 0.0002 loss_kl_train: 783.5608 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1108s\n",
      "control13 Epoch: 0166 loss_train: 0.0002 loss_kl_train: 815.2343 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1117s\n",
      "control13 Epoch: 0167 loss_train: 0.0001 loss_kl_train: 431.3561 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.0971s\n",
      "control13 Epoch: 0168 loss_train: 0.0002 loss_kl_train: 707.1959 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0856s\n",
      "control13 Epoch: 0169 loss_train: 2.1300 loss_kl_train: 21298697.7092 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0778s\n",
      "control13 Epoch: 0170 loss_train: 4796.2549 loss_kl_train: 47962545374.0368 loss_x_train: 0.0002 loss_x_val: 0.0014 time: 78.0807s\n",
      "control13 Epoch: 0171 loss_train: 0.0059 loss_kl_train: 57614.7468 loss_x_train: 0.0001 loss_x_val: 0.0010 time: 78.0577s\n",
      "control13 Epoch: 0172 loss_train: 0.4066 loss_kl_train: 4064061.8752 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 78.0502s\n",
      "control13 Epoch: 0173 loss_train: 0.0010 loss_kl_train: 9426.8304 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.0379s\n",
      "control13 Epoch: 0174 loss_train: 0.0081 loss_kl_train: 79862.0643 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.0216s\n",
      "control13 Epoch: 0175 loss_train: 0.0002 loss_kl_train: 1458.0235 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0842s\n",
      "control13 Epoch: 0176 loss_train: 0.0001 loss_kl_train: 144.3173 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0945s\n",
      "control13 Epoch: 0177 loss_train: 0.0001 loss_kl_train: 109.8205 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0784s\n",
      "control13 Epoch: 0178 loss_train: 0.0001 loss_kl_train: 106.0417 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0697s\n",
      "control13 Epoch: 0179 loss_train: 0.0001 loss_kl_train: 106.7419 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0480s\n",
      "disease13 Epoch: 0180 loss_train: 0.0068 loss_kl_train: 65884.2592 loss_x_train: 0.0002 loss_x_val: 0.0014 time: 88.6537s\n",
      "disease13 Epoch: 0181 loss_train: 42558.5961 loss_kl_train: 425585958691.8603 loss_x_train: 0.0002 loss_x_val: 0.0014 time: 88.4279s\n",
      "disease13 Epoch: 0182 loss_train: 34006.9448 loss_kl_train: 340069447671.4897 loss_x_train: 0.0002 loss_x_val: 0.0014 time: 88.6548s\n",
      "disease13 Epoch: 0183 loss_train: 0.0056 loss_kl_train: 54657.4512 loss_x_train: 0.0002 loss_x_val: 0.0014 time: 88.6622s\n",
      "disease13 Epoch: 0184 loss_train: 0.0582 loss_kl_train: 580243.7738 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 88.6875s\n",
      "disease13 Epoch: 0185 loss_train: 0.0001 loss_kl_train: 138.0235 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6792s\n",
      "disease13 Epoch: 0186 loss_train: 0.0003 loss_kl_train: 1855.2288 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 88.7331s\n",
      "disease13 Epoch: 0187 loss_train: 218.3121 loss_kl_train: 2183119714.2465 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 88.7120s\n",
      "disease13 Epoch: 0188 loss_train: 0.0222 loss_kl_train: 221156.4965 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 88.7214s\n",
      "disease13 Epoch: 0189 loss_train: 0.0017 loss_kl_train: 16404.1938 loss_x_train: 0.0001 loss_x_val: 0.0012 time: 88.7339s\n",
      "disease13 Epoch: 0190 loss_train: 0.1763 loss_kl_train: 1762268.9238 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 88.7446s\n",
      "disease13 Epoch: 0191 loss_train: 0.0001 loss_kl_train: 360.1859 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7438s\n",
      "disease13 Epoch: 0192 loss_train: 0.0077 loss_kl_train: 76483.7912 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 88.7472s\n",
      "disease13 Epoch: 0193 loss_train: 12.4143 loss_kl_train: 124141615.9742 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 88.7474s\n",
      "disease13 Epoch: 0194 loss_train: 3591.5794 loss_kl_train: 35915794322.4119 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 88.7614s\n",
      "disease13 Epoch: 0195 loss_train: 1.3956 loss_kl_train: 13955371.9208 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 88.7361s\n",
      "disease13 Epoch: 0196 loss_train: 0.0001 loss_kl_train: 148.1213 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7101s\n",
      "disease13 Epoch: 0197 loss_train: 0.0001 loss_kl_train: 161.9552 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7380s\n",
      "disease13 Epoch: 0198 loss_train: 0.0001 loss_kl_train: 305.5284 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7839s\n",
      "disease13 Epoch: 0199 loss_train: 0.0001 loss_kl_train: 142.4382 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7558s\n",
      "disease8 Epoch: 0200 loss_train: 0.0001 loss_kl_train: 129.0154 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3415s\n",
      "disease8 Epoch: 0201 loss_train: 4819.7530 loss_kl_train: 48197530120.3997 loss_x_train: 0.0001 loss_x_val: 0.0016 time: 78.1496s\n",
      "disease8 Epoch: 0202 loss_train: 0.0034 loss_kl_train: 33173.9599 loss_x_train: 0.0001 loss_x_val: 0.0006 time: 78.3154s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease8 Epoch: 0203 loss_train: 0.0001 loss_kl_train: 416.2535 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3170s\n",
      "disease8 Epoch: 0204 loss_train: 0.0001 loss_kl_train: 253.7008 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3195s\n",
      "disease8 Epoch: 0205 loss_train: 0.0001 loss_kl_train: 252.5442 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.3502s\n",
      "disease8 Epoch: 0206 loss_train: 0.0001 loss_kl_train: 262.1981 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.3499s\n",
      "disease8 Epoch: 0207 loss_train: 0.0004 loss_kl_train: 2993.9548 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3375s\n",
      "disease8 Epoch: 0208 loss_train: 0.0001 loss_kl_train: 303.7614 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3171s\n",
      "disease8 Epoch: 0209 loss_train: 0.0001 loss_kl_train: 441.5374 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.3089s\n",
      "disease8 Epoch: 0210 loss_train: 0.0001 loss_kl_train: 262.9203 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3193s\n",
      "disease8 Epoch: 0211 loss_train: 0.0001 loss_kl_train: 253.5775 loss_x_train: 0.0001 loss_x_val: 0.0005 time: 78.3022s\n",
      "disease8 Epoch: 0212 loss_train: 0.0001 loss_kl_train: 272.2411 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2917s\n",
      "disease8 Epoch: 0213 loss_train: 0.0002 loss_kl_train: 1534.8920 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2847s\n",
      "disease8 Epoch: 0214 loss_train: 0.0001 loss_kl_train: 252.2166 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2905s\n",
      "disease8 Epoch: 0215 loss_train: 0.0001 loss_kl_train: 251.2498 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.2911s\n",
      "disease8 Epoch: 0216 loss_train: 0.0001 loss_kl_train: 251.1580 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2786s\n",
      "disease8 Epoch: 0217 loss_train: 0.0001 loss_kl_train: 253.4898 loss_x_train: 0.0001 loss_x_val: 0.0005 time: 78.2561s\n",
      "disease8 Epoch: 0218 loss_train: 0.0001 loss_kl_train: 276.7032 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2818s\n",
      "disease8 Epoch: 0219 loss_train: 0.0001 loss_kl_train: 320.2005 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.2406s\n",
      "control8 Epoch: 0220 loss_train: 0.0001 loss_kl_train: 174.6353 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0368s\n",
      "control8 Epoch: 0221 loss_train: 0.0029 loss_kl_train: 28473.5722 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 79.8193s\n",
      "control8 Epoch: 0222 loss_train: 0.0001 loss_kl_train: 486.9226 loss_x_train: 0.0001 loss_x_val: 0.0005 time: 80.0386s\n",
      "control8 Epoch: 0223 loss_train: 0.0031 loss_kl_train: 30154.3182 loss_x_train: 0.0001 loss_x_val: 0.0007 time: 80.0941s\n",
      "control8 Epoch: 0224 loss_train: 0.0001 loss_kl_train: 221.4718 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0818s\n",
      "control8 Epoch: 0225 loss_train: 0.0001 loss_kl_train: 451.1047 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1213s\n",
      "control8 Epoch: 0226 loss_train: 0.0001 loss_kl_train: 175.0664 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1152s\n",
      "control8 Epoch: 0227 loss_train: 0.0001 loss_kl_train: 177.8280 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1084s\n",
      "control8 Epoch: 0228 loss_train: 0.0001 loss_kl_train: 379.5962 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1144s\n",
      "control8 Epoch: 0229 loss_train: 0.0001 loss_kl_train: 176.1823 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1745s\n",
      "control8 Epoch: 0230 loss_train: 0.0001 loss_kl_train: 172.9504 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1290s\n",
      "control8 Epoch: 0231 loss_train: 0.0001 loss_kl_train: 168.7788 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0641s\n",
      "control8 Epoch: 0232 loss_train: 0.0001 loss_kl_train: 168.1083 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1273s\n",
      "control8 Epoch: 0233 loss_train: 0.0001 loss_kl_train: 194.5947 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0785s\n",
      "control8 Epoch: 0234 loss_train: 0.0001 loss_kl_train: 166.8815 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0954s\n",
      "control8 Epoch: 0235 loss_train: 0.0001 loss_kl_train: 176.7217 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1321s\n",
      "control8 Epoch: 0236 loss_train: 0.0001 loss_kl_train: 165.8226 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1706s\n",
      "control8 Epoch: 0237 loss_train: 0.0001 loss_kl_train: 165.2811 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1223s\n",
      "control8 Epoch: 0238 loss_train: 0.0159 loss_kl_train: 158592.1065 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1648s\n",
      "control8 Epoch: 0239 loss_train: 0.0001 loss_kl_train: 172.2999 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1450s\n",
      "control13 Epoch: 0240 loss_train: 0.0023 loss_kl_train: 21264.9465 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.1393s\n",
      "control13 Epoch: 0241 loss_train: 0.0053 loss_kl_train: 51459.1077 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0062s\n",
      "control13 Epoch: 0242 loss_train: 11.7563 loss_kl_train: 117561442.4120 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 78.1211s\n",
      "control13 Epoch: 0243 loss_train: 0.0018 loss_kl_train: 16727.8763 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1777s\n",
      "control13 Epoch: 0244 loss_train: 0.0017 loss_kl_train: 15693.6918 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2176s\n",
      "control13 Epoch: 0245 loss_train: 0.0019 loss_kl_train: 18187.9195 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2226s\n",
      "control13 Epoch: 0246 loss_train: 0.0030 loss_kl_train: 29252.6532 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1967s\n",
      "control13 Epoch: 0247 loss_train: 0.0015 loss_kl_train: 14592.6041 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1729s\n",
      "control13 Epoch: 0248 loss_train: 0.0015 loss_kl_train: 14264.7089 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1683s\n",
      "control13 Epoch: 0249 loss_train: 0.0019 loss_kl_train: 18157.6067 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1363s\n",
      "control13 Epoch: 0250 loss_train: 0.0081 loss_kl_train: 80234.6392 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1680s\n",
      "control13 Epoch: 0251 loss_train: 0.0018 loss_kl_train: 17105.8079 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1459s\n",
      "control13 Epoch: 0252 loss_train: 0.0014 loss_kl_train: 13023.3452 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1288s\n",
      "control13 Epoch: 0253 loss_train: 0.0016 loss_kl_train: 15175.4421 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1254s\n",
      "control13 Epoch: 0254 loss_train: 0.0013 loss_kl_train: 12527.0210 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1359s\n",
      "control13 Epoch: 0255 loss_train: 0.0019 loss_kl_train: 18147.8352 loss_x_train: 0.0001 loss_x_val: 0.0005 time: 78.1437s\n",
      "control13 Epoch: 0256 loss_train: 0.0015 loss_kl_train: 13878.3650 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1390s\n",
      "control13 Epoch: 0257 loss_train: 0.0012 loss_kl_train: 11510.9168 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1153s\n",
      "control13 Epoch: 0258 loss_train: 0.2789 loss_kl_train: 2787937.1670 loss_x_train: 0.0001 loss_x_val: 0.0012 time: 78.1051s\n",
      "control13 Epoch: 0259 loss_train: 0.0012 loss_kl_train: 10941.1016 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1257s\n",
      "disease13 Epoch: 0260 loss_train: 0.0006 loss_kl_train: 4978.5252 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7413s\n",
      "disease13 Epoch: 0261 loss_train: 1.9890 loss_kl_train: 19888460.0920 loss_x_train: 0.0001 loss_x_val: 0.0013 time: 88.4921s\n",
      "disease13 Epoch: 0262 loss_train: 1.3995 loss_kl_train: 13994201.0634 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 88.6769s\n",
      "disease13 Epoch: 0263 loss_train: 17.5424 loss_kl_train: 175423396.0936 loss_x_train: 0.0001 loss_x_val: 0.0012 time: 88.6687s\n",
      "disease13 Epoch: 0264 loss_train: 0.3992 loss_kl_train: 3991034.7289 loss_x_train: 0.0001 loss_x_val: 0.0005 time: 88.7018s\n",
      "disease13 Epoch: 0265 loss_train: 0.0619 loss_kl_train: 618132.8397 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 88.6771s\n",
      "disease13 Epoch: 0266 loss_train: 0.0004 loss_kl_train: 3085.1879 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6839s\n",
      "disease13 Epoch: 0267 loss_train: 0.0004 loss_kl_train: 3059.0784 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6624s\n",
      "disease13 Epoch: 0268 loss_train: 0.0004 loss_kl_train: 3053.0342 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6858s\n",
      "disease13 Epoch: 0269 loss_train: 0.0004 loss_kl_train: 3031.7002 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6543s\n",
      "disease13 Epoch: 0270 loss_train: 0.0004 loss_kl_train: 3030.9320 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6935s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease13 Epoch: 0271 loss_train: 163.9391 loss_kl_train: 1639389669.4624 loss_x_train: 0.0001 loss_x_val: 0.0005 time: 88.6600s\n",
      "disease13 Epoch: 0272 loss_train: 16.5190 loss_kl_train: 165189383.8180 loss_x_train: 0.0001 loss_x_val: 0.0013 time: 88.6690s\n",
      "disease13 Epoch: 0273 loss_train: 0.1719 loss_kl_train: 1717535.6517 loss_x_train: 0.0001 loss_x_val: 0.0011 time: 88.6789s\n",
      "disease13 Epoch: 0274 loss_train: 0.0007 loss_kl_train: 6401.5099 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6919s\n",
      "disease13 Epoch: 0275 loss_train: 0.0006 loss_kl_train: 5427.5850 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7062s\n",
      "disease13 Epoch: 0276 loss_train: 0.0005 loss_kl_train: 4589.4991 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6919s\n",
      "disease13 Epoch: 0277 loss_train: 0.0005 loss_kl_train: 3934.9692 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6814s\n",
      "disease13 Epoch: 0278 loss_train: 0.0005 loss_kl_train: 4146.3328 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6615s\n",
      "disease13 Epoch: 0279 loss_train: 0.0004 loss_kl_train: 3125.6684 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6794s\n",
      "disease8 Epoch: 0280 loss_train: 0.0002 loss_kl_train: 1113.7526 loss_x_train: 0.0001 loss_x_val: 0.0001 time: 78.2891s\n",
      "disease8 Epoch: 0281 loss_train: 0.0002 loss_kl_train: 1048.8609 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0822s\n",
      "disease8 Epoch: 0282 loss_train: 0.0002 loss_kl_train: 993.0662 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2567s\n",
      "disease8 Epoch: 0283 loss_train: 0.4630 loss_kl_train: 4629704.2671 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3004s\n",
      "disease8 Epoch: 0284 loss_train: 0.1481 loss_kl_train: 1479545.1081 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.2850s\n",
      "disease8 Epoch: 0285 loss_train: 0.0002 loss_kl_train: 1683.4132 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2827s\n",
      "disease8 Epoch: 0286 loss_train: 0.0008 loss_kl_train: 6967.2639 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2484s\n",
      "disease8 Epoch: 0287 loss_train: 0.0001 loss_kl_train: 762.7176 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2906s\n",
      "disease8 Epoch: 0288 loss_train: 0.0001 loss_kl_train: 827.4423 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2827s\n",
      "disease8 Epoch: 0289 loss_train: 0.0001 loss_kl_train: 672.5821 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3153s\n",
      "disease8 Epoch: 0290 loss_train: 0.0001 loss_kl_train: 650.7456 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2764s\n",
      "disease8 Epoch: 0291 loss_train: 0.0001 loss_kl_train: 634.8243 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3228s\n",
      "disease8 Epoch: 0292 loss_train: 0.0001 loss_kl_train: 616.7174 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2946s\n",
      "disease8 Epoch: 0293 loss_train: 0.0001 loss_kl_train: 599.8179 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2683s\n",
      "disease8 Epoch: 0294 loss_train: 0.0001 loss_kl_train: 622.1509 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2652s\n",
      "disease8 Epoch: 0295 loss_train: 0.0001 loss_kl_train: 572.1865 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2677s\n",
      "disease8 Epoch: 0296 loss_train: 0.0001 loss_kl_train: 838.1299 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2766s\n",
      "disease8 Epoch: 0297 loss_train: 0.0001 loss_kl_train: 548.3289 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2662s\n",
      "disease8 Epoch: 0298 loss_train: 8.4826 loss_kl_train: 84824750.2953 loss_x_train: 0.0001 loss_x_val: 0.0005 time: 78.2959s\n",
      "disease8 Epoch: 0299 loss_train: 0.0002 loss_kl_train: 1633.7377 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2618s\n",
      "control8 Epoch: 0300 loss_train: 0.0002 loss_kl_train: 972.6864 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0731s\n",
      "control8 Epoch: 0301 loss_train: 0.0035 loss_kl_train: 33904.1885 loss_x_train: 0.0001 loss_x_val: 0.0011 time: 79.8744s\n",
      "control8 Epoch: 0302 loss_train: 0.0337 loss_kl_train: 336444.6720 loss_x_train: 0.0001 loss_x_val: 0.0006 time: 80.1636s\n",
      "control8 Epoch: 0303 loss_train: 0.0002 loss_kl_train: 1378.5872 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1312s\n",
      "control8 Epoch: 0304 loss_train: 0.0001 loss_kl_train: 926.1017 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1918s\n",
      "control8 Epoch: 0305 loss_train: 0.0001 loss_kl_train: 924.9028 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1240s\n",
      "control8 Epoch: 0306 loss_train: 0.0001 loss_kl_train: 914.2320 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1738s\n",
      "control8 Epoch: 0307 loss_train: 0.0001 loss_kl_train: 908.3158 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1578s\n",
      "control8 Epoch: 0308 loss_train: 0.0001 loss_kl_train: 902.9348 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1685s\n",
      "control8 Epoch: 0309 loss_train: 0.0001 loss_kl_train: 939.3611 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1714s\n",
      "control8 Epoch: 0310 loss_train: 0.0001 loss_kl_train: 899.9905 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1792s\n",
      "control8 Epoch: 0311 loss_train: 0.0001 loss_kl_train: 944.6192 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1425s\n",
      "control8 Epoch: 0312 loss_train: 0.0001 loss_kl_train: 894.2513 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1804s\n",
      "control8 Epoch: 0313 loss_train: 0.0001 loss_kl_train: 893.1001 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1342s\n",
      "control8 Epoch: 0314 loss_train: 248.0947 loss_kl_train: 2480945478.3288 loss_x_train: 0.0001 loss_x_val: 0.0013 time: 80.1904s\n",
      "control8 Epoch: 0315 loss_train: 0.0001 loss_kl_train: 271.5220 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1873s\n",
      "control8 Epoch: 0316 loss_train: 0.0001 loss_kl_train: 210.3485 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1849s\n",
      "control8 Epoch: 0317 loss_train: 0.0001 loss_kl_train: 191.9460 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1623s\n",
      "control8 Epoch: 0318 loss_train: 0.0001 loss_kl_train: 193.8044 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1962s\n",
      "control8 Epoch: 0319 loss_train: 0.0001 loss_kl_train: 206.3878 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.1413s\n",
      "control13 Epoch: 0320 loss_train: 0.0555 loss_kl_train: 553335.9389 loss_x_train: 0.0002 loss_x_val: 0.0003 time: 78.1313s\n",
      "control13 Epoch: 0321 loss_train: 0.0001 loss_kl_train: 415.8617 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 77.9137s\n",
      "control13 Epoch: 0322 loss_train: 0.2724 loss_kl_train: 2723406.2035 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.0773s\n",
      "control13 Epoch: 0323 loss_train: 0.0001 loss_kl_train: 364.5961 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.1222s\n",
      "control13 Epoch: 0324 loss_train: 0.0001 loss_kl_train: 349.5168 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1379s\n",
      "control13 Epoch: 0325 loss_train: 0.0001 loss_kl_train: 332.7812 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1686s\n",
      "control13 Epoch: 0326 loss_train: 0.0001 loss_kl_train: 320.0701 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1580s\n",
      "control13 Epoch: 0327 loss_train: 0.0001 loss_kl_train: 425.0529 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1400s\n",
      "control13 Epoch: 0328 loss_train: 0.0001 loss_kl_train: 299.1102 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1294s\n",
      "control13 Epoch: 0329 loss_train: 0.0001 loss_kl_train: 290.0091 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.1511s\n",
      "control13 Epoch: 0330 loss_train: 0.0001 loss_kl_train: 635.2641 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1853s\n",
      "control13 Epoch: 0331 loss_train: 0.0001 loss_kl_train: 270.2211 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1864s\n",
      "control13 Epoch: 0332 loss_train: 0.0001 loss_kl_train: 260.8702 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1625s\n",
      "control13 Epoch: 0333 loss_train: 0.0001 loss_kl_train: 252.3637 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1898s\n",
      "control13 Epoch: 0334 loss_train: 0.0001 loss_kl_train: 251.5808 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.1953s\n",
      "control13 Epoch: 0335 loss_train: 0.0001 loss_kl_train: 239.8652 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1821s\n",
      "control13 Epoch: 0336 loss_train: 0.0001 loss_kl_train: 230.9933 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.2247s\n",
      "control13 Epoch: 0337 loss_train: 0.0001 loss_kl_train: 235.0609 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1898s\n",
      "control13 Epoch: 0338 loss_train: 0.0001 loss_kl_train: 395.0411 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1764s\n",
      "control13 Epoch: 0339 loss_train: 0.0001 loss_kl_train: 213.1112 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2307s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease13 Epoch: 0340 loss_train: 0.0001 loss_kl_train: 230.6198 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.8443s\n",
      "disease13 Epoch: 0341 loss_train: 0.0001 loss_kl_train: 475.1125 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6210s\n",
      "disease13 Epoch: 0342 loss_train: 0.0545 loss_kl_train: 543850.4268 loss_x_train: 0.0001 loss_x_val: 0.0012 time: 88.7500s\n",
      "disease13 Epoch: 0343 loss_train: 0.1654 loss_kl_train: 1652910.9936 loss_x_train: 0.0001 loss_x_val: 0.0013 time: 88.7920s\n",
      "disease13 Epoch: 0344 loss_train: 0.0343 loss_kl_train: 342298.7907 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 88.7858s\n",
      "disease13 Epoch: 0345 loss_train: 0.0001 loss_kl_train: 365.7031 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7868s\n",
      "disease13 Epoch: 0346 loss_train: 0.0001 loss_kl_train: 288.1413 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7639s\n",
      "disease13 Epoch: 0347 loss_train: 0.0166 loss_kl_train: 165078.8388 loss_x_train: 0.0001 loss_x_val: 0.0007 time: 88.7492s\n",
      "disease13 Epoch: 0348 loss_train: 0.0001 loss_kl_train: 230.9828 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.7878s\n",
      "disease13 Epoch: 0349 loss_train: 0.0001 loss_kl_train: 225.9098 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.7166s\n",
      "disease13 Epoch: 0350 loss_train: 0.0001 loss_kl_train: 292.7152 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7319s\n",
      "disease13 Epoch: 0351 loss_train: 0.0001 loss_kl_train: 326.1572 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7382s\n",
      "disease13 Epoch: 0352 loss_train: 0.0001 loss_kl_train: 325.8439 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7147s\n",
      "disease13 Epoch: 0353 loss_train: 0.0003 loss_kl_train: 1971.2884 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7020s\n",
      "disease13 Epoch: 0354 loss_train: 0.0001 loss_kl_train: 216.0582 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.7008s\n",
      "disease13 Epoch: 0355 loss_train: 0.0001 loss_kl_train: 211.9461 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.7000s\n",
      "disease13 Epoch: 0356 loss_train: 0.0006 loss_kl_train: 5049.6997 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.7140s\n",
      "disease13 Epoch: 0357 loss_train: 0.0001 loss_kl_train: 213.9711 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.7007s\n",
      "disease13 Epoch: 0358 loss_train: 0.0001 loss_kl_train: 212.7415 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.6927s\n",
      "disease13 Epoch: 0359 loss_train: 0.0001 loss_kl_train: 208.7342 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.7127s\n",
      "disease8 Epoch: 0360 loss_train: 0.0001 loss_kl_train: 175.2608 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3346s\n",
      "disease8 Epoch: 0361 loss_train: 0.0001 loss_kl_train: 185.4249 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.1305s\n",
      "disease8 Epoch: 0362 loss_train: 0.0001 loss_kl_train: 267.9698 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2581s\n",
      "disease8 Epoch: 0363 loss_train: 285.8116 loss_kl_train: 2858114606.5288 loss_x_train: 0.0001 loss_x_val: 0.0015 time: 78.3044s\n",
      "disease8 Epoch: 0364 loss_train: 0.0001 loss_kl_train: 211.4000 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.3338s\n",
      "disease8 Epoch: 0365 loss_train: 0.0001 loss_kl_train: 75.0260 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3106s\n",
      "disease8 Epoch: 0366 loss_train: 0.0001 loss_kl_train: 76.3046 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.3139s\n",
      "disease8 Epoch: 0367 loss_train: 0.0001 loss_kl_train: 74.3674 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2889s\n",
      "disease8 Epoch: 0368 loss_train: 0.0001 loss_kl_train: 74.2562 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2731s\n",
      "disease8 Epoch: 0369 loss_train: 0.0001 loss_kl_train: 73.8470 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2741s\n",
      "disease8 Epoch: 0370 loss_train: 0.0001 loss_kl_train: 75.2556 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2969s\n",
      "disease8 Epoch: 0371 loss_train: 0.0001 loss_kl_train: 74.3900 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2539s\n",
      "disease8 Epoch: 0372 loss_train: 0.0001 loss_kl_train: 73.8630 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2593s\n",
      "disease8 Epoch: 0373 loss_train: 0.0001 loss_kl_train: 73.0100 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.3204s\n",
      "disease8 Epoch: 0374 loss_train: 0.0001 loss_kl_train: 72.7541 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2830s\n",
      "disease8 Epoch: 0375 loss_train: 0.0001 loss_kl_train: 72.7441 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2616s\n",
      "disease8 Epoch: 0376 loss_train: 0.0001 loss_kl_train: 73.2636 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2667s\n",
      "disease8 Epoch: 0377 loss_train: 0.0001 loss_kl_train: 73.1325 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2781s\n",
      "disease8 Epoch: 0378 loss_train: 0.0001 loss_kl_train: 73.3500 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2436s\n",
      "disease8 Epoch: 0379 loss_train: 0.0001 loss_kl_train: 73.9004 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.2564s\n",
      "control8 Epoch: 0380 loss_train: 0.0001 loss_kl_train: 490.2157 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 80.0797s\n",
      "control8 Epoch: 0381 loss_train: 0.0001 loss_kl_train: 731.6872 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 79.8209s\n",
      "control8 Epoch: 0382 loss_train: 0.0029 loss_kl_train: 28626.2120 loss_x_train: 0.0001 loss_x_val: 0.0014 time: 80.0204s\n",
      "control8 Epoch: 0383 loss_train: 0.0001 loss_kl_train: 79.8973 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0515s\n",
      "control8 Epoch: 0384 loss_train: 0.0000 loss_kl_train: 78.4023 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1474s\n",
      "control8 Epoch: 0385 loss_train: 0.0000 loss_kl_train: 77.3559 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0838s\n",
      "control8 Epoch: 0386 loss_train: 0.0000 loss_kl_train: 76.9630 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0771s\n",
      "control8 Epoch: 0387 loss_train: 0.0001 loss_kl_train: 77.0917 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0886s\n",
      "control8 Epoch: 0388 loss_train: 0.0001 loss_kl_train: 77.5315 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0785s\n",
      "control8 Epoch: 0389 loss_train: 0.0001 loss_kl_train: 78.1643 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0598s\n",
      "control8 Epoch: 0390 loss_train: 0.0001 loss_kl_train: 78.3208 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0201s\n",
      "control8 Epoch: 0391 loss_train: 0.0001 loss_kl_train: 78.8144 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0677s\n",
      "control8 Epoch: 0392 loss_train: 0.0001 loss_kl_train: 79.3389 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0756s\n",
      "control8 Epoch: 0393 loss_train: 0.0001 loss_kl_train: 169.3942 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0766s\n",
      "control8 Epoch: 0394 loss_train: 0.0001 loss_kl_train: 82.7317 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0646s\n",
      "control8 Epoch: 0395 loss_train: 0.0000 loss_kl_train: 79.6574 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0505s\n",
      "control8 Epoch: 0396 loss_train: 0.0001 loss_kl_train: 125.2364 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0974s\n",
      "control8 Epoch: 0397 loss_train: 0.0001 loss_kl_train: 231.0292 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0886s\n",
      "control8 Epoch: 0398 loss_train: 0.0000 loss_kl_train: 78.9743 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.0795s\n",
      "control8 Epoch: 0399 loss_train: 0.0001 loss_kl_train: 82.2078 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 80.1171s\n",
      "control13 Epoch: 0400 loss_train: 0.0001 loss_kl_train: 204.3263 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.0834s\n",
      "control13 Epoch: 0401 loss_train: 0.0001 loss_kl_train: 119.4102 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 77.8366s\n",
      "control13 Epoch: 0402 loss_train: 0.0001 loss_kl_train: 114.4955 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0022s\n",
      "control13 Epoch: 0403 loss_train: 0.0001 loss_kl_train: 83.0824 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0386s\n",
      "control13 Epoch: 0404 loss_train: 0.0001 loss_kl_train: 134.5540 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0555s\n",
      "control13 Epoch: 0405 loss_train: 0.0014 loss_kl_train: 12706.7770 loss_x_train: 0.0001 loss_x_val: 0.0005 time: 78.0426s\n",
      "control13 Epoch: 0406 loss_train: 0.0001 loss_kl_train: 88.5636 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0370s\n",
      "control13 Epoch: 0407 loss_train: 0.0001 loss_kl_train: 88.5450 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0699s\n",
      "control13 Epoch: 0408 loss_train: 0.0001 loss_kl_train: 84.3149 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0832s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control13 Epoch: 0409 loss_train: 0.0001 loss_kl_train: 82.8335 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.0610s\n",
      "control13 Epoch: 0410 loss_train: 0.0001 loss_kl_train: 82.4433 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.0671s\n",
      "control13 Epoch: 0411 loss_train: 0.0001 loss_kl_train: 82.5345 loss_x_train: 0.0000 loss_x_val: 0.0003 time: 78.0573s\n",
      "control13 Epoch: 0412 loss_train: 0.0001 loss_kl_train: 82.6828 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0634s\n",
      "control13 Epoch: 0413 loss_train: 0.0001 loss_kl_train: 83.0577 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0462s\n",
      "control13 Epoch: 0414 loss_train: 0.0001 loss_kl_train: 83.6732 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0302s\n",
      "control13 Epoch: 0415 loss_train: 0.0001 loss_kl_train: 84.3001 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.0298s\n",
      "control13 Epoch: 0416 loss_train: 0.0012 loss_kl_train: 11683.2213 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.0303s\n",
      "control13 Epoch: 0417 loss_train: 0.0001 loss_kl_train: 83.8014 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.0411s\n",
      "control13 Epoch: 0418 loss_train: 0.0001 loss_kl_train: 102.4531 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.0205s\n",
      "control13 Epoch: 0419 loss_train: 0.0001 loss_kl_train: 82.6524 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 78.0303s\n",
      "disease13 Epoch: 0420 loss_train: 0.0001 loss_kl_train: 135.5154 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6326s\n",
      "disease13 Epoch: 0421 loss_train: 0.0018 loss_kl_train: 16986.5261 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.4140s\n",
      "disease13 Epoch: 0422 loss_train: 0.0002 loss_kl_train: 1223.1453 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.5571s\n",
      "disease13 Epoch: 0423 loss_train: 0.0001 loss_kl_train: 130.1130 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6240s\n",
      "disease13 Epoch: 0424 loss_train: 0.0004 loss_kl_train: 3228.0488 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6316s\n",
      "disease13 Epoch: 0425 loss_train: 0.0001 loss_kl_train: 112.5518 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.6644s\n",
      "disease13 Epoch: 0426 loss_train: 0.0010 loss_kl_train: 9782.0223 loss_x_train: 0.0001 loss_x_val: 0.0011 time: 88.6198s\n",
      "disease13 Epoch: 0427 loss_train: 0.0001 loss_kl_train: 649.7226 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6401s\n",
      "disease13 Epoch: 0428 loss_train: 0.0001 loss_kl_train: 134.2886 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.6365s\n",
      "disease13 Epoch: 0429 loss_train: 0.0001 loss_kl_train: 121.8554 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.6232s\n",
      "disease13 Epoch: 0430 loss_train: 0.0003 loss_kl_train: 2842.2832 loss_x_train: 0.0001 loss_x_val: 0.0006 time: 88.6047s\n",
      "disease13 Epoch: 0431 loss_train: 0.0001 loss_kl_train: 144.3866 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6358s\n",
      "disease13 Epoch: 0432 loss_train: 0.0001 loss_kl_train: 112.3080 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.6510s\n",
      "disease13 Epoch: 0433 loss_train: 0.0001 loss_kl_train: 267.9473 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.6727s\n",
      "disease13 Epoch: 0434 loss_train: 0.0005 loss_kl_train: 4840.7571 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 88.6418s\n",
      "disease13 Epoch: 0435 loss_train: 0.0025 loss_kl_train: 24800.2790 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.6448s\n",
      "disease13 Epoch: 0436 loss_train: 0.0001 loss_kl_train: 119.9968 loss_x_train: 0.0000 loss_x_val: 0.0002 time: 88.6346s\n",
      "disease13 Epoch: 0437 loss_train: 1842516013.5399 loss_kl_train: 18425159564928860.0000 loss_x_train: 0.0003 loss_x_val: 0.0077 time: 88.5863s\n",
      "disease13 Epoch: 0438 loss_train: 1172.8792 loss_kl_train: 11728789472.3130 loss_x_train: 0.0003 loss_x_val: 0.0020 time: 88.6224s\n",
      "disease13 Epoch: 0439 loss_train: 0.0011 loss_kl_train: 10277.3617 loss_x_train: 0.0001 loss_x_val: 0.0013 time: 88.6431s\n",
      "disease8 Epoch: 0440 loss_train: 0.0020 loss_kl_train: 18798.3451 loss_x_train: 0.0001 loss_x_val: 0.0013 time: 78.2605s\n",
      "disease8 Epoch: 0441 loss_train: 0.0003 loss_kl_train: 1798.7062 loss_x_train: 0.0001 loss_x_val: 0.0003 time: 78.0305s\n",
      "disease8 Epoch: 0442 loss_train: 0.0353 loss_kl_train: 352231.8145 loss_x_train: 0.0001 loss_x_val: 0.0004 time: 78.2163s\n",
      "disease8 Epoch: 0443 loss_train: 0.0002 loss_kl_train: 1588.8314 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2106s\n",
      "disease8 Epoch: 0444 loss_train: 0.0002 loss_kl_train: 1555.8938 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2572s\n",
      "disease8 Epoch: 0445 loss_train: 0.0002 loss_kl_train: 1484.9763 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2337s\n",
      "disease8 Epoch: 0446 loss_train: 0.0002 loss_kl_train: 1443.6375 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2465s\n",
      "disease8 Epoch: 0447 loss_train: 0.0002 loss_kl_train: 1522.2075 loss_x_train: 0.0001 loss_x_val: 0.0002 time: 78.2316s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-70c45ff02cb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mtrain_loss_advD_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss_advD_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtrain_loss_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss_kl_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss_x_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss_x_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-70c45ff02cb3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mtrainInput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizerVAEXA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(modelsavepath,str(9360)+'.pt')))\n",
    "# epochs=20000\n",
    "if pretrainedAE:\n",
    "    print('loading '+pretrainedAE['name']+' epoch '+str(pretrainedAE['epoch']))\n",
    "    model.load_state_dict(torch.load(os.path.join('/mnt/xinyi/pamrats/models/train_gae_starmap/'+pretrainedAE['name'],str(pretrainedAE['epoch'])+'.pt')))\n",
    "    \n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    loss_kl_train_all=0\n",
    "    loss_x_train_all=0\n",
    "    loss_all=0\n",
    "    for batch_idx, trainInput in enumerate(trainInputloader):\n",
    "#         print(batch_idx)\n",
    "        if torch.sum(trainInput)==0:\n",
    "            print('all zeros '+str(batch_idx))\n",
    "\n",
    "        if use_cuda:\n",
    "            trainInput=trainInput.cuda().float()\n",
    "        optimizerVAEXA.zero_grad()\n",
    "\n",
    "        recon, z, mu, logvar = model(trainInput)\n",
    "\n",
    "        if adv and (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "            modelAdv.eval()\n",
    "            advOut=modelAdv(z)\n",
    "\n",
    "        loss_kl_train=loss_kl(mu, logvar)\n",
    "        loss_x_train=loss_x(recon, trainInput)\n",
    "        loss=loss_kl_train*kl_weight+loss_x_train \n",
    "        if torch.isnan(torch.sum(loss_kl_train)):\n",
    "            print('kl '+str(batch_idx))\n",
    "        if torch.isnan(torch.sum(mu)):\n",
    "            print('mu '+str(batch_idx))\n",
    "        if torch.isnan(torch.sum(logvar)):\n",
    "            print('logvar '+str(batch_idx))\n",
    "        if torch.isnan(torch.sum(z)):\n",
    "            print('z '+str(batch_idx))\n",
    "        if torch.isnan(torch.sum(loss_x_train)):\n",
    "            print('x loss '+str(batch_idx))\n",
    "        if torch.isnan(torch.sum(trainInput)):\n",
    "            print('x input '+str(batch_idx))\n",
    "        if torch.isnan(torch.sum(recon)):\n",
    "            print('x recon '+str(batch_idx))\n",
    "        \n",
    "        \n",
    "        loss_kl_train_all+=loss_kl_train.item()\n",
    "        loss_x_train_all+=loss_x_train.item()\n",
    "        loss_all+=loss.item()\n",
    "        \n",
    "        if adv and (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "            loss_adv_train=loss_adv(advOut,sampleLabel_ae,train_nodes_idx)\n",
    "            loss+=loss_adv_train*advWeight\n",
    "        loss.backward()\n",
    "        optimizerVAEXA.step()\n",
    "\n",
    "    loss_kl_train_all=loss_kl_train_all/len(trainInputloader.dataset)\n",
    "    loss_x_train_all=loss_x_train_all/len(trainInputloader.dataset)\n",
    "    loss_all=loss_all/len(trainInputloader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    loss_x_val_all=0\n",
    "    for batch_idx, valInput in enumerate(valInputloader):\n",
    "        if use_cuda:\n",
    "            valInput=valInput.cuda().float()\n",
    "        recon,z, mu, logvar = model(valInput)\n",
    "\n",
    "        if adv and (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "            advOut=modelAdv(z)\n",
    "\n",
    "        loss_x_val_all+=loss_x(recon, valInput).item()\n",
    "\n",
    "        if adv and (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "            loss_adv_val=loss_adv(advOut,sampleLabel_ae,val_nodes_idx)\n",
    "            loss_val+=loss_adv_val*advWeight\n",
    "    loss_x_val_all=loss_x_val_all/len(valInputloader.dataset)\n",
    "    \n",
    "    print(training_samples_t+' Epoch: {:04d}'.format(epoch),\n",
    "          'loss_train: {:.4f}'.format(loss_all),\n",
    "          'loss_kl_train: {:.4f}'.format(loss_kl_train_all),\n",
    "          'loss_x_train: {:.4f}'.format(loss_x_train_all),\n",
    "          'loss_x_val: {:.4f}'.format(loss_x_val_all),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    if adv and (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "        print('loss_adv_train: {:.4f}'.format(loss_adv_train.item()),\n",
    "              'loss_adv_val: {:.4f}'.format(loss_adv_val.item())\n",
    "             )\n",
    "#     return loss.item(),loss_x_train.item(),loss_val.item(),loss_x_val.item()\n",
    "#     return loss.item(),loss_kl_train.item(),loss_x_train.item(),loss_val.item(),loss_x_val.item()\n",
    "    if adv:\n",
    "        if (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "            return float(loss),float(loss_kl_train),float(loss_x_train),float(loss_a_train),float(loss_val),float(loss_x_val),float(loss_a_val),float(loss_adv_train),float(loss_adv_val)        \n",
    "        else:\n",
    "            return float(loss),float(loss_kl_train),float(loss_x_train),float(loss_a_train),float(loss_val),float(loss_x_val),float(loss_a_val),None,None   \n",
    "    else:\n",
    "        return loss_all,loss_kl_train_all,loss_x_train_all,loss_x_val_all      \n",
    "\n",
    "def train_discriminator(epoch):\n",
    "    t = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    if adj_decodeName==None:\n",
    "        adj_recon,mu,logvar,z,features_recon = model(features, adj_norm)\n",
    "    #     features_recon, z, mu, logvar=model(features.float())\n",
    "    else:\n",
    "        adj_recon,mu,logvar,z,features_recon = model(features, adj_norm,adj_decode)\n",
    "        \n",
    "    \n",
    "    if clf:\n",
    "        modelClf.eval()\n",
    "        clfOut=modelClf(z)\n",
    "        \n",
    "    modelAdv.train()\n",
    "    optimizerAdv.zero_grad()\n",
    "    advOut=modelAdv(z)\n",
    "    \n",
    "    loss_adv_train=loss_adv(advOut,sampleLabel_d,train_nodes_idx)\n",
    "    loss = loss_adv_train*advWeight\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizerAdv.step()\n",
    "\n",
    "    modelAdv.eval()\n",
    "    advOut=modelAdv(z)\n",
    "    loss_adv_val=loss_adv(advOut,sampleLabel_d,val_nodes_idx)\n",
    "    loss_val=loss_adv_val*advWeight\n",
    "    print(training_samples_t+' Epoch: {:04d}'.format(epoch),\n",
    "          'loss_adv_train: {:.4f}'.format(loss_adv_train.item()),\n",
    "          'loss_adv_val: {:.4f}'.format(loss_adv_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    return float(loss_adv_train),float(loss_adv_val)\n",
    "    \n",
    "train_loss_ep=[None]*epochs\n",
    "train_loss_kl_ep=[None]*epochs\n",
    "train_loss_x_ep=[None]*epochs\n",
    "train_loss_adv_ep=[None]*epochs\n",
    "train_loss_advD_ep=[None]*epochs\n",
    "val_loss_x_ep=[None]*epochs\n",
    "val_loss_adv_ep=[None]*epochs\n",
    "val_loss_advD_ep=[None]*epochs\n",
    "t_ep=time.time()\n",
    "\n",
    "for ep in range(epochs):\n",
    "# for ep in range(10000,20000):\n",
    "    t=int(ep/switchFreq)%len(training_samples)\n",
    "    training_samples_t=training_samples[t]\n",
    "    \n",
    "    trainInputnp, valInputnp, _=imageslist[training_samples_t]\n",
    "    if adv and (training_samples_t in list(sampleLabellist_ae.keys())):\n",
    "#         sampleLabel_ae=sampleLabellist_ae[training_samples_t]\n",
    "#         sampleLabel_d=sampleLabellist_d[training_samples_t]\n",
    "        sampleLabel_ae=sampleLabellist_ae[training_samples_t].cuda().float()\n",
    "        sampleLabel_d=sampleLabellist_d[training_samples_t].cuda().float()\n",
    "    \n",
    "    trainInputloader=DataLoader(trainInputnp, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    valInputloader=DataLoader(valInputnp, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    \n",
    "    \n",
    "    if adv:\n",
    "        train_loss_ep[ep],train_loss_kl_ep[ep],train_loss_x_ep[ep],train_loss_a_ep[ep],val_loss_ep[ep],val_loss_x_ep[ep],val_loss_a_ep[ep],train_loss_adv_ep[ep],val_loss_adv_ep[ep]=train(ep)\n",
    "        if (training_samples_t in list(sampleLabellist_ae.keys())):\n",
    "            train_loss_advD_ep[ep],val_loss_advD_ep[ep]=train_discriminator(ep)\n",
    "    else:\n",
    "        train_loss_ep[ep],train_loss_kl_ep[ep],train_loss_x_ep[ep],val_loss_x_ep[ep]=train(ep)\n",
    "\n",
    "        \n",
    "    if ep%saveFreq == 0:\n",
    "        torch.save(model.cpu().state_dict(), os.path.join(modelsavepath,str(ep)+'.pt'))\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "print(' total time: {:.4f}s'.format(time.time() - t_ep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "with open(os.path.join(logsavepath,'train_loss'), 'wb') as output:\n",
    "    pickle.dump(train_loss_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath,'train_loss_kl'), 'wb') as output:\n",
    "    pickle.dump(train_loss_kl_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath,'train_loss_x'), 'wb') as output:\n",
    "    pickle.dump(train_loss_x_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath,'val_loss_x'), 'wb') as output:\n",
    "    pickle.dump(val_loss_x_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "if adv:\n",
    "    with open(os.path.join(logsavepath,'train_loss_adv'), 'wb') as output:\n",
    "        pickle.dump(train_loss_adv_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(logsavepath,'val_loss_adv'), 'wb') as output:\n",
    "        pickle.dump(val_loss_adv_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(logsavepath,'train_loss_advD'), 'wb') as output:\n",
    "        pickle.dump(train_loss_advD_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(logsavepath,'val_loss_advD'), 'wb') as output:\n",
    "        pickle.dump(val_loss_advD_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(os.path.join(logsavepath,'ct_unique'), 'wb') as output:\n",
    "#     pickle.dump(ct_unique, output, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(epochs),train_loss_x_ep)\n",
    "plt.plot(np.arange(epochs),val_loss_x_ep)\n",
    "# plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "# plt.ylim((0,0.01))\n",
    "# plt.xlim((0,3000))\n",
    "plt.legend(['training x recon loss','validation x recon loss','training kl loss'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath,'loss_seed3_x.jpg'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name='c13k20XA_07_dca'\n",
    "# logsavepath='/mnt/xinyi/pamrats/log/train_gae_starmap/'+name\n",
    "# with open(os.path.join(logsavepath,'val_loss_a'), 'rb') as output:\n",
    "#     val_loss_a_ep=pickle.load(output)\n",
    "np.argmin(val_loss_x_ep[:447])\n",
    "# np.where(np.logical_not(np.isfinite(val_loss_ep[:])))\n",
    "# val_loss_a_ep[8700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease13\n",
      "test results loss_x_test: 0.0002\n",
      "control13\n",
      "test results loss_x_test: 0.0002\n",
      "disease8\n",
      "test results loss_x_test: 0.0002\n",
      "control8\n",
      "test results loss_x_test: 0.0002\n"
     ]
    }
   ],
   "source": [
    "testepoch=400\n",
    "model.load_state_dict(torch.load(os.path.join(modelsavepath,str(testepoch)+'.pt')))\n",
    "model.eval()\n",
    "for s in sampleidx.keys():\n",
    "    print(s)\n",
    "    _, _, testInputnp=imageslist[s]\n",
    "    \n",
    "    testInputloader=DataLoader(testInputnp, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    \n",
    "    loss_x_test_all=0\n",
    "    for batch_idx, testInput in enumerate(testInputloader):\n",
    "        if use_cuda:\n",
    "            testInput=testInput.cuda().float()\n",
    "        recon,z, mu, logvar = model(testInput)\n",
    "        \n",
    "        if adv and (s in list(sampleLabellist_ae.keys())):\n",
    "            sampleLabel_ae=sampleLabellist_ae[s].cuda().float()\n",
    "            modelAdv.eval()\n",
    "            advOut=modelAdv(z)\n",
    "\n",
    "        loss_x_test_all+=loss_x(recon, testInput).item()\n",
    "    loss_x_test_all=loss_x_test_all/len(testInputloader.dataset)\n",
    "\n",
    "    if adv and (s in list(sampleLabellist_ae.keys())):\n",
    "        loss_adv_test=loss_adv(advOut,sampleLabel_ae,test_nodes_idx)\n",
    "        print('loss_adv_test: {:.4f}'.format(loss_adv_test.item()))\n",
    "        \n",
    "    print('test results',\n",
    "          'loss_x_test: {:.4f}'.format(loss_x_test_all))\n",
    "#          'loss_adv_test: {:.4f}'.format(loss_adv_test.item()))\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
