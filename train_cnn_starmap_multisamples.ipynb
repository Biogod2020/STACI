{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xinyiz/pamrats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is adapted from https://github.com/tkipf/gae/blob/master/gae/train.py and https://github.com/tkipf/pygcn/blob/master/pygcn/train.py##\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Train on CPU (hide GPU) due to memory constraints\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import average_precision_score\n",
    "\n",
    "import image.loadImage as loadImage\n",
    "import gae.gae.optimizer as optimizer\n",
    "import image.modelsCNN as modelsCNN\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/pamrats/image/loadImage.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  imagerc=(imagerc-imagercmin)/(imagercmax-imagercmin)\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "use_cuda=True\n",
    "fastmode=False #Validate during training pass\n",
    "seed=3\n",
    "epochs=10000\n",
    "saveFreq=20\n",
    "lr=0.001 #initial learning rate\n",
    "lr_adv=0.001\n",
    "weight_decay=0 #Weight for L2 loss on embedding matrix.\n",
    "\n",
    "batchsize=16\n",
    "kernel_size=4\n",
    "stride=2\n",
    "padding=1\n",
    "\n",
    "hidden1=128 #Number of channels in hidden layer 1\n",
    "hidden2=256 \n",
    "hidden3=512\n",
    "hidden4=1024\n",
    "hidden5=1024\n",
    "fc_dim1=1024*13*13\n",
    "fc_dim2=1024\n",
    "# fc_dim3=128\n",
    "# fc_dim4=128\n",
    "# gcn_dim1=2600\n",
    "adv_hidden=128\n",
    "\n",
    "dropout=0.01\n",
    "testNodes=0.1 #fraction of total nodes for testing\n",
    "valNodes=0.05 #fraction of total nodes for validation\n",
    "# clfweight=20\n",
    "advWeight=2\n",
    "# randFeatureSubset=None\n",
    "model_str='cnn_vae'\n",
    "adv=None  #'clf_fc1_eq'  #'clf_fc1_control_eq' #'clf_fc1_control'  #'clf_fc1'\n",
    "\n",
    "pretrainedAE=None #{'name':'controlphy5XAbin_01_dca','epoch':9990}\n",
    "training_samples=['control13','disease13','disease8','control8']\n",
    "# training_samples=['control13','control8']\n",
    "targetBatch=None\n",
    "switchFreq=100\n",
    "diamThresh_mul=416\n",
    "minThresh_mul=6\n",
    "name='all_thresh10min6_01'\n",
    "logsavepath='/mnt/xinyi/pamrats/log/train_cnn_starmap/'+name\n",
    "modelsavepath='/mnt/xinyi/pamrats/models/train_cnn_starmap/'+name\n",
    "plotsavepath='/mnt/xinyi/pamrats/plots/train_cnn_starmap/'+name\n",
    "\n",
    "#Load data\n",
    "sampleidx={'disease13':'AD_mouse9494','control13':'AD_mouse9498','disease8':'AD_mouse9723','control8':'AD_mouse9735'}\n",
    "datadir=os.path.join('/mnt/xinyi/2021-01-13-mAD-test-dataset')\n",
    "\n",
    "imageslist={}\n",
    "for s in sampleidx.keys():\n",
    "    imageslist[s]=loadImage.loadandsplit(sampleidx[s],datadir,diamThresh_mul,valNodes,testNodes,ifFlip=True,minCutoff=minThresh_mul,seed=seed)\n",
    "    \n",
    "if adv:\n",
    "    if 'control_eq' in adv:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['control13']=torch.tensor([0.5,0.5]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([0.5,0.5]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['control13']=torch.tensor([1,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,1]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "    elif 'control' in adv:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['control13']=torch.tensor([0,1]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([1,0]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['control13']=torch.tensor([1,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,1]).expand(adjnormlist['control8'].shape[0],-1)        \n",
    "    elif 'eq' in adv:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['disease13']=torch.tensor([0.5,0.5,0.5,0.5]).expand(adjnormlist['disease13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control13']=torch.tensor([0.5,0.5,0.5,0.5]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['disease8']=torch.tensor([0.5,0.5,0.5,0.5]).expand(adjnormlist['disease8'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([0.5,0.5,0.5,0.5]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['disease13']=torch.tensor([1,0,0,0]).expand(adjnormlist['disease13'].shape[0],-1)\n",
    "        sampleLabellist_d['control13']=torch.tensor([0,1,0,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['disease8']=torch.tensor([0,0,1,0]).expand(adjnormlist['disease8'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,0,0,1]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "    else:\n",
    "        sampleLabellist_ae={}\n",
    "        sampleLabellist_ae['disease13']=torch.tensor([0,1,1,1]).expand(adjnormlist['disease13'].shape[0],-1)\n",
    "        sampleLabellist_ae['control13']=torch.tensor([1,0,1,1]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_ae['disease8']=torch.tensor([1,1,0,1]).expand(adjnormlist['disease8'].shape[0],-1)\n",
    "        sampleLabellist_ae['control8']=torch.tensor([1,1,1,0]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "\n",
    "        sampleLabellist_d={}\n",
    "        sampleLabellist_d['disease13']=torch.tensor([1,0,0,0]).expand(adjnormlist['disease13'].shape[0],-1)\n",
    "        sampleLabellist_d['control13']=torch.tensor([0,1,0,0]).expand(adjnormlist['control13'].shape[0],-1)\n",
    "        sampleLabellist_d['disease8']=torch.tensor([0,0,1,0]).expand(adjnormlist['disease8'].shape[0],-1)\n",
    "        sampleLabellist_d['control8']=torch.tensor([0,0,0,1]).expand(adjnormlist['control8'].shape[0],-1)\n",
    "        \n",
    "# Set cuda and seed\n",
    "np.random.seed(seed)\n",
    "if use_cuda and (not torch.cuda.is_available()):\n",
    "    print('cuda not available')\n",
    "    use_cuda=False\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.enabled = True\n",
    "\n",
    "# Load data\n",
    "# if randFeatureSubset != None:\n",
    "#     idx=np.random.choice(features.shape[1],randFeatureSubset,replace=False)\n",
    "#     features=features[:,idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(logsavepath):\n",
    "    os.mkdir(logsavepath)\n",
    "if not os.path.exists(modelsavepath):\n",
    "    os.mkdir(modelsavepath)\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all train/validation sets\n",
    "\n",
    "mse=torch.nn.MSELoss()\n",
    "# mse=torch.nn.MSELoss(reduction=None)\n",
    "# Create model\n",
    "if model_str=='cnn_vae':\n",
    "    model = modelsCNN.CNN_VAE(kernel_size, stride, padding, 1, hidden1, hidden2, hidden3, hidden4, hidden5, fc_dim1,fc_dim2)\n",
    "    loss_kl=optimizer.optimizer_kl\n",
    "    loss_x=mse\n",
    "\n",
    "if adv=='clf_fc1' or adv=='clf_fc1_eq' or adv=='clf_fc1_control' or adv=='clf_fc1_control_eq':\n",
    "    modelAdv=gae.gae.model.Clf_fc1(hidden2, dropout,adv_hidden,sampleLabellist_ae['control13'].size()[1])\n",
    "    loss_adv=optimizer.optimizer_CEclf\n",
    "    \n",
    "if adv=='clf_linear1' or adv=='clf_linear1_control':\n",
    "    modelAdv=gae.gae.model.Clf_linear1(hidden2, dropout,sampleLabellist_ae['control13'].size()[1])\n",
    "    loss_adv=optimizer.optimizer_CEclf\n",
    "        \n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    if adv:\n",
    "        modelAdv.cuda()\n",
    "#         for sk in sampleLabellist_ae.keys():\n",
    "#             sampleLabellist_ae[sk]=sampleLabellist_ae[sk].cuda().float()\n",
    "#             sampleLabellist_d[sk]=sampleLabellist_d[sk].cuda().float()\n",
    "#     for fk in featureslist.keys():\n",
    "#         featureslist[fk] = featureslist[fk].cuda().float()\n",
    "#     for ak in adj_list.keys():\n",
    "#         adjnormlist[ak] =adjnormlist[ak].cuda()\n",
    "#         adj_list[ak] = adj_list[ak].cuda().float()\n",
    "#     if adj_decode is not None:\n",
    "#         adj_decode=adj_decode.cuda()\n",
    "    \n",
    "\n",
    "optimizerVAEXA = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "if adv:\n",
    "    optimizerAdv=optim.Adam(modelAdv.parameters(), lr=lr_adv, weight_decay=weight_decay)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 338.00 MiB (GPU 0; 11.91 GiB total capacity; 10.62 GiB already allocated; 192.56 MiB free; 558.16 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0e6ca9ae8510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mtrain_loss_advD_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss_advD_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mtrain_loss_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss_kl_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss_x_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_loss_x_ep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0e6ca9ae8510>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizerVAEXA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mrecon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madv\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtraining_samples_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampleLabellist_ae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtraining_samples_t\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtargetBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pamrats/image/modelsCNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pamrats/image/modelsCNN.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcD1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch2/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1695\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1696\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m     )\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 338.00 MiB (GPU 0; 11.91 GiB total capacity; 10.62 GiB already allocated; 192.56 MiB free; 558.16 MiB cached)"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(os.path.join(modelsavepath,str(9360)+'.pt')))\n",
    "# epochs=20000\n",
    "if pretrainedAE:\n",
    "    print('loading '+pretrainedAE['name']+' epoch '+str(pretrainedAE['epoch']))\n",
    "    model.load_state_dict(torch.load(os.path.join('/mnt/xinyi/pamrats/models/train_gae_starmap/'+pretrainedAE['name'],str(pretrainedAE['epoch'])+'.pt')))\n",
    "    \n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    \n",
    "    loss_kl_train_all=0\n",
    "    loss_x_train_all=0\n",
    "    loss_all=0\n",
    "    for batch_idx, trainInput in enumerate(trainInputloader):\n",
    "        print(batch_idx)\n",
    "        if use_cuda:\n",
    "            trainInput=trainInput.cuda().float()\n",
    "        optimizerVAEXA.zero_grad()\n",
    "\n",
    "        recon, z, mu, logvar = model(trainInput)\n",
    "\n",
    "        if adv and (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "            modelAdv.eval()\n",
    "            advOut=modelAdv(z)\n",
    "\n",
    "        loss_kl_train=loss_kl(mu, logvar)\n",
    "        loss_x_train=loss_x(recon, trainInput)\n",
    "        loss=loss_kl_train+loss_x_train \n",
    "\n",
    "        loss_kl_train_all+=loss_kl_train.item()\n",
    "        loss_x_train_all+=loss_x_train.item()\n",
    "        loss_all+=loss.item()\n",
    "        \n",
    "        if adv and (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "            loss_adv_train=loss_adv(advOut,sampleLabel_ae,train_nodes_idx)\n",
    "            loss+=loss_adv_train*advWeight\n",
    "        loss.backward()\n",
    "        optimizerVAEXA.step()\n",
    "\n",
    "    loss_kl_train_all=loss_kl_train_all/len(trainInputloader.dataset)\n",
    "    loss_x_train_all=loss_x_train_all/len(trainInputloader.dataset)\n",
    "    loss_all=loss_all/len(trainInputloader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    loss_x_val_all=0\n",
    "    for batch_idx, valInput in enumerate(valInputloader):\n",
    "        if use_cuda():\n",
    "            valInput=valInput.cuda().float()\n",
    "        recon,z, mu, logvar = model(valInput)\n",
    "\n",
    "        if adv and (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "            advOut=modelAdv(z)\n",
    "\n",
    "        loss_x_val_all+=loss_x(recon, valInput).item()\n",
    "\n",
    "        if adv and (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "            loss_adv_val=loss_adv(advOut,sampleLabel_ae,val_nodes_idx)\n",
    "            loss_val+=loss_adv_val*advWeight\n",
    "    loss_x_val_all=loss_x_val_all/len(valInputloader.dataset)\n",
    "    \n",
    "    print(training_samples_t+' Epoch: {:04d}'.format(epoch),\n",
    "          'loss_train: {:.4f}'.format(loss_all),\n",
    "          'loss_kl_train: {:.4f}'.format(loss_kl_train_all),\n",
    "          'loss_x_train: {:.4f}'.format(loss_x_train_all),\n",
    "          'loss_x_val: {:.4f}'.format(loss_x_val_all),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    if adv and (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "        print('loss_adv_train: {:.4f}'.format(loss_adv_train.item()),\n",
    "              'loss_adv_val: {:.4f}'.format(loss_adv_val.item())\n",
    "             )\n",
    "#     return loss.item(),loss_x_train.item(),loss_val.item(),loss_x_val.item()\n",
    "#     return loss.item(),loss_kl_train.item(),loss_x_train.item(),loss_val.item(),loss_x_val.item()\n",
    "    if adv:\n",
    "        if (training_samples_t in list(sampleLabellist_ae.keys())) and (training_samples_t != targetBatch):\n",
    "            return float(loss),float(loss_kl_train),float(loss_x_train),float(loss_a_train),float(loss_val),float(loss_x_val),float(loss_a_val),float(loss_adv_train),float(loss_adv_val)        \n",
    "        else:\n",
    "            return float(loss),float(loss_kl_train),float(loss_x_train),float(loss_a_train),float(loss_val),float(loss_x_val),float(loss_a_val),None,None   \n",
    "    else:\n",
    "        return loss_all,loss_kl_train_all,loss_x_train_all,loss_x_val_all      \n",
    "\n",
    "def train_discriminator(epoch):\n",
    "    t = time.time()\n",
    "    model.eval()\n",
    "    \n",
    "    if adj_decodeName==None:\n",
    "        adj_recon,mu,logvar,z,features_recon = model(features, adj_norm)\n",
    "    #     features_recon, z, mu, logvar=model(features.float())\n",
    "    else:\n",
    "        adj_recon,mu,logvar,z,features_recon = model(features, adj_norm,adj_decode)\n",
    "        \n",
    "    \n",
    "    if clf:\n",
    "        modelClf.eval()\n",
    "        clfOut=modelClf(z)\n",
    "        \n",
    "    modelAdv.train()\n",
    "    optimizerAdv.zero_grad()\n",
    "    advOut=modelAdv(z)\n",
    "    \n",
    "    loss_adv_train=loss_adv(advOut,sampleLabel_d,train_nodes_idx)\n",
    "    loss = loss_adv_train*advWeight\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizerAdv.step()\n",
    "\n",
    "    modelAdv.eval()\n",
    "    advOut=modelAdv(z)\n",
    "    loss_adv_val=loss_adv(advOut,sampleLabel_d,val_nodes_idx)\n",
    "    loss_val=loss_adv_val*advWeight\n",
    "    print(training_samples_t+' Epoch: {:04d}'.format(epoch),\n",
    "          'loss_adv_train: {:.4f}'.format(loss_adv_train.item()),\n",
    "          'loss_adv_val: {:.4f}'.format(loss_adv_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    return float(loss_adv_train),float(loss_adv_val)\n",
    "    \n",
    "# print('cross-validation ',seti)\n",
    "train_loss_ep=[None]*epochs\n",
    "train_loss_kl_ep=[None]*epochs\n",
    "train_loss_x_ep=[None]*epochs\n",
    "train_loss_adv_ep=[None]*epochs\n",
    "train_loss_advD_ep=[None]*epochs\n",
    "val_loss_x_ep=[None]*epochs\n",
    "val_loss_adv_ep=[None]*epochs\n",
    "val_loss_advD_ep=[None]*epochs\n",
    "t_ep=time.time()\n",
    "\n",
    "for ep in range(epochs):\n",
    "# for ep in range(10000,20000):\n",
    "    t=int(ep/switchFreq)%len(training_samples)\n",
    "    training_samples_t=training_samples[t]\n",
    "    \n",
    "    trainInputnp, valInputnp, _=imageslist[training_samples_t]\n",
    "    if adv and (training_samples_t in list(sampleLabellist_ae.keys())):\n",
    "#         sampleLabel_ae=sampleLabellist_ae[training_samples_t]\n",
    "#         sampleLabel_d=sampleLabellist_d[training_samples_t]\n",
    "        sampleLabel_ae=sampleLabellist_ae[training_samples_t].cuda().float()\n",
    "        sampleLabel_d=sampleLabellist_d[training_samples_t].cuda().float()\n",
    "    \n",
    "    trainInputloader=DataLoader(trainInputnp, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    valInputloader=DataLoader(valInputnp, batch_size=batchsize, drop_last=False, shuffle=False)\n",
    "    \n",
    "    \n",
    "    if adv:\n",
    "        train_loss_ep[ep],train_loss_kl_ep[ep],train_loss_x_ep[ep],train_loss_a_ep[ep],val_loss_ep[ep],val_loss_x_ep[ep],val_loss_a_ep[ep],train_loss_adv_ep[ep],val_loss_adv_ep[ep]=train(ep)\n",
    "        if (training_samples_t in list(sampleLabellist_ae.keys())):\n",
    "            train_loss_advD_ep[ep],val_loss_advD_ep[ep]=train_discriminator(ep)\n",
    "    else:\n",
    "        train_loss_ep[ep],train_loss_kl_ep[ep],train_loss_x_ep[ep],val_loss_x_ep[ep]=train(ep)\n",
    "\n",
    "        \n",
    "    if ep%saveFreq == 0:\n",
    "        torch.save(model.cpu().state_dict(), os.path.join(modelsavepath,str(ep)+'.pt'))\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "        torch.cuda.empty_cache()\n",
    "print(' total time: {:.4f}s'.format(time.time() - t_ep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(logsavepath,'train_loss'), 'rb') as input:\n",
    "#     train_loss_ep[:9360]=pickle.load(input)\n",
    "# with open(os.path.join(logsavepath,'train_loss_kl'), 'rb') as input:\n",
    "#     train_loss_kl_ep[:9360]=pickle.load(input)\n",
    "# with open(os.path.join(logsavepath,'train_loss_x'), 'rb') as input:\n",
    "#     train_loss_x_ep[:9360]=pickle.load(input)\n",
    "# with open(os.path.join(logsavepath,'train_loss_a'), 'rb') as input:\n",
    "#     train_loss_a_ep[:9360]=pickle.load(input)\n",
    "# with open(os.path.join(logsavepath,'val_loss'), 'rb') as input:\n",
    "#     val_loss_ep[:9360]=pickle.load(input)\n",
    "# with open(os.path.join(logsavepath,'val_loss_x'), 'rb') as input:\n",
    "#     val_loss_x_ep[:9360]=pickle.load(input)\n",
    "# with open(os.path.join(logsavepath,'val_loss_a'), 'rb') as input:\n",
    "#     val_loss_a_ep[:9360]=pickle.load(input)\n",
    "# with open(os.path.join(logsavepath,'train_loss_adv'), 'rb') as input:\n",
    "#     train_loss_adv_ep[:9360]=pickle.load(input)\n",
    "# with open(os.path.join(logsavepath,'val_loss_adv'), 'rb') as input:\n",
    "#     val_loss_adv_ep[:9360]=pickle.load(input)\n",
    "# with open(os.path.join(logsavepath,'train_loss_advD'), 'rb') as input:\n",
    "#     train_loss_advD_ep[:9360]=pickle.load(input)\n",
    "# with open(os.path.join(logsavepath,'val_loss_advD'), 'rb') as input:\n",
    "#     val_loss_advD_ep[:9360]=pickle.load(input)\n",
    "    \n",
    "with open(os.path.join(logsavepath,'train_loss'), 'wb') as output:\n",
    "    pickle.dump(train_loss_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath,'train_loss_kl'), 'wb') as output:\n",
    "    pickle.dump(train_loss_kl_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath,'train_loss_x'), 'wb') as output:\n",
    "    pickle.dump(train_loss_x_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(logsavepath,'val_loss_x'), 'wb') as output:\n",
    "    pickle.dump(val_loss_x_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "if adv:\n",
    "    with open(os.path.join(logsavepath,'train_loss_adv'), 'wb') as output:\n",
    "        pickle.dump(train_loss_adv_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(logsavepath,'val_loss_adv'), 'wb') as output:\n",
    "        pickle.dump(val_loss_adv_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(logsavepath,'train_loss_advD'), 'wb') as output:\n",
    "        pickle.dump(train_loss_advD_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(os.path.join(logsavepath,'val_loss_advD'), 'wb') as output:\n",
    "        pickle.dump(val_loss_advD_ep, output, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(os.path.join(logsavepath,'ct_unique'), 'wb') as output:\n",
    "#     pickle.dump(ct_unique, output, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(epochs),train_loss_ep)\n",
    "# plt.plot(np.arange(epochs),val_loss_ep)\n",
    "plt.plot(np.arange(epochs),train_loss_x_ep)\n",
    "plt.plot(np.arange(epochs),val_loss_x_ep)\n",
    "plt.plot(np.arange(epochs),train_loss_kl_ep)\n",
    "# plt.plot(np.arange(epochs),np.array(train_loss_adv_ep)*advWeight)\n",
    "# plt.plot(np.arange(epochs),np.array(val_loss_adv_ep)*advWeight)\n",
    "# plt.plot(np.arange(epochs),np.array(train_loss_advD_ep)*advWeight)\n",
    "# plt.plot(np.arange(epochs),np.array(val_loss_advD_ep)*advWeight)\n",
    "# plt.ylim((0,15))\n",
    "# plt.xlim((0,3000))\n",
    "# plt.legend(['training loss','validation loss','training x recon loss','validation x recon loss','training kl loss'],loc='upper right')\n",
    "# plt.legend(['training x recon loss','validation x recon loss','training a recon loss','validation a recon loss','training kl loss','training classifier loss','validation classifier loss'],loc='upper right')\n",
    "plt.legend(['training x recon loss','validation x recon loss','training kl loss','training discriminator ae','validation discriminator ae','training discriminator d','validation discriminator d'],loc='upper right')\n",
    "# plt.legend(['training loss','validation loss','training x recon loss','validation x recon loss','training a recon loss','validation a recon loss','training kl loss','training discriminator ae','validation discriminator ae','training discriminator d','validation discriminator d'],loc='upper right')\n",
    "plt.savefig(os.path.join(plotsavepath,'loss_seed3_xa.jpg'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41656726598739624"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name='c13k20XA_07_dca'\n",
    "# logsavepath='/mnt/xinyi/pamrats/log/train_gae_starmap/'+name\n",
    "# with open(os.path.join(logsavepath,'val_loss_a'), 'rb') as output:\n",
    "#     val_loss_a_ep=pickle.load(output)\n",
    "np.argmin(val_loss_x_ep[:])\n",
    "# np.where(np.logical_not(np.isfinite(val_loss_ep[:])))\n",
    "val_loss_a_ep[8700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease13\n",
      "loss_adv_test: 0.8363\n",
      "test results loss_test: 1.9879 loss_x_test: 1.4408 loss_a_test: 0.5471\n",
      "control13\n",
      "loss_adv_test: 0.8378\n",
      "test results loss_test: 1.8927 loss_x_test: 1.3481 loss_a_test: 0.5446\n",
      "disease8\n",
      "loss_adv_test: 0.8383\n",
      "test results loss_test: 1.7926 loss_x_test: 1.2689 loss_a_test: 0.5237\n",
      "control8\n",
      "loss_adv_test: 0.8379\n",
      "test results loss_test: 1.9069 loss_x_test: 1.3716 loss_a_test: 0.5353\n"
     ]
    }
   ],
   "source": [
    "testepoch=9990\n",
    "model.load_state_dict(torch.load(os.path.join(modelsavepath,str(testepoch)+'.pt')))\n",
    "model.eval()\n",
    "for s in sampleidx.keys():\n",
    "    print(s)\n",
    "    \n",
    "    adj_norm=adjnormlist[s].cuda().float()\n",
    "    adj_label=adj_list[s].cuda().float()\n",
    "    features=featureslist[s+'X_'+training_sample_X].cuda().float()\n",
    "    pos_weight=pos_weightlist[s]\n",
    "    norm=normlist[s]\n",
    "    \n",
    "    if 'dca' in model_str:\n",
    "        features_raw=features_raw_list[s+'X_raw'].cuda()\n",
    "    num_nodes,num_features = features.shape\n",
    "    maskpath=os.path.join(savedir,'trainMask',s+'_'+maskedgeName+'_seed'+str(seed)+'.pkl')\n",
    "    if useSavedMaskedEdges and os.path.exists(maskpath):\n",
    "#         print('opening saved')\n",
    "        with open(maskpath, 'rb') as input:\n",
    "            maskedgeres = pickle.load(input)\n",
    "    else:\n",
    "        # construct training, validation, and test sets\n",
    "        maskedgeres= preprocessing.mask_nodes_edges(features.shape[0],testNodeSize=testNodes,valNodeSize=valNodes)\n",
    "        with open(maskpath, 'wb') as output:\n",
    "            pickle.dump(maskedgeres, output, pickle.HIGHEST_PROTOCOL)\n",
    "    train_nodes_idx,val_nodes_idx,test_nodes_idx = maskedgeres\n",
    "    \n",
    "    if s in training_samples:\n",
    "        test_nodes_idx_s=test_nodes_idx\n",
    "    else:\n",
    "        test_nodes_idx_s=torch.tensor(np.arange(num_nodes))\n",
    "        \n",
    "#     adj_decode=None\n",
    "#     if adj_decodeName == 'gala':\n",
    "#         adj_decode=preprocessing.preprocess_graph_sharp(adj)\n",
    "\n",
    "    if adj_decodeName==None:\n",
    "        adj_recon,mu,logvar,z, features_recon = model(features, adj_norm)\n",
    "    else:\n",
    "        adj_decode=adj_decode.cuda()\n",
    "        adj_recon,mu,logvar,z, features_recon = model(features, adj_norm,adj_decode)\n",
    "    if adv and (s in list(sampleLabellist_ae.keys())):\n",
    "        sampleLabel_ae=sampleLabellist_ae[s].cuda().float()\n",
    "        modelAdv.eval()\n",
    "        advOut=modelAdv(z)\n",
    "    if 'dca' in model_str:\n",
    "        if 'NB' in name:\n",
    "            loss_x_test=loss_x(features_recon, features,test_nodes_idx,XreconWeight)\n",
    "        else:\n",
    "            loss_x_test=loss_x(features_recon, features,test_nodes_idx_s,XreconWeight,ridgeL,features_raw)\n",
    "    else:\n",
    "        loss_x_test=loss_x(features_recon, features,test_nodes_idx_s,XreconWeight,mse)\n",
    "    loss_a_test=loss_a(adj_recon, adj_label, pos_weight, norm,test_nodes_idx_s)\n",
    "    loss_test = loss_x_test+loss_a_test\n",
    "    \n",
    "    if adv and (s in list(sampleLabellist_ae.keys())):\n",
    "        loss_adv_test=loss_adv(advOut,sampleLabel_ae,test_nodes_idx)\n",
    "        print('loss_adv_test: {:.4f}'.format(loss_adv_test.item()))\n",
    "        \n",
    "    print('test results',\n",
    "          'loss_test: {:.4f}'.format(loss_test.item()),\n",
    "          'loss_x_test: {:.4f}'.format(loss_x_test.item()),\n",
    "          'loss_a_test: {:.4f}'.format(loss_a_test.item()))\n",
    "#          'loss_adv_test: {:.4f}'.format(loss_adv_test.item()))\n",
    "    if protein:\n",
    "        test_nodes_idx_s_genes=torch.clone(test_nodes_idx_s)\n",
    "        test_nodes_idx_s_genes[2112:]=0\n",
    "        test_nodes_idx_s_proteins=torch.clone(test_nodes_idx_s)\n",
    "        test_nodes_idx_s_proteins[:2112]=0\n",
    "        if 'dca' in model_str:\n",
    "            loss_genes_test=loss_x(features_recon, features,test_nodes_idx_s_genes,XreconWeight,ridgeL,features_raw)\n",
    "            loss_proteins_test=loss_x(features_recon, features,test_nodes_idx_s_proteins,XreconWeight,ridgeL,features_raw)\n",
    "        print('loss_x_genes: {:.4f}'.format(loss_genes_test.item()),\n",
    "          'loss_x_proteins: {:.4f}'.format(loss_proteins_test.item()))\n",
    "    if 'dca' in model_str:\n",
    "        features_raw=features_raw.cpu()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=features\n",
    "y_true_raw=features_raw\n",
    "preds=features_recon\n",
    "mask=nodesmask=torch.tensor(np.arange(num_nodes))\n",
    "reconWeight=20\n",
    "eps = 1e-10\n",
    "\n",
    "output,pi,theta,y_pred=preds\n",
    "nb_case=optimizer.optimizer_nb(preds,y_true,mask,reconWeight,eps = 1e-10,ifmean=False)- torch.log(pi+eps)\n",
    "\n",
    "zero_nb = torch.pow(theta/(theta+y_pred+eps), theta)\n",
    "zero_case = -torch.log(pi + ((1.0-pi)*zero_nb)+eps)\n",
    "result = torch.where(torch.lt(y_true_raw.cuda(), 1), zero_case, nb_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000e+00, 2.1077e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00],\n",
       "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00],\n",
       "        [1.1921e-07, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         1.1921e-07, -0.0000e+00],\n",
       "        [1.7968e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, 1.7740e+00,\n",
       "         1.1915e+00, -0.0000e+00],\n",
       "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         1.1921e-07, -0.0000e+00],\n",
       "        [1.1921e-07, 1.1921e-07, 1.1921e-07, -0.0000e+00, 1.1921e-07, 1.1921e-07,\n",
       "         1.1921e-07, 1.1921e-07],\n",
       "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00],\n",
       "        [-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
       "         1.4272e+00, -0.0000e+00]], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:8,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2504,  8.5853, -0.1941, -0.1474, -0.1934, -0.2717, -0.5645, -0.3465],\n",
       "        [-0.2504, -0.1938, -0.1941, -0.1474, -0.1934, -0.2717, -0.5645, -0.3465],\n",
       "        [-0.2504, -0.1938, -0.1941, -0.1474, -0.1934, -0.2717, -0.5645, -0.3465],\n",
       "        [ 5.5540, -0.1938, -0.1941, -0.1474, -0.1934,  3.1612,  1.2601, -0.3465],\n",
       "        [-0.2504, -0.1938, -0.1941, -0.1474, -0.1934, -0.2717, -0.5645, -0.3465],\n",
       "        [-0.2504, -0.1938, -0.1941, -0.1474, -0.1934, -0.2717, -0.5645, -0.3465],\n",
       "        [-0.2504, -0.1938, -0.1941, -0.1474, -0.1934, -0.2717, -0.5645, -0.3465],\n",
       "        [-0.2504, -0.1938, -0.1941, -0.1474, -0.1934, -0.2717,  2.5718, -0.3465]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:8,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8589e-09, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroidx=(features_raw==0)\n",
    "nonzeroidx=(features_raw!=0)\n",
    "torch.sum(result[zeroidx])/torch.sum(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(result[zeroidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4cb07b2960f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model.pi.weight[:8,:8]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_str' is not defined"
     ]
    }
   ],
   "source": [
    "# model.pi.weight[:8,:8]\n",
    "model_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
