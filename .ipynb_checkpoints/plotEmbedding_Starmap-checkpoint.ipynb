{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xinyiz/pamrats')\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import average_precision_score\n",
    "\n",
    "import gae.gae.optimizer as optimizer\n",
    "import gae.gae.model\n",
    "import gae.gae.preprocessing as preprocessing\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverseAct='leakyRelu'\n",
    "# inverseAct=None\n",
    "plottype='pca'\n",
    "pca=PCA()\n",
    "use_cuda=True\n",
    "fastmode=False #Validate during training pass\n",
    "seed=3\n",
    "useSavedMaskedEdges=False\n",
    "maskedgeName='knn20_connectivity'\n",
    "plotepoch=1980\n",
    "hidden1=2048 #Number of units in hidden layer 1\n",
    "# hidden2=2048 #Number of units in hidden layer 2\n",
    "# hidden3=16\n",
    "fc_dim1=2048\n",
    "# fc_dim2=2112\n",
    "# fc_dim3=2112\n",
    "# fc_dim4=2112\n",
    "# gcn_dim1=2048\n",
    "\n",
    "dropout=0.01\n",
    "# randFeatureSubset=None\n",
    "model_str='fc1_dca'\n",
    "adj_decodeName=None #gala or None\n",
    "plot_samples={'disease13':'AD_mouse9494','control13':'AD_mouse9498','disease8':'AD_mouse9723','control8':'AD_mouse9735'}\n",
    "# plot_sample_X=['logminmax']\n",
    "plot_sample_X=['corrected','scaled']\n",
    "standardizeX=False\n",
    "name='c13k20XA_FCXonly_02_dca'\n",
    "logsavepath='/mnt/xinyi/pamrats/log/train_gae_starmap/'+name\n",
    "modelsavepath='/mnt/xinyi/pamrats/models/train_gae_starmap/'+name\n",
    "plotsavepath='/mnt/xinyi/pamrats/plots/train_gae_starmap/'+name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cuda and seed\n",
    "np.random.seed(seed)\n",
    "if use_cuda and (not torch.cuda.is_available()):\n",
    "    print('cuda not available')\n",
    "    use_cuda=False\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "savedir=os.path.join('/mnt/xinyi/','starmap')\n",
    "adj_dir=os.path.join(savedir,'a')\n",
    "\n",
    "featureslist={}\n",
    "if plot_sample_X[0] in ['corrected','scaled']:\n",
    "    scaleddata=scanpy.read_h5ad('/mnt/xinyi/2021-01-13-mAD-test-dataset/2020-12-27-starmap-mAD-scaled.h5ad')\n",
    "    for s in plot_samples.keys():\n",
    "        featureslist[s+'X_'+'corrected']=torch.tensor(scaleddata.layers['corrected'][scaleddata.obs['sample']==plot_samples[s]])\n",
    "        featureslist[s+'X_'+'scaled']=torch.tensor(scaleddata.layers['scaled'][scaleddata.obs['sample']==plot_samples[s]])\n",
    "    \n",
    "else:\n",
    "    scaleddata=scanpy.read_h5ad('/mnt/xinyi/2021-01-13-mAD-test-dataset/2020-12-27-starmap-mAD-raw.h5ad')\n",
    "    \n",
    "    for s in plot_samples.keys():\n",
    "        scaleddata_train=scaleddata.X[scaleddata.obs['sample']==plot_samples[s]]\n",
    "\n",
    "        if plot_sample_X[0]=='logminmax':\n",
    "            featurelog_train=np.log2(scaleddata_train+1/2)\n",
    "            scaler = MinMaxScaler()\n",
    "            featurelog_train_minmax=np.transpose(scaler.fit_transform(np.transpose(featurelog_train)))\n",
    "            featureslist[s+'X_'+plot_sample_X[0]]=torch.tensor(featurelog_train_minmax)\n",
    "\n",
    "\n",
    "adj_list={}\n",
    "adj_list['disease13']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9494.npz'))\n",
    "adj_list['control13']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9498.npz'))\n",
    "adj_list['disease8']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9723.npz'))\n",
    "adj_list['control8']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9735.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "num_nodes,num_features = list(featureslist.values())[0].shape\n",
    "if model_str=='gcn_vae_xa':\n",
    "    model  = gae.gae.model.GCNModelVAE_XA(num_features, hidden1, hidden2,fc_dim1,fc_dim2,fc_dim3,fc_dim4, dropout)\n",
    "elif model_str=='fc1':\n",
    "    model  = gae.gae.model.FCVAE1(num_features, hidden1,dropout)\n",
    "elif model_str == 'gcn_vae_xa_e2_d1':\n",
    "    model  = gae.gae.model.GCNModelVAE_XA_e2_d1(num_features, hidden1,hidden2, dropout)\n",
    "elif model_str == 'gcn_vae_gcnX_inprA':\n",
    "    model = gae.gae.model.GCNModelVAE_gcnX_inprA(num_features, hidden1, hidden2,gcn_dim1, dropout)\n",
    "elif model_str=='fc1_dca':\n",
    "    model = gae.gae.model.FCVAE1_DCA(num_features, hidden1,fc_dim1, dropout)\n",
    "model.load_state_dict(torch.load(os.path.join(modelsavepath,str(plotepoch)+'.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotembeddingbyCT(ctlist,savename,excludelist,embedding,savepath,plotname,plotdimx=0,plotdimy=1):\n",
    "    celltypes=np.unique(ctlist)\n",
    "    celltypes_dict={}\n",
    "    idx=0\n",
    "    for ct in celltypes:\n",
    "        celltypes_dict[ct]=idx\n",
    "        idx+=1\n",
    "        \n",
    "    colortest=sns.color_palette(\"husl\", celltypes.size)\n",
    "    np.random.shuffle(colortest)\n",
    "    fig, ax = plt.subplots(dpi=400)\n",
    "    for ct in celltypes:\n",
    "        if ct in excludelist:\n",
    "            continue\n",
    "        idx=(ctlist==ct)\n",
    "        ax.scatter(\n",
    "            embedding[idx, plotdimx],\n",
    "            embedding[idx, plotdimy],\n",
    "            color=colortest[celltypes_dict[ct]],label=ct,s=3,alpha=0.5\n",
    "            )\n",
    "\n",
    "    plt.gca().set_aspect('equal', 'datalim')\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(10)\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "    # Put a legend below current axis\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "              fancybox=True, shadow=True, ncol=5)\n",
    "#     ax.legend(ncol=3)\n",
    "    plt.title(plotname+' embedding', fontsize=24)\n",
    "    plt.savefig(os.path.join(savepath,savename+'.jpg'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-converter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotembeddingbyCT_contrast(ctlist,savename,excludelist,embedding,savepath,plotname,plotdimx=0,plotdimy=1): \n",
    "    celltypes=np.unique(ctlist)\n",
    "    celltypes_dict={}\n",
    "    idx=0\n",
    "    for ct in celltypes:\n",
    "        celltypes_dict[ct]=idx\n",
    "        idx+=1\n",
    "\n",
    "    colortest=sns.color_palette(\"tab10\")\n",
    "    if not os.path.exists(os.path.join(savepath)):\n",
    "        os.makedirs(savepath)\n",
    "\n",
    "    for ct in celltypes:\n",
    "        fig, ax = plt.subplots()\n",
    "        if ct == 'Unassigned':\n",
    "            continue\n",
    "\n",
    "        idx=(ctlist!=ct)\n",
    "        ax.scatter(\n",
    "            embedding[idx, plotdimx],\n",
    "            embedding[idx, plotdimy],\n",
    "            color=colortest[1],label='others',s=1,alpha=0.5\n",
    "            )\n",
    "\n",
    "        idx=(ctlist==ct)\n",
    "        ax.scatter(\n",
    "            embedding[idx, plotdimx],\n",
    "            embedding[idx, plotdimy],\n",
    "            color=colortest[0],label=ct,s=3,alpha=0.5\n",
    "            )\n",
    "\n",
    "        plt.gca().set_aspect('equal', 'datalim')\n",
    "        fig.set_figheight(10)\n",
    "        fig.set_figwidth(10)\n",
    "        ax.legend()\n",
    "        plt.title(plotname+' embedding', fontsize=24)\n",
    "        plt.gcf().savefig(os.path.join(savepath,savename+'_'+ct+'.jpg'))\n",
    "        plt.show()\n",
    "    #     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverseLeakyRelu(v,slope=0.01):\n",
    "    vnegidx=(v<0)\n",
    "    v[vnegidx]=1/slope*v[vnegidx]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in plot_samples.keys():\n",
    "    sampleidx=plot_samples[s]\n",
    "    adj=adj_list[s]\n",
    "    adj_norm = preprocessing.preprocess_graph(adj)\n",
    "    adj_decode=None\n",
    "    if adj_decodeName == 'gala':\n",
    "        adj_decode=preprocessing.preprocess_graph_sharp(adj)\n",
    "    celltype_broad=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']\n",
    "    celltype_sub=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'cell_type_label']\n",
    "    region=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']\n",
    "    for xcorr in plot_sample_X:\n",
    "        samplename=s+'X_'+xcorr\n",
    "        features=featureslist[samplename]\n",
    "        if standardizeX:\n",
    "            features=torch.tensor(scale(features,axis=0, with_mean=True, with_std=True, copy=True))\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "            features = features.cuda().float()\n",
    "            adj_norm=adj_norm.cuda()\n",
    "            if adj_decodeName:\n",
    "                adj_decode=adj_decode.cuda()\n",
    "        if inverseAct:\n",
    "            samplename+='_beforeAct'\n",
    "        sampledir=os.path.join(plotsavepath,samplename)\n",
    "        savedir=os.path.join(plotsavepath,samplename,'embedding_'+plottype)\n",
    "        if not os.path.exists(sampledir):\n",
    "            os.mkdir(sampledir)\n",
    "        if not os.path.exists(savedir):\n",
    "            os.mkdir(savedir)\n",
    "        \n",
    "        model.eval()\n",
    "        if adj_decodeName==None:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm)\n",
    "    #         features_recon, z, mu, logvar=model(features.float())\n",
    "        else:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm,adj_decode)\n",
    "        if inverseAct=='leakyRelu':\n",
    "            muplot=inverseLeakyRelu(mu.cpu().detach().numpy())\n",
    "        else:\n",
    "            muplot=mu.cpu().detach().numpy()\n",
    "            \n",
    "        if plottype=='umap':\n",
    "            reducer = umap.UMAP()\n",
    "            embedding = reducer.fit_transform(muplot)\n",
    "            \n",
    "        elif plottype=='pca':\n",
    "            embedding=pca.fit_transform(muplot)\n",
    "        \n",
    "        plotembeddingbyCT(celltype_broad,'celltype_broad',[],embedding,savedir,plottype+' of '+s)\n",
    "        plotembeddingbyCT(celltype_sub,'celltype_sub',[],embedding,savedir,plottype+' of '+s)\n",
    "        plotembeddingbyCT(region,'region',[],embedding,savedir,plottype+' of '+s)\n",
    "        \n",
    "        plotembeddingbyCT_contrast(celltype_sub,'celltype_sub',[],embedding,os.path.join(savedir,'contrast'),plottype+' of '+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate plots by region\n",
    "for s in plot_samples.keys():\n",
    "    sampleidx=plot_samples[s]\n",
    "    adj=adj_list[s]\n",
    "    adj_norm = preprocessing.preprocess_graph(adj)\n",
    "    if adj_decodeName == 'gala':\n",
    "        adj_decode=preprocessing.preprocess_graph_sharp(adj)\n",
    "    celltype_broad=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']\n",
    "    celltype_sub=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'cell_type_label']\n",
    "    region=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']\n",
    "    for xcorr in plot_sample_X:\n",
    "        samplename=s+'X_'+xcorr\n",
    "        features=featureslist[samplename]\n",
    "        if standardizeX:\n",
    "            features=torch.tensor(scale(features,axis=0, with_mean=True, with_std=True, copy=True))\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "            features = features.cuda().float()\n",
    "            adj_norm=adj_norm.cuda()\n",
    "            if adj_decodeName:\n",
    "                adj_decode=adj_decode.cuda()\n",
    "        if inverseAct:\n",
    "            samplename+='_beforeAct'\n",
    "        sampledir=os.path.join(plotsavepath,samplename)\n",
    "        if not os.path.exists(sampledir):\n",
    "            os.mkdir(sampledir)\n",
    "        model.eval()\n",
    "        if adj_decodeName==None:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm)\n",
    "    #         features_recon, z, mu, logvar=model(features.float())\n",
    "        else:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm,adj_decode)\n",
    "        \n",
    "        for reg in np.unique(region):\n",
    "            savedir=os.path.join(plotsavepath,samplename,'embedding_'+plottype+'_'+reg)\n",
    "            if not os.path.exists(savedir):\n",
    "                os.mkdir(savedir)\n",
    "            \n",
    "            reg_idx=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']==reg\n",
    "            \n",
    "            muplot=mu.cpu().detach().numpy()\n",
    "            if inverseAct=='leakyRelu':\n",
    "                muplot=inverseLeakyRelu(muplot)\n",
    "            if plottype=='umap':\n",
    "                reducer = umap.UMAP()\n",
    "                embedding = reducer.fit_transform(muplot[reg_idx])\n",
    "            elif plottype=='pca':\n",
    "                embedding=pca.fit_transform(muplot[reg_idx])\n",
    "                \n",
    "            \n",
    "            plotembeddingbyCT(celltype_broad[reg_idx],'celltype_broad',[],embedding,savedir,plottype+' of '+s+' '+reg)\n",
    "            plotembeddingbyCT(celltype_sub[reg_idx],'celltype_sub',[],embedding,savedir,plottype+' of '+s+' '+reg)\n",
    "#             plotembeddingbyCT(region,'region',[],embedding[reg_idx],savedir,'UMAP of '+s)\n",
    "\n",
    "            plotembeddingbyCT_contrast(celltype_sub[reg_idx],'celltype_sub',[],embedding,os.path.join(savedir,'contrast'),plottype+' of '+s+' '+reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all latents to one plot \n",
    "for xcorr in plot_sample_X:\n",
    "    latents=None\n",
    "    celltype_broad=None\n",
    "    celltype_sub=None\n",
    "    region=None\n",
    "    samplenameList=None\n",
    "    \n",
    "    for s in plot_samples.keys():\n",
    "        sampleidx=plot_samples[s]\n",
    "        adj=adj_list[s]\n",
    "        adj_norm = preprocessing.preprocess_graph(adj)\n",
    "        if adj_decodeName == 'gala':\n",
    "            adj_decode=preprocessing.preprocess_graph_sharp(adj)\n",
    "        \n",
    "        samplename=s+'X_'+xcorr\n",
    "        features=featureslist[samplename]\n",
    "        if standardizeX:\n",
    "            features=torch.tensor(scale(features,axis=0, with_mean=True, with_std=True, copy=True))\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "            features = features.cuda().float()\n",
    "            adj_norm=adj_norm.cuda()\n",
    "            if adj_decodeName:\n",
    "                adj_decode=adj_decode.cuda()\n",
    "        model.eval()\n",
    "        if adj_decodeName==None:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm)\n",
    "    #         features_recon, z, mu, logvar=model(features.float())\n",
    "        else:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm,adj_decode)\n",
    "            \n",
    "        if latents is None:\n",
    "            latents=mu.cpu().detach().numpy()\n",
    "            celltype_broad=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']\n",
    "            celltype_sub=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'cell_type_label']\n",
    "            region=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']\n",
    "            samplenameList=np.repeat(s,mu.shape[0])\n",
    "        else:\n",
    "            latents=np.vstack((latents,mu.cpu().detach().numpy()))\n",
    "            celltype_broad=np.concatenate((celltype_broad,scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']),axis=None)\n",
    "            celltype_sub=np.concatenate((celltype_sub,scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'cell_type_label']),axis=None)\n",
    "            region=np.concatenate((region,scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']),axis=None)\n",
    "            samplenameList=np.concatenate((samplenameList,np.repeat(s,mu.shape[0])),axis=None)\n",
    "        \n",
    "    sampledir=os.path.join(plotsavepath,'combined'+xcorr)\n",
    "    if inverseAct:\n",
    "        sampledir+='_beforeAct'\n",
    "    savedir=os.path.join(plotsavepath,'combined'+xcorr,'embedding_'+plottype)\n",
    "    if not os.path.exists(sampledir):\n",
    "        os.mkdir(sampledir)\n",
    "    if not os.path.exists(savedir):\n",
    "        os.mkdir(savedir)\n",
    "    \n",
    "    if inverseAct=='leakyRelu':\n",
    "        latents=inverseLeakyRelu(latents)\n",
    "    if plottype=='umap':\n",
    "        reducer = umap.UMAP()\n",
    "        embedding = reducer.fit_transform(latents)\n",
    "    elif plottype=='pca':\n",
    "        embedding=pca.fit_transform(latents)\n",
    "        \n",
    "    plotembeddingbyCT(samplenameList,'sample',[],embedding,savedir,'all samples')\n",
    "    plotembeddingbyCT(celltype_broad,'celltype_broad',[],embedding,savedir,'all samples')\n",
    "    plotembeddingbyCT(celltype_sub,'celltype_sub',[],embedding,savedir,'all samples')\n",
    "    plotembeddingbyCT(region,'region',[],embedding,savedir,'all samples')\n",
    "\n",
    "    plotembeddingbyCT_contrast(celltype_sub,'celltype_sub',[],embedding,os.path.join(savedir,'contrast'),'all samples')    \n",
    "    for reg in np.unique(region):\n",
    "        savedir=os.path.join(sampledir,'embedding_'+plottype+'_'+reg)\n",
    "        if not os.path.exists(savedir):\n",
    "            os.mkdir(savedir)\n",
    "\n",
    "        reg_idx=region==reg\n",
    "\n",
    "        if plottype=='umap':\n",
    "            reducer = umap.UMAP()\n",
    "            embedding = reducer.fit_transform(latents[reg_idx])\n",
    "        elif plottype=='pca':\n",
    "            embedding=pca.fit_transform(latents[reg_idx])\n",
    "        \n",
    "        plotembeddingbyCT(samplenameList[reg_idx],'sample',[],embedding,savedir,plottype+' of '+'all samples'+' '+reg)\n",
    "        plotembeddingbyCT(celltype_broad[reg_idx],'celltype_broad',[],embedding,savedir,plottype+' of '+'all samples'+' '+reg)\n",
    "        plotembeddingbyCT(celltype_sub[reg_idx],'celltype_sub',[],embedding,savedir,plottype+' of '+'all samples'+' '+reg)\n",
    "#             plotembeddingbyCT(region,'region',[],embedding[reg_idx],savedir,'UMAP of '+s)\n",
    "\n",
    "        plotembeddingbyCT_contrast(celltype_sub[reg_idx],'celltype_sub',[],embedding,os.path.join(savedir,'contrast'),plottype+' of '+'all samples'+' '+reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate plots by region and cell types\n",
    "for s in plot_samples.keys():\n",
    "    sampleidx=plot_samples[s]\n",
    "    adj=adj_list[s]\n",
    "    adj_norm = preprocessing.preprocess_graph(adj)\n",
    "    if adj_decodeName == 'gala':\n",
    "        adj_decode=preprocessing.preprocess_graph_sharp(adj)\n",
    "    celltype_broad=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']\n",
    "    celltype_sub=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'cell_type_label']\n",
    "    region=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']\n",
    "    for xcorr in plot_sample_X:\n",
    "        samplename=s+'X_'+xcorr\n",
    "        features=featureslist[samplename]\n",
    "        if standardizeX:\n",
    "            features=torch.tensor(scale(features,axis=0, with_mean=True, with_std=True, copy=True))\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "            features = features.cuda().float()\n",
    "            adj_norm=adj_norm.cuda()\n",
    "            if adj_decodeName:\n",
    "                adj_decode=adj_decode.cuda()\n",
    "        if inverseAct:\n",
    "            samplename+='_beforeAct'\n",
    "        sampledir=os.path.join(plotsavepath,samplename)\n",
    "        if not os.path.exists(sampledir):\n",
    "            os.mkdir(sampledir)\n",
    "        model.eval()\n",
    "        if adj_decodeName==None:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm)\n",
    "    #         features_recon, z, mu, logvar=model(features.float())\n",
    "        else:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm,adj_decode)\n",
    "            \n",
    "        for r in np.unique(region):\n",
    "            ridx=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']==r\n",
    "            for reg in np.unique(celltype_broad):\n",
    "                savedir=os.path.join(plotsavepath,samplename,'embedding_'+plottype+'_'+reg)\n",
    "                if not os.path.exists(savedir):\n",
    "                    os.mkdir(savedir)\n",
    "\n",
    "                ct_idx=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']==reg\n",
    "                reg_idx=np.logical_and(ridx,ct_idx)\n",
    "                if np.sum(reg_idx)==0:\n",
    "                    continue\n",
    "                \n",
    "                muplot=mu.cpu().detach().numpy()\n",
    "                if inverseAct=='leakyRelu':\n",
    "                    muplot=inverseLeakyRelu(muplot)\n",
    "                if plottype=='umap'\n",
    "                    reducer = umap.UMAP()\n",
    "                    embedding = reducer.fit_transform(muplot[reg_idx])\n",
    "                elif plottype=='pca':\n",
    "                    embedding=pca.fit_transform(muplot[reg_idx])\n",
    "\n",
    "    #             plotembeddingbyCT(celltype_broad[reg_idx],'celltype_broad',[],embedding,savedir,'UMAP of '+s+' '+reg)\n",
    "                plotembeddingbyCT(celltype_sub[reg_idx],'celltype_sub_'+r,[],embedding,savedir,plottype+' of '+r+' '+s+' '+reg)\n",
    "    #             plotembeddingbyCT(region,'region',[],embedding[reg_idx],savedir,s)\n",
    "\n",
    "                plotembeddingbyCT_contrast(celltype_sub[reg_idx],'celltype_sub_'+r,[],embedding,os.path.join(savedir,'contrast'),plottype+' of '+r+' '+s+' '+reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
