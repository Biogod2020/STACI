{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe373f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xinyiz/pamrats')\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.metrics import average_precision_score\n",
    "\n",
    "import gae.gae.optimizer as optimizer\n",
    "import gae.gae.model\n",
    "import gae.gae.preprocessing as preprocessing\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN,MiniBatchKMeans,AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ec689c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "ifplot=True\n",
    "ifcluster=True\n",
    "\n",
    "logitL1=0.1 #smaller is sparser\n",
    "geneThresh=2.5 #times std above mean\n",
    "\n",
    "inverseAct='leakyRelu'\n",
    "# inverseAct=None\n",
    "plottype='umap'\n",
    "pca=PCA()\n",
    "minCells=15 #min number of cells for analysis\n",
    "minCell_clusterDE=5\n",
    "# clustermethod=['kmeanbatch']\n",
    "clustermethod=['kmeanbatch']\n",
    "#umap/leiden clustering parameters\n",
    "n_neighbors=10\n",
    "min_dist=0.25\n",
    "n_pcs=40 #for clustering\n",
    "# resolution=[0.5,1,1.5,2]\n",
    "resolution=[0.05,0.1,0.2,0.3]\n",
    "plotepoch=9990\n",
    "savenameAdd=''\n",
    "#DBscan\n",
    "epslist= [6,8,10]\n",
    "min_sampleslist=[15,30,45] \n",
    "#agglomerative\n",
    "nclusterlist=[3]\n",
    "# nclusterlist=[2,3,4,5,8,10]\n",
    "aggMetric=['euclidean']\n",
    "\n",
    "\n",
    "combineCelltype={'glia':['Astro','Micro', 'OPC', 'Oligo'],'CA':['CA1', 'CA2', 'CA3']}\n",
    "\n",
    "use_cuda=True\n",
    "fastmode=False #Validate during training pass\n",
    "seed=3\n",
    "useSavedMaskedEdges=False\n",
    "maskedgeName='knn20_connectivity'\n",
    "hidden1=1024 #Number of units in hidden layer 1\n",
    "hidden2=1024 #Number of units in hidden layer 2\n",
    "# hidden3=16\n",
    "fc_dim1=1024\n",
    "# fc_dim2=2112\n",
    "# fc_dim3=2112\n",
    "# fc_dim4=2112\n",
    "# gcn_dim1=2048\n",
    "\n",
    "protein=None #'scaled_binary'\n",
    "# proteinWeights=0.05\n",
    "dropout=0.01\n",
    "# randFeatureSubset=None\n",
    "model_str='gcn_vae_xa_e2_d1_dca'\n",
    "adj_decodeName=None #gala or None\n",
    "plot_samples={'disease13':'AD_mouse9494','control13':'AD_mouse9498','disease8':'AD_mouse9723','control8':'AD_mouse9735'}\n",
    "plot_sample_X=['logminmax']\n",
    "plotRecon='' #'meanRecon'\n",
    "# plot_sample_X=['corrected','scaled']\n",
    "standardizeX=False\n",
    "name='allk20XA_01_dca'\n",
    "logsavepath='/mnt/xinyi/pamrats/log/train_gae_starmap/'+name\n",
    "modelsavepath='/mnt/xinyi/pamrats/models/train_gae_starmap/'+name\n",
    "plotsavepath='/mnt/xinyi/pamrats/plots/train_gae_starmap/'+name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f44c3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cuda and seed\n",
    "np.random.seed(seed)\n",
    "if use_cuda and (not torch.cuda.is_available()):\n",
    "    print('cuda not available')\n",
    "    use_cuda=False\n",
    "torch.manual_seed(seed)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bde2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "savedir=os.path.join('/mnt/xinyi/','starmap')\n",
    "adj_dir=os.path.join(savedir,'a')\n",
    "\n",
    "featureslist={}\n",
    "if plot_sample_X[0] in ['corrected','scaled']:\n",
    "    scaleddata=scanpy.read_h5ad('/mnt/xinyi/2021-01-13-mAD-test-dataset/2020-12-27-starmap-mAD-scaled.h5ad')\n",
    "    \n",
    "    for s in plot_samples.keys():\n",
    "        featureslist[s+'X_'+'corrected']=torch.tensor(scaleddata.layers['corrected'][scaleddata.obs['sample']==plot_samples[s]])\n",
    "        featureslist[s+'X_'+'scaled']=torch.tensor(scaleddata.layers['scaled'][scaleddata.obs['sample']==plot_samples[s]])\n",
    "    \n",
    "else:\n",
    "    scaleddata=scanpy.read_h5ad('/mnt/xinyi/2021-01-13-mAD-test-dataset/2020-12-27-starmap-mAD-raw.h5ad')\n",
    "    \n",
    "    for s in plot_samples.keys():\n",
    "        scaleddata_train=scaleddata.X[scaleddata.obs['sample']==plot_samples[s]]\n",
    "\n",
    "        if plot_sample_X[0]=='logminmax':\n",
    "            featurelog_train=np.log2(scaleddata_train+1/2)\n",
    "            scaler = MinMaxScaler()\n",
    "            featurelog_train_minmax=np.transpose(scaler.fit_transform(np.transpose(featurelog_train)))\n",
    "            featureslist[s+'X_'+plot_sample_X[0]]=torch.tensor(featurelog_train_minmax)\n",
    "\n",
    "for s in plot_samples.keys():\n",
    "    featureslist[s+'X_'+plot_sample_X[0]].requires_grad=True\n",
    "    \n",
    "if protein: ##adjust for scaled/corrected\n",
    "    proteinsavepath=os.path.join('/mnt/xinyi/','starmap','protein')\n",
    "    for s in plot_samples.keys():\n",
    "        pmtx=sp.load_npz(os.path.join(proteinsavepath,plot_samples[s]+'_'+protein+'.npz'))\n",
    "        pmtx=preprocessing.sparse_mx_to_torch_sparse_tensor(pmtx)\n",
    "        pmtx=pmtx.to_dense()\n",
    "        scalefactor=torch.sum(featureslist[s+'X_'+plot_sample_X[0]])/torch.sum(pmtx)*proteinWeights\n",
    "        featureslist[s+'X_'+plot_sample_X[0]]=torch.cat((featureslist[s+'X_'+plot_sample_X[0]],pmtx*scalefactor),dim=1)\n",
    "\n",
    "adj_list={}\n",
    "adj_list['disease13']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9494.npz'))\n",
    "adj_list['control13']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9498.npz'))\n",
    "adj_list['disease8']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9723.npz'))\n",
    "adj_list['control8']=sp.load_npz(os.path.join(adj_dir,maskedgeName+'_AD_mouse9735.npz'))\n",
    "\n",
    "feature_names=scaleddata.var.index\n",
    "feature_names=feature_names.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87fd3fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "num_nodes,num_features = list(featureslist.values())[0].shape\n",
    "if model_str=='gcn_vae_xa':\n",
    "    model  = gae.gae.model.GCNModelVAE_XA(num_features, hidden1, hidden2,fc_dim1,fc_dim2,fc_dim3,fc_dim4, dropout)\n",
    "elif model_str=='fc1':\n",
    "    model  = gae.gae.model.FCVAE1(num_features, hidden1,dropout)\n",
    "elif model_str == 'gcn_vae_xa_e2_d1':\n",
    "    model  = gae.gae.model.GCNModelVAE_XA_e2_d1(num_features, hidden1,hidden2, dropout)\n",
    "elif model_str == 'gcn_vae_gcnX_inprA':\n",
    "    model = gae.gae.model.GCNModelVAE_gcnX_inprA(num_features, hidden1, hidden2,gcn_dim1, dropout)\n",
    "elif model_str=='fc1_dca':\n",
    "    model = gae.gae.model.FCVAE1_DCA(num_features, hidden1,fc_dim1, dropout)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dca':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaFork':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCAfork(num_features, hidden1,hidden2,fc_dim1, dropout)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaElemPi':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCAelemPi(num_features, hidden1,hidden2,fc_dim1, dropout,shareGenePi)\n",
    "elif model_str=='gcn_vae_xa_e2_d1_dcaConstantDisp':\n",
    "    model = gae.gae.model.GCNModelVAE_XA_e2_d1_DCA_constantDisp(num_features, hidden1,hidden2,fc_dim1, dropout,shareGenePi)\n",
    "else:\n",
    "    print('model not found')\n",
    "model.load_state_dict(torch.load(os.path.join(modelsavepath,str(plotepoch)+'.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf34c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "def inverseLeakyRelu(v,slope=0.01):\n",
    "    vnegidx=(v<0)\n",
    "    v[vnegidx]=1/slope*v[vnegidx]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde96273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute embeddings\n",
    "mulist={}\n",
    "for s in plot_samples.keys():\n",
    "    adj=adj_list[s]\n",
    "    adj_norm = preprocessing.preprocess_graph(adj)\n",
    "    adj_decode=None\n",
    "    if adj_decodeName == 'gala':\n",
    "        adj_decode=preprocessing.preprocess_graph_sharp(adj)\n",
    "    for xcorr in plot_sample_X:\n",
    "        samplename=s+'X_'+xcorr\n",
    "        features=featureslist[samplename]\n",
    "        if standardizeX:\n",
    "            features=torch.tensor(scale(features,axis=0, with_mean=True, with_std=True, copy=True))\n",
    "        if use_cuda:\n",
    "            model.cuda()\n",
    "            features = features.cuda().float()\n",
    "            adj_norm=adj_norm.cuda()\n",
    "            if adj_decodeName:\n",
    "                adj_decode=adj_decode.cuda()\n",
    "        \n",
    "        model.eval()\n",
    "        if adj_decodeName==None:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm)\n",
    "        else:\n",
    "            adj_recon,mu,logvar,z, features_recon = model(features, adj_norm,adj_decode)\n",
    "        if inverseAct=='leakyRelu':\n",
    "            muplot=inverseLeakyRelu(mu)\n",
    "        else:\n",
    "            muplot=mu\n",
    "        if plotRecon:\n",
    "            if plotRecon=='meanRecon':\n",
    "                mulist[samplename]=features_recon[3].cpu().detach().numpy()\n",
    "        else:\n",
    "            mulist[samplename]=muplot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe444ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiffActivation(cbyf,cidx,labels,savepath):\n",
    "    \n",
    "    res=np.array([])\n",
    "    for l in np.unique(labels):\n",
    "        if l==-1:\n",
    "            continue\n",
    "        if np.sum(labels==l)<minCell_clusterDE or np.sum(labels!=l)<minCell_clusterDE:\n",
    "            continue\n",
    "        \n",
    "        labels_l=np.where(labels==l,1,0)\n",
    "        logitl=LogisticRegression(C=logitL1, penalty='l1', solver='saga',multi_class='ovr',max_iter=1000,fit_intercept=False)\n",
    "        logitl.fit(cbyf.cpu().detach().numpy()[cidx], labels_l)\n",
    "        coeffl=np.flatnonzero(logitl.coef_)\n",
    "#         print(coeffl)\n",
    "        if coeffl.size>0:\n",
    "            with open(os.path.join(savepath,str(l)+'da'), 'wb') as output:\n",
    "                pickle.dump(coeffl, output, pickle.HIGHEST_PROTOCOL)\n",
    "            np.savetxt(os.path.join(savepath,str(l)+'DA.csv'), coeffl, delimiter=\",\")\n",
    "            res=np.concatenate((res,coeffl))\n",
    "    if res.size==0:\n",
    "        return res\n",
    "    res=np.unique(res)\n",
    "    if savepath:\n",
    "        with open(os.path.join(savepath,'da'), 'wb') as output:\n",
    "            pickle.dump(res, output, pickle.HIGHEST_PROTOCOL)\n",
    "    print(res.size)\n",
    "    return res.astype(int)\n",
    "\n",
    "def filterColbySTD(mtx,thresh):\n",
    "    mtxMean=np.mean(mtx,axis=1)\n",
    "    mtxSTD=np.std(mtx,axis=1)\n",
    "    mtxThresh=mtxMean+mtxSTD*thresh\n",
    "    res=np.flatnonzero(np.sum(mtx>mtxThresh.reshape((-1,1)),axis=0))\n",
    "    print(res.size)\n",
    "    return res\n",
    "\n",
    "def plotGradient(x,cbyf_l,cidx,n,labels,genethresh,feature_names,savepath):\n",
    "    order=np.argsort(labels)\n",
    "\n",
    "    gradSelf=np.zeros((cidx.size,x.shape[1]))\n",
    "    gradNeighbor=np.zeros((cidx.size,x.shape[1]))\n",
    "    gradAvg=np.zeros((cidx.size,x.shape[1]))\n",
    "    for c in range(cidx.size):\n",
    "        model.zero_grad()\n",
    "        gradraw=torch.autograd.grad(cbyf_l[cidx[c]],x,retain_graph=True)[0]\n",
    "#         print(gradraw.shape)\n",
    "        gradSelf[c]=gradraw[cidx[c]]\n",
    "        gradnonzeroIdx=(torch.sum(gradraw,1)!=0)\n",
    "        gradAvg[c]=torch.mean(gradraw[gradnonzeroIdx],0)\n",
    "        gradNeighbor[c]=(torch.sum(gradraw[gradnonzeroIdx],0)-gradraw[cidx[c]])/(torch.sum(gradnonzeroIdx)-1)\n",
    "    geneSelf=filterColbySTD(gradSelf,genethresh)\n",
    "    geneNeighbor=filterColbySTD(gradNeighbor,genethresh)\n",
    "    geneAvg=filterColbySTD(gradAvg,genethresh)\n",
    "    gradSelf=gradSelf[:,geneSelf]\n",
    "    gradNeighbor=gradNeighbor[:,geneNeighbor]\n",
    "    gradAvg=gradAvg[:,geneAvg]\n",
    "    gradSelf=gradSelf[order]\n",
    "    gradNeighbor=gradNeighbor[order]\n",
    "    gradAvg=gradAvg[order]\n",
    "\n",
    "    np.savetxt(os.path.join(savepath,str(n)+'Self.csv'), feature_names[geneSelf], delimiter=\",\",fmt=\"%s\")\n",
    "    np.savetxt(os.path.join(savepath,str(n)+'Neighbor.csv'), feature_names[geneNeighbor], delimiter=\",\",fmt=\"%s\")\n",
    "    np.savetxt(os.path.join(savepath,str(n)+'Avg.csv'), feature_names[geneAvg], delimiter=\",\",fmt=\"%s\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(25, 25))\n",
    "    im = ax.imshow(gradSelf,cmap='binary')\n",
    "    ax.set_xticks(np.arange(geneSelf.size))\n",
    "    ax.set_xticklabels(feature_names[geneSelf])\n",
    "    ax.set_yticks(np.arange(labels.size)[np.unique(labels[order],return_index=True)[1]])\n",
    "    ax.set_yticklabels(np.unique(labels))\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "#     fig.set_figheight(35)\n",
    "#     fig.set_figwidth(35)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(savepath,str(n)+'Self.jpg'))\n",
    "    plt.close()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(25, 25))\n",
    "    im = ax.imshow(gradNeighbor,cmap='binary')\n",
    "    ax.set_xticks(np.arange(geneNeighbor.size))\n",
    "    ax.set_xticklabels(feature_names[geneNeighbor])\n",
    "    ax.set_yticks(np.arange(labels.size)[np.unique(labels[order],return_index=True)[1]])\n",
    "    ax.set_yticklabels(np.unique(labels))\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "#     fig.set_figheight(35)\n",
    "#     fig.set_figwidth(35)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(savepath,str(n)+'Neighbor.jpg'))\n",
    "    plt.close()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(25, 25))\n",
    "    im = ax.imshow(gradAvg,cmap='binary')\n",
    "    ax.set_xticks(np.arange(geneAvg.size))\n",
    "    ax.set_xticklabels(feature_names[geneAvg])\n",
    "    ax.set_yticks(np.arange(labels.size)[np.unique(labels[order],return_index=True)[1]])\n",
    "    ax.set_yticklabels(np.unique(labels))\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",rotation_mode=\"anchor\")\n",
    "#     fig.set_figheight(35)\n",
    "#     fig.set_figwidth(35)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(savepath,str(n)+'Avg.jpg'))\n",
    "    plt.close()\n",
    "        \n",
    "        \n",
    "\n",
    "def daLeiden(sample,cbyf,cidx,n_neighbors,n_pcs,min_dist,resolution,feature_names):\n",
    "    for r in resolution:\n",
    "        savenamecluster='leiden_nn'+str(n_neighbors)+'mdist0'+str(int(min_dist*100))+'n_pcs'+str(n_pcs)+'res'+str(r)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        labels=np.array(labels)\n",
    "        if np.unique(labels).shape[0]==1:\n",
    "            continue\n",
    "        \n",
    "        savepath=os.path.join(desavedir,savenamecluster)\n",
    "        if not os.path.exists(savepath):\n",
    "            os.makedirs(savepath)\n",
    "        daDict=getDiffActivation(cbyf,cidx,labels,savepath)\n",
    "        for n in daDict:\n",
    "            plotGradient(sample,cbyf[:,n],cidx,n,labels,geneThresh,feature_names,savepath)\n",
    "\n",
    "def daDBscan(sample,cbyf,cidx,epsL,min_samplesL,n_pcs,feature_names):\n",
    "    for eps in epsL:\n",
    "        for min_samples in min_samplesL:\n",
    "            savenamecluster='dbscan_eps'+str(eps)+'msamples'+str(min_samples)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "            if not os.path.exists(readpath):\n",
    "                print('DNE: '+readpath)\n",
    "                continue\n",
    "            with open(readpath, 'rb') as input:\n",
    "                labels = pickle.load(input)\n",
    "            labels=np.array(labels)\n",
    "            if np.unique(labels).shape[0]==1:\n",
    "                continue\n",
    "            \n",
    "            savepath=os.path.join(desavedir,savenamecluster)\n",
    "            if not os.path.exists(savepath):\n",
    "                os.makedirs(savepath)\n",
    "            daDict=getDiffActivation(cbyf,cidx,labels,savepath)\n",
    "            for n in daDict:\n",
    "                plotGradient(sample,cbyf[:,n],cidx,n,labels,geneThresh,feature_names,savepath)\n",
    "                \n",
    "def daAgg(sample,cbyf,cidx,nclusterL,aggmetricL,n_pcs,feature_names):\n",
    "    for ncluster in nclusterL:\n",
    "        for aggmetric in aggmetricL:\n",
    "            savenamecluster='agg_ncluster'+str(ncluster)+aggmetric+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "            readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "            if not os.path.exists(readpath):\n",
    "                print('DNE: '+readpath)\n",
    "                continue\n",
    "            with open(readpath, 'rb') as input:\n",
    "                labels = pickle.load(input)\n",
    "            labels=np.array(labels)\n",
    "            if np.unique(labels).shape[0]==1:\n",
    "                continue\n",
    "            savepath=os.path.join(desavedir,savenamecluster)\n",
    "            if not os.path.exists(savepath):\n",
    "                os.makedirs(savepath)\n",
    "            daDict=getDiffActivation(cbyf,cidx,labels,savepath)\n",
    "            for n in daDict:\n",
    "                plotGradient(sample,cbyf[:,n],cidx,n,labels,geneThresh,feature_names,savepath)\n",
    "            \n",
    "def daMinibatchKmean(sample,cbyf,cidx,nclusterL,n_pcs,feature_names):\n",
    "    for ncluster in nclusterL:\n",
    "        savenamecluster='minibatchkmean_ncluster'+str(ncluster)+'n_pcs'+str(n_pcs)+'epoch'+str(plotepoch)\n",
    "        readpath=os.path.join(clustersavedir,savenamecluster)\n",
    "        if not os.path.exists(readpath):\n",
    "            print('DNE: '+readpath)\n",
    "            continue\n",
    "        with open(readpath, 'rb') as input:\n",
    "            labels = pickle.load(input)\n",
    "        labels=np.array(labels)\n",
    "        if np.unique(labels).shape[0]==1:\n",
    "            continue\n",
    "            \n",
    "        savepath=os.path.join(desavedir,savenamecluster)\n",
    "        if not os.path.exists(savepath):\n",
    "            os.makedirs(savepath)\n",
    "        daDict=getDiffActivation(cbyf,cidx,labels,savepath)\n",
    "        for n in daDict:\n",
    "            plotGradient(sample,cbyf[:,n],cidx,n,labels,geneThresh,feature_names,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abb3b823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease13\n",
      "Cortex\n",
      "Hippocampus\n",
      "CA1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "77\n",
      "72\n",
      "72\n",
      "69\n",
      "63\n",
      "63\n",
      "49\n",
      "47\n",
      "47\n",
      "86\n",
      "81\n",
      "81\n",
      "81\n",
      "75\n",
      "75\n",
      "72\n",
      "65\n",
      "65\n",
      "70\n",
      "65\n",
      "66\n",
      "65\n",
      "64\n",
      "64\n",
      "75\n",
      "70\n",
      "70\n",
      "92\n",
      "89\n",
      "89\n",
      "81\n",
      "78\n",
      "78\n",
      "69\n",
      "66\n",
      "66\n",
      "79\n",
      "74\n",
      "74\n",
      "75\n",
      "66\n",
      "66\n",
      "71\n",
      "64\n",
      "64\n",
      "62\n",
      "54\n",
      "54\n",
      "68\n",
      "65\n",
      "65\n",
      "87\n",
      "80\n",
      "80\n",
      "79\n",
      "75\n",
      "75\n",
      "76\n",
      "69\n",
      "69\n",
      "106\n",
      "98\n",
      "98\n",
      "85\n",
      "76\n",
      "76\n",
      "77\n",
      "71\n",
      "71\n",
      "92\n",
      "84\n",
      "84\n",
      "83\n",
      "78\n",
      "79\n",
      "79\n",
      "78\n",
      "78\n",
      "90\n",
      "85\n",
      "85\n",
      "80\n",
      "73\n",
      "73\n",
      "76\n",
      "68\n",
      "68\n",
      "65\n",
      "63\n",
      "63\n",
      "69\n",
      "65\n",
      "65\n",
      "113\n",
      "101\n",
      "101\n",
      "67\n",
      "64\n",
      "64\n",
      "77\n",
      "72\n",
      "72\n",
      "93\n",
      "82\n",
      "82\n",
      "70\n",
      "67\n",
      "67\n",
      "74\n",
      "69\n",
      "69\n",
      "76\n",
      "71\n",
      "71\n",
      "85\n",
      "78\n",
      "78\n",
      "92\n",
      "81\n",
      "81\n",
      "85\n",
      "81\n",
      "80\n",
      "75\n",
      "69\n",
      "69\n",
      "65\n",
      "62\n",
      "62\n",
      "94\n",
      "89\n",
      "89\n",
      "84\n",
      "82\n",
      "82\n",
      "107\n",
      "94\n",
      "94\n",
      "99\n",
      "92\n",
      "92\n",
      "59\n",
      "57\n",
      "57\n",
      "65\n",
      "61\n",
      "61\n",
      "94\n",
      "87\n",
      "87\n",
      "91\n",
      "84\n",
      "85\n",
      "72\n",
      "73\n",
      "72\n",
      "Micro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "71\n",
      "70\n",
      "70\n",
      "84\n",
      "79\n",
      "79\n",
      "89\n",
      "82\n",
      "82\n",
      "85\n",
      "83\n",
      "83\n",
      "64\n",
      "65\n",
      "65\n",
      "48\n",
      "45\n",
      "46\n",
      "84\n",
      "82\n",
      "82\n",
      "101\n",
      "98\n",
      "98\n",
      "86\n",
      "83\n",
      "82\n",
      "75\n",
      "74\n",
      "74\n",
      "82\n",
      "79\n",
      "79\n",
      "63\n",
      "55\n",
      "55\n",
      "103\n",
      "100\n",
      "100\n",
      "76\n",
      "73\n",
      "73\n",
      "94\n",
      "86\n",
      "86\n",
      "72\n",
      "71\n",
      "71\n",
      "58\n",
      "56\n",
      "56\n",
      "117\n",
      "114\n",
      "114\n",
      "65\n",
      "65\n",
      "64\n",
      "83\n",
      "76\n",
      "76\n",
      "78\n",
      "75\n",
      "75\n",
      "85\n",
      "79\n",
      "79\n",
      "77\n",
      "73\n",
      "73\n",
      "78\n",
      "77\n",
      "77\n",
      "83\n",
      "79\n",
      "79\n",
      "77\n",
      "74\n",
      "74\n",
      "61\n",
      "60\n",
      "60\n",
      "84\n",
      "83\n",
      "82\n",
      "60\n",
      "57\n",
      "57\n",
      "93\n",
      "84\n",
      "85\n",
      "102\n",
      "97\n",
      "97\n",
      "71\n",
      "70\n",
      "70\n",
      "118\n",
      "107\n",
      "107\n",
      "105\n",
      "99\n",
      "100\n",
      "66\n",
      "65\n",
      "65\n",
      "113\n",
      "100\n",
      "100\n",
      "107\n",
      "102\n",
      "102\n",
      "60\n",
      "58\n",
      "58\n",
      "80\n",
      "79\n",
      "79\n",
      "82\n",
      "80\n",
      "80\n",
      "74\n",
      "70\n",
      "71\n",
      "77\n",
      "76\n",
      "75\n",
      "70\n",
      "68\n",
      "68\n",
      "110\n",
      "106\n",
      "107\n",
      "81\n",
      "78\n",
      "78\n",
      "80\n",
      "76\n",
      "76\n",
      "65\n",
      "65\n",
      "65\n",
      "93\n",
      "87\n",
      "87\n",
      "86\n",
      "79\n",
      "79\n",
      "77\n",
      "75\n",
      "75\n",
      "91\n",
      "88\n",
      "87\n",
      "CA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "77\n",
      "71\n",
      "71\n",
      "133\n",
      "127\n",
      "127\n",
      "83\n",
      "80\n",
      "79\n",
      "86\n",
      "80\n",
      "80\n",
      "79\n",
      "74\n",
      "74\n",
      "73\n",
      "71\n",
      "71\n",
      "61\n",
      "57\n",
      "59\n",
      "81\n",
      "79\n",
      "79\n",
      "89\n",
      "81\n",
      "81\n",
      "104\n",
      "99\n",
      "99\n",
      "84\n",
      "78\n",
      "78\n",
      "89\n",
      "85\n",
      "85\n",
      "87\n",
      "82\n",
      "82\n",
      "88\n",
      "83\n",
      "83\n",
      "81\n",
      "74\n",
      "74\n",
      "74\n",
      "65\n",
      "65\n",
      "81\n",
      "72\n",
      "72\n",
      "76\n",
      "70\n",
      "70\n",
      "83\n",
      "81\n",
      "80\n",
      "111\n",
      "104\n",
      "105\n",
      "99\n",
      "92\n",
      "92\n",
      "87\n",
      "80\n",
      "80\n",
      "79\n",
      "73\n",
      "74\n",
      "84\n",
      "80\n",
      "80\n",
      "80\n",
      "73\n",
      "74\n",
      "113\n",
      "107\n",
      "106\n",
      "103\n",
      "96\n",
      "96\n",
      "99\n",
      "94\n",
      "94\n",
      "95\n",
      "90\n",
      "90\n",
      "73\n",
      "70\n",
      "70\n",
      "71\n",
      "69\n",
      "69\n",
      "102\n",
      "95\n",
      "96\n",
      "133\n",
      "122\n",
      "122\n",
      "96\n",
      "91\n",
      "91\n",
      "79\n",
      "76\n",
      "76\n",
      "89\n",
      "84\n",
      "84\n",
      "109\n",
      "99\n",
      "99\n",
      "117\n",
      "102\n",
      "102\n",
      "87\n",
      "80\n",
      "80\n",
      "105\n",
      "91\n",
      "91\n",
      "103\n",
      "97\n",
      "97\n",
      "85\n",
      "77\n",
      "77\n",
      "76\n",
      "74\n",
      "74\n",
      "89\n",
      "88\n",
      "88\n",
      "120\n",
      "106\n",
      "106\n",
      "62\n",
      "59\n",
      "59\n",
      "124\n",
      "119\n",
      "118\n",
      "106\n",
      "98\n",
      "98\n",
      "83\n",
      "77\n",
      "78\n",
      "104\n",
      "97\n",
      "98\n",
      "82\n",
      "74\n",
      "74\n",
      "70\n",
      "68\n",
      "69\n",
      "110\n",
      "101\n",
      "101\n",
      "White Matter\n",
      "control13\n",
      "Cortex\n",
      "Hippocampus\n",
      "CA1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "77\n",
      "70\n",
      "70\n",
      "63\n",
      "61\n",
      "61\n",
      "63\n",
      "61\n",
      "61\n",
      "69\n",
      "67\n",
      "67\n",
      "71\n",
      "67\n",
      "67\n",
      "67\n",
      "62\n",
      "62\n",
      "79\n",
      "75\n",
      "75\n",
      "60\n",
      "56\n",
      "56\n",
      "64\n",
      "60\n",
      "60\n",
      "88\n",
      "84\n",
      "84\n",
      "75\n",
      "71\n",
      "71\n",
      "62\n",
      "62\n",
      "62\n",
      "64\n",
      "65\n",
      "65\n",
      "60\n",
      "57\n",
      "57\n",
      "83\n",
      "80\n",
      "80\n",
      "80\n",
      "79\n",
      "79\n",
      "83\n",
      "82\n",
      "82\n",
      "88\n",
      "84\n",
      "84\n",
      "48\n",
      "48\n",
      "48\n",
      "69\n",
      "65\n",
      "65\n",
      "59\n",
      "57\n",
      "57\n",
      "63\n",
      "62\n",
      "62\n",
      "69\n",
      "68\n",
      "68\n",
      "69\n",
      "66\n",
      "64\n",
      "72\n",
      "72\n",
      "72\n",
      "71\n",
      "66\n",
      "67\n",
      "66\n",
      "61\n",
      "61\n",
      "71\n",
      "68\n",
      "69\n",
      "83\n",
      "77\n",
      "78\n",
      "64\n",
      "62\n",
      "62\n",
      "62\n",
      "60\n",
      "60\n",
      "72\n",
      "69\n",
      "69\n",
      "Micro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "48\n",
      "47\n",
      "47\n",
      "65\n",
      "61\n",
      "61\n",
      "78\n",
      "72\n",
      "72\n",
      "61\n",
      "61\n",
      "61\n",
      "84\n",
      "84\n",
      "84\n",
      "66\n",
      "68\n",
      "67\n",
      "56\n",
      "55\n",
      "55\n",
      "55\n",
      "51\n",
      "51\n",
      "69\n",
      "72\n",
      "72\n",
      "75\n",
      "75\n",
      "75\n",
      "76\n",
      "76\n",
      "76\n",
      "65\n",
      "64\n",
      "64\n",
      "70\n",
      "71\n",
      "71\n",
      "74\n",
      "73\n",
      "73\n",
      "CA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "77\n",
      "76\n",
      "76\n",
      "96\n",
      "90\n",
      "90\n",
      "98\n",
      "94\n",
      "94\n",
      "117\n",
      "111\n",
      "111\n",
      "74\n",
      "73\n",
      "73\n",
      "117\n",
      "111\n",
      "111\n",
      "92\n",
      "90\n",
      "90\n",
      "80\n",
      "79\n",
      "79\n",
      "75\n",
      "72\n",
      "72\n",
      "69\n",
      "67\n",
      "67\n",
      "69\n",
      "65\n",
      "65\n",
      "100\n",
      "98\n",
      "98\n",
      "103\n",
      "96\n",
      "96\n",
      "76\n",
      "78\n",
      "77\n",
      "70\n",
      "68\n",
      "68\n",
      "84\n",
      "78\n",
      "79\n",
      "80\n",
      "76\n",
      "76\n",
      "88\n",
      "83\n",
      "83\n",
      "67\n",
      "61\n",
      "61\n",
      "92\n",
      "89\n",
      "89\n",
      "109\n",
      "108\n",
      "108\n",
      "95\n",
      "90\n",
      "90\n",
      "99\n",
      "96\n",
      "95\n",
      "82\n",
      "78\n",
      "78\n",
      "82\n",
      "80\n",
      "80\n",
      "69\n",
      "67\n",
      "68\n",
      "71\n",
      "67\n",
      "68\n",
      "94\n",
      "90\n",
      "90\n",
      "91\n",
      "88\n",
      "88\n",
      "88\n",
      "84\n",
      "84\n",
      "82\n",
      "77\n",
      "77\n",
      "59\n",
      "57\n",
      "57\n",
      "100\n",
      "93\n",
      "93\n",
      "126\n",
      "118\n",
      "117\n",
      "72\n",
      "68\n",
      "68\n",
      "72\n",
      "68\n",
      "68\n",
      "67\n",
      "65\n",
      "65\n",
      "79\n",
      "79\n",
      "79\n",
      "104\n",
      "100\n",
      "100\n",
      "76\n",
      "70\n",
      "70\n",
      "86\n",
      "84\n",
      "83\n",
      "76\n",
      "72\n",
      "72\n",
      "77\n",
      "74\n",
      "75\n",
      "107\n",
      "104\n",
      "104\n",
      "58\n",
      "53\n",
      "53\n",
      "116\n",
      "106\n",
      "106\n",
      "94\n",
      "87\n",
      "88\n",
      "101\n",
      "96\n",
      "96\n",
      "88\n",
      "83\n",
      "83\n",
      "89\n",
      "84\n",
      "84\n",
      "91\n",
      "89\n",
      "89\n",
      "White Matter\n",
      "disease8\n",
      "Cortex\n",
      "Hippocampus\n",
      "CA1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "102\n",
      "98\n",
      "98\n",
      "63\n",
      "60\n",
      "61\n",
      "59\n",
      "58\n",
      "58\n",
      "79\n",
      "76\n",
      "76\n",
      "69\n",
      "64\n",
      "64\n",
      "55\n",
      "52\n",
      "52\n",
      "98\n",
      "95\n",
      "95\n",
      "67\n",
      "67\n",
      "67\n",
      "76\n",
      "74\n",
      "73\n",
      "59\n",
      "56\n",
      "56\n",
      "57\n",
      "55\n",
      "55\n",
      "79\n",
      "76\n",
      "76\n",
      "69\n",
      "65\n",
      "65\n",
      "102\n",
      "97\n",
      "96\n",
      "73\n",
      "72\n",
      "73\n",
      "72\n",
      "68\n",
      "69\n",
      "84\n",
      "81\n",
      "81\n",
      "92\n",
      "89\n",
      "88\n",
      "79\n",
      "75\n",
      "75\n",
      "83\n",
      "77\n",
      "77\n",
      "64\n",
      "61\n",
      "61\n",
      "48\n",
      "46\n",
      "46\n",
      "85\n",
      "81\n",
      "81\n",
      "72\n",
      "72\n",
      "72\n",
      "66\n",
      "66\n",
      "66\n",
      "63\n",
      "59\n",
      "59\n",
      "86\n",
      "83\n",
      "82\n",
      "73\n",
      "68\n",
      "68\n",
      "88\n",
      "84\n",
      "83\n",
      "83\n",
      "76\n",
      "76\n",
      "79\n",
      "77\n",
      "77\n",
      "74\n",
      "72\n",
      "72\n",
      "61\n",
      "57\n",
      "59\n",
      "77\n",
      "71\n",
      "71\n",
      "70\n",
      "70\n",
      "70\n",
      "79\n",
      "76\n",
      "76\n",
      "91\n",
      "89\n",
      "89\n",
      "57\n",
      "54\n",
      "54\n",
      "Micro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "66\n",
      "63\n",
      "63\n",
      "43\n",
      "40\n",
      "40\n",
      "65\n",
      "63\n",
      "63\n",
      "65\n",
      "62\n",
      "62\n",
      "62\n",
      "59\n",
      "59\n",
      "75\n",
      "70\n",
      "70\n",
      "76\n",
      "75\n",
      "75\n",
      "88\n",
      "80\n",
      "80\n",
      "60\n",
      "61\n",
      "60\n",
      "50\n",
      "44\n",
      "45\n",
      "71\n",
      "68\n",
      "68\n",
      "72\n",
      "69\n",
      "69\n",
      "49\n",
      "48\n",
      "48\n",
      "69\n",
      "66\n",
      "67\n",
      "69\n",
      "63\n",
      "63\n",
      "56\n",
      "56\n",
      "56\n",
      "79\n",
      "72\n",
      "72\n",
      "CA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "80\n",
      "77\n",
      "77\n",
      "117\n",
      "113\n",
      "113\n",
      "87\n",
      "78\n",
      "79\n",
      "70\n",
      "65\n",
      "65\n",
      "83\n",
      "83\n",
      "83\n",
      "67\n",
      "66\n",
      "66\n",
      "80\n",
      "72\n",
      "71\n",
      "54\n",
      "53\n",
      "53\n",
      "108\n",
      "101\n",
      "101\n",
      "88\n",
      "84\n",
      "84\n",
      "79\n",
      "71\n",
      "70\n",
      "105\n",
      "101\n",
      "101\n",
      "108\n",
      "107\n",
      "107\n",
      "88\n",
      "83\n",
      "84\n",
      "85\n",
      "82\n",
      "82\n",
      "80\n",
      "75\n",
      "75\n",
      "81\n",
      "76\n",
      "76\n",
      "102\n",
      "94\n",
      "94\n",
      "80\n",
      "71\n",
      "71\n",
      "64\n",
      "61\n",
      "61\n",
      "63\n",
      "63\n",
      "63\n",
      "95\n",
      "89\n",
      "89\n",
      "82\n",
      "73\n",
      "73\n",
      "61\n",
      "57\n",
      "57\n",
      "93\n",
      "87\n",
      "87\n",
      "77\n",
      "75\n",
      "75\n",
      "119\n",
      "114\n",
      "114\n",
      "77\n",
      "74\n",
      "74\n",
      "77\n",
      "69\n",
      "69\n",
      "100\n",
      "99\n",
      "99\n",
      "53\n",
      "50\n",
      "50\n",
      "91\n",
      "88\n",
      "88\n",
      "66\n",
      "62\n",
      "62\n",
      "84\n",
      "82\n",
      "82\n",
      "92\n",
      "85\n",
      "85\n",
      "68\n",
      "66\n",
      "66\n",
      "114\n",
      "105\n",
      "105\n",
      "105\n",
      "97\n",
      "98\n",
      "65\n",
      "61\n",
      "61\n",
      "72\n",
      "71\n",
      "71\n",
      "80\n",
      "75\n",
      "75\n",
      "86\n",
      "83\n",
      "82\n",
      "96\n",
      "90\n",
      "89\n",
      "89\n",
      "82\n",
      "82\n",
      "87\n",
      "81\n",
      "81\n",
      "99\n",
      "92\n",
      "92\n",
      "80\n",
      "76\n",
      "76\n",
      "84\n",
      "79\n",
      "79\n",
      "78\n",
      "73\n",
      "73\n",
      "105\n",
      "100\n",
      "100\n",
      "52\n",
      "53\n",
      "53\n",
      "86\n",
      "81\n",
      "81\n",
      "79\n",
      "77\n",
      "77\n",
      "86\n",
      "79\n",
      "79\n",
      "62\n",
      "59\n",
      "59\n",
      "109\n",
      "103\n",
      "104\n",
      "85\n",
      "82\n",
      "82\n",
      "White Matter\n",
      "control8\n",
      "Cortex\n",
      "Hippocampus\n",
      "CA1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "72\n",
      "64\n",
      "64\n",
      "66\n",
      "62\n",
      "62\n",
      "79\n",
      "79\n",
      "79\n",
      "68\n",
      "63\n",
      "63\n",
      "52\n",
      "50\n",
      "50\n",
      "55\n",
      "52\n",
      "52\n",
      "73\n",
      "71\n",
      "71\n",
      "71\n",
      "67\n",
      "68\n",
      "83\n",
      "80\n",
      "80\n",
      "77\n",
      "74\n",
      "74\n",
      "68\n",
      "67\n",
      "67\n",
      "55\n",
      "52\n",
      "52\n",
      "62\n",
      "60\n",
      "61\n",
      "77\n",
      "72\n",
      "72\n",
      "79\n",
      "77\n",
      "77\n",
      "81\n",
      "77\n",
      "77\n",
      "88\n",
      "87\n",
      "87\n",
      "50\n",
      "48\n",
      "48\n",
      "61\n",
      "57\n",
      "57\n",
      "87\n",
      "81\n",
      "81\n",
      "77\n",
      "73\n",
      "73\n",
      "70\n",
      "66\n",
      "66\n",
      "62\n",
      "60\n",
      "60\n",
      "96\n",
      "88\n",
      "89\n",
      "108\n",
      "100\n",
      "100\n",
      "68\n",
      "64\n",
      "64\n",
      "88\n",
      "82\n",
      "82\n",
      "81\n",
      "77\n",
      "77\n",
      "65\n",
      "64\n",
      "64\n",
      "82\n",
      "76\n",
      "77\n",
      "63\n",
      "62\n",
      "62\n",
      "67\n",
      "66\n",
      "66\n",
      "80\n",
      "73\n",
      "73\n",
      "86\n",
      "79\n",
      "79\n",
      "85\n",
      "80\n",
      "80\n",
      "83\n",
      "76\n",
      "76\n",
      "69\n",
      "67\n",
      "67\n",
      "94\n",
      "88\n",
      "88\n",
      "76\n",
      "65\n",
      "65\n",
      "105\n",
      "95\n",
      "95\n",
      "56\n",
      "52\n",
      "52\n",
      "96\n",
      "87\n",
      "87\n",
      "84\n",
      "81\n",
      "80\n",
      "91\n",
      "82\n",
      "82\n",
      "62\n",
      "58\n",
      "58\n",
      "81\n",
      "76\n",
      "76\n",
      "52\n",
      "51\n",
      "51\n",
      "80\n",
      "74\n",
      "74\n",
      "60\n",
      "60\n",
      "60\n",
      "72\n",
      "71\n",
      "71\n",
      "Micro\n",
      "13\n",
      "47\n",
      "46\n",
      "46\n",
      "81\n",
      "79\n",
      "79\n",
      "39\n",
      "39\n",
      "39\n",
      "70\n",
      "65\n",
      "65\n",
      "80\n",
      "77\n",
      "77\n",
      "71\n",
      "69\n",
      "69\n",
      "47\n",
      "47\n",
      "47\n",
      "73\n",
      "70\n",
      "69\n",
      "48\n",
      "48\n",
      "48\n",
      "68\n",
      "66\n",
      "66\n",
      "58\n",
      "59\n",
      "60\n",
      "63\n",
      "62\n",
      "61\n",
      "69\n",
      "65\n",
      "65\n",
      "CA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/xinyiz/anaconda3/envs/pytorch2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "90\n",
      "80\n",
      "80\n",
      "87\n",
      "78\n",
      "78\n",
      "91\n",
      "82\n",
      "82\n",
      "128\n",
      "121\n",
      "121\n",
      "85\n",
      "84\n",
      "84\n",
      "74\n",
      "72\n",
      "71\n",
      "62\n",
      "61\n",
      "61\n",
      "76\n",
      "75\n",
      "75\n",
      "87\n",
      "82\n",
      "82\n",
      "56\n",
      "53\n",
      "53\n",
      "74\n",
      "69\n",
      "69\n",
      "70\n",
      "68\n",
      "68\n",
      "89\n",
      "86\n",
      "86\n",
      "74\n",
      "68\n",
      "68\n",
      "83\n",
      "78\n",
      "78\n",
      "87\n",
      "85\n",
      "85\n",
      "83\n",
      "83\n",
      "82\n",
      "77\n",
      "74\n",
      "75\n",
      "64\n",
      "61\n",
      "61\n",
      "141\n",
      "135\n",
      "136\n",
      "82\n",
      "79\n",
      "79\n",
      "82\n",
      "77\n",
      "77\n",
      "89\n",
      "82\n",
      "82\n",
      "97\n",
      "91\n",
      "91\n",
      "78\n",
      "75\n",
      "75\n",
      "97\n",
      "93\n",
      "94\n",
      "90\n",
      "83\n",
      "83\n",
      "79\n",
      "77\n",
      "77\n",
      "78\n",
      "73\n",
      "73\n",
      "90\n",
      "87\n",
      "87\n",
      "80\n",
      "73\n",
      "74\n",
      "59\n",
      "58\n",
      "58\n",
      "58\n",
      "55\n",
      "55\n",
      "64\n",
      "60\n",
      "60\n",
      "96\n",
      "88\n",
      "88\n",
      "86\n",
      "79\n",
      "79\n",
      "85\n",
      "82\n",
      "82\n",
      "80\n",
      "75\n",
      "75\n",
      "70\n",
      "70\n",
      "70\n",
      "105\n",
      "99\n",
      "100\n",
      "86\n",
      "76\n",
      "76\n",
      "127\n",
      "112\n",
      "112\n",
      "77\n",
      "75\n",
      "75\n",
      "51\n",
      "49\n",
      "49\n",
      "87\n",
      "79\n",
      "79\n",
      "91\n",
      "84\n",
      "85\n",
      "64\n",
      "60\n",
      "60\n",
      "95\n",
      "88\n",
      "88\n",
      "89\n",
      "81\n",
      "82\n",
      "77\n",
      "74\n",
      "75\n",
      "100\n",
      "95\n",
      "95\n",
      "100\n",
      "90\n",
      "91\n",
      "82\n",
      "80\n",
      "80\n",
      "117\n",
      "108\n",
      "108\n",
      "77\n",
      "73\n",
      "73\n",
      "79\n",
      "70\n",
      "70\n",
      "123\n",
      "111\n",
      "111\n",
      "61\n",
      "56\n",
      "56\n",
      "97\n",
      "86\n",
      "86\n",
      "68\n",
      "63\n",
      "63\n",
      "74\n",
      "67\n",
      "68\n",
      "66\n",
      "66\n",
      "66\n",
      "85\n",
      "81\n",
      "81\n",
      "105\n",
      "94\n",
      "94\n",
      "100\n",
      "95\n",
      "95\n",
      "98\n",
      "91\n",
      "91\n",
      "White Matter\n"
     ]
    }
   ],
   "source": [
    "# separate plots by region and cell types\n",
    "for s in plot_samples.keys():\n",
    "# for s in ['control8']:\n",
    "#     if s in ['disease13']:\n",
    "#         continue\n",
    "    print(s)\n",
    "    sampleidx=plot_samples[s]\n",
    "    celltype_broad=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'top_level']\n",
    "    celltype_sub=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'cell_type_label']\n",
    "    region=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']\n",
    "#     sobj_coord_np=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,['x','y']].to_numpy()\n",
    "    \n",
    "    origCT=np.unique(celltype_broad)\n",
    "    celltypeplot=np.concatenate((origCT,list(combineCelltype.keys())),axis=None)\n",
    "    for xcorr in plot_sample_X:\n",
    "        samplename=s+'X_'+xcorr\n",
    "        featureDE=featureslist[samplename]\n",
    "        muplot=mulist[samplename]\n",
    "\n",
    "        if inverseAct:\n",
    "            samplename+='_beforeAct'\n",
    "        sampledir=os.path.join(plotsavepath,samplename)\n",
    "        if not os.path.exists(sampledir):\n",
    "            os.mkdir(sampledir)\n",
    "            \n",
    "        for r in np.unique(region):\n",
    "            print(r)\n",
    "            ridx=scaleddata.obs.loc[scaleddata.obs['sample']==sampleidx,'region']==r\n",
    "            for reg in celltypeplot:\n",
    "#                 if not ((r=='Cortex' and reg in ['Ex']) or (r=='Hippocampus' and reg in ['CA1','DG','Micro','CA'])):\n",
    "                if not  (r=='Hippocampus' and reg in ['CA1','Micro','CA']):\n",
    "                    continue\n",
    "                print(reg)\n",
    "                clustersavedir=os.path.join(plotsavepath,samplename,'cluster'+'_'+reg,r)\n",
    "                desavedir=os.path.join(plotsavepath,samplename,'da'+'_'+reg+r)\n",
    "                if not os.path.exists(desavedir):\n",
    "                    os.mkdir(desavedir)\n",
    "\n",
    "                if reg in origCT:\n",
    "                    ct_idx=celltype_broad==reg\n",
    "                else:\n",
    "                    ct_idx=False\n",
    "                    for i in combineCelltype[reg]:\n",
    "                        ct_idx=np.logical_or(ct_idx,celltype_broad==i)\n",
    "                \n",
    "                reg_idx=np.logical_and(ridx,ct_idx)\n",
    "                reg_idx=np.arange(reg_idx.size)[reg_idx]\n",
    "                        \n",
    "                if np.sum(reg_idx)<minCells:\n",
    "                    continue\n",
    "                if 'leiden' in clustermethod:\n",
    "                    daLeiden(featureDE,muplot,reg_idx,n_neighbors,n_pcs,min_dist,resolution,feature_names)\n",
    "                if 'dbscan' in clustermethod:\n",
    "                    daDBscan(featureDE,muplot,reg_idx,epslist,min_sampleslist,n_pcs,feature_names)\n",
    "                if 'agglomerative' in clustermethod:\n",
    "                    daAgg(featureDE,muplot,reg_idx,nclusterlist,aggMetric,n_pcs,feature_names)\n",
    "                if 'kmeanbatch' in clustermethod:\n",
    "                    daMinibatchKmean(featureDE,muplot,reg_idx,nclusterlist,n_pcs,feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2824210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradtest=torch.autograd.grad(mulist[samplename][0,0],featureslist[samplename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c1ff883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2112)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.sum(gradtest[0],0)!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5c91544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9.,  0., 12.,  0.,  1.,  1.,  0.,  2.,  0.,  2.]),\n",
       " array([0.00071649, 0.00106264, 0.00140878, 0.00175492, 0.00210106,\n",
       "        0.00244721, 0.00279335, 0.00313949, 0.00348563, 0.00383178,\n",
       "        0.00417792], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradtestnp=gradtest[0].cpu().detach().numpy()\n",
    "plt.hist(np.std(gradtestnp[np.sum(gradtestnp,1)!=0],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0f4a2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 1., 1., 0., 6., 1., 5., 0., 6., 5.]),\n",
       " array([-1.85907789e-04, -1.68891653e-04, -1.51875516e-04, -1.34859380e-04,\n",
       "        -1.17843236e-04, -1.00827092e-04, -8.38109554e-05, -6.67948188e-05,\n",
       "        -4.97786787e-05, -3.27625385e-05, -1.57464001e-05], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANiElEQVR4nO3ce4xc91nG8e+LncS0FDXBSzFxN5tUVZAbqbisQkOkloYASYy4iEo4UlEDQYt6Iwgk5Cj/pEIIt5VKQUG0FhQQlF4IVCoNaZomjaCUJF0XOzfH1HGNaiWtHUqgbqVETl/+OGft8Xh256y9Z+e1/f1Io52Zc5lnf/vbx7PnnHFkJpKkur5n0gEkSUuzqCWpOItakoqzqCWpOItakopb28dO169fnzMzM33sWpLOSjt37nw2M6dGLeulqGdmZpifn+9j15J0VoqI/1psmYc+JKk4i1qSirOoJak4i1qSirOoJak4i1qSiutU1BHx8oi4MyKejIg9EXFV38EkSY2u11H/MfCZzHxzRJwPvKTHTJKkAWOLOiK+H3gDcBNAZr4AvNBvLEnSgi7vqC8DDgN/GRGvBXYCt2TmtwdXiog5YA5genp6pXPqLDOz7a6JvO6B7Vsm8rrnokn9jOHs+zl3OUa9Fngd8GeZuRn4NrBteKXM3JGZs5k5OzU18uPqkqRT0KWoDwIHM/Oh9vGdNMUtSVoFY4s6M78OfC0iLm+f+ingiV5TSZKO6XrVx7uAj7RXfOwHfq2/SJKkQZ2KOjN3AbP9RpEkjeInEyWpOItakoqzqCWpOItakoqzqCWpOItakoqzqCWpOItakoqzqCWpOItakoqzqCWpOItakoqzqCWpOItakoqzqCWpOItakoqzqCWpOItakoqzqCWpOItakoqzqCWpOItakoqzqCWpOItakoqzqCWpuLVdVoqIA8C3gBeBo5k522coSdJxnYq69abMfLa3JJKkkTz0IUnFdX1HncBnIyKBD2XmjuEVImIOmAOYnp5euYTSWWBm210Te+0D27dM7LUnZVLj3ddYd31HfXVmvg64HnhHRLxheIXM3JGZs5k5OzU1taIhJelc1qmoM/Pp9ush4JPAlX2GkiQdN7aoI+KlEfGyhfvAzwCP9R1MktTocoz6FcAnI2Jh/b/LzM/0mkqSdMzYos7M/cBrVyGLJGkEL8+TpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqrnNRR8SaiPiPiPh0n4EkSSdazjvqW4A9fQWRJI3WqagjYiOwBfjzfuNIkoZ1fUf9AeD3gO8utkJEzEXEfETMHz58eCWySZLoUNQR8XPAoczcudR6mbkjM2czc3ZqamrFAkrSua7LO+qrgZ+PiAPAx4BrIuJve00lSTpmbFFn5q2ZuTEzZ4CtwP2Z+Zbek0mSAK+jlqTy1i5n5cx8AHiglySSpJF8Ry1JxVnUklScRS1JxVnUklScRS1JxVnUklScRS1JxVnUklScRS1JxVnUklScRS1JxVnUklScRS1JxVnUklScRS1JxVnUklScRS1JxVnUklScRS1JxVnUklScRS1JxVnUklScRS1JxVnUklScRS1JxY0t6ohYFxEPR8TuiHg8It69GsEkSY21HdZ5HrgmM49ExHnAFyLi7sx8sOdskiQ6FHVmJnCkfXhee8s+Q0mSjut0jDoi1kTELuAQcG9mPjRinbmImI+I+cOHD69wTEk6d3Uq6sx8MTN/FNgIXBkRV4xYZ0dmzmbm7NTU1ArHlKRz17Ku+sjM54AHgOv6CCNJOlmXqz6mIuLl7f3vBa4Fnuw5lySp1eWqjw3AX0fEGppi/0RmfrrfWJKkBV2u+ngE2LwKWSRJI/jJREkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOIsakkqzqKWpOLGFnVEvDIiPh8ReyLi8Yi4ZTWCSZIaazuscxT43cz8ckS8DNgZEfdm5hM9Z5Mk0eEddWY+k5lfbu9/C9gDXNx3MElSo8s76mMiYgbYDDw0YtkcMAcwPT19yoFmtt11ytuejgPbt0zkdSVpnM4nEyPi+4B/AH47M/9veHlm7sjM2cycnZqaWsmMknRO61TUEXEeTUl/JDP/sd9IkqRBXa76COAvgD2Z+f7+I0mSBnV5R3018KvANRGxq73d0HMuSVJr7MnEzPwCEKuQRZI0gp9MlKTiLGpJKs6ilqTiLGpJKs6ilqTiLGpJKs6ilqTiLGpJKs6ilqTiLGpJKs6ilqTiLGpJKs6ilqTiLGpJKs6ilqTiLGpJKs6ilqTiLGpJKs6ilqTiLGpJKs6ilqTiLGpJKs6ilqTiLGpJKs6ilqTixhZ1RHw4Ig5FxGOrEUiSdKIu76j/Criu5xySpEWMLerM/Bfgm6uQRZI0wtqV2lFEzAFzANPT0yu121Uzs+2uSUdYdQe2b5l0hFV3Lv6cdeZbsZOJmbkjM2czc3ZqamqlditJ5zyv+pCk4ixqSSquy+V5HwX+Hbg8Ig5GxM39x5IkLRh7MjEzb1yNIJKk0Tz0IUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVJxFLUnFWdSSVFynoo6I6yJib0Tsi4htfYeSJB03tqgjYg3wp8D1wCbgxojY1HcwSVKjyzvqK4F9mbk/M18APgb8Qr+xJEkL1nZY52LgawOPDwI/PrxSRMwBc+3DIxGx9/Tjnbb1wLOTDrFMq5Y53rNiuzrTxvlMywunkXkFf87LdU6NM5z2WF+y2IIuRR0jnsuTnsjcAexYRqjeRcR8Zs5OOsdymLl/Z1peMPNqqZq5y6GPg8ArBx5vBJ7uJ44kaViXov4S8OqIuDQizge2Ap/qN5YkacHYQx+ZeTQi3gncA6wBPpyZj/eebGWUOhTTkZn7d6blBTOvlpKZI/Okw82SpEL8ZKIkFWdRS1J1mVnmBlwE3At8pf164SLrXQfsBfYB27psD9zarr8X+NmB5/+A5jrxI0Ov8UfArvb2n8BzA8teHFh2d6HMNwGHB7L9xsCyt7av8RXg7YUy/w7wBPAIcB9wyYhxfhQ4VCTvBcDH220eAmYKjfGPtWO1D/gTjh/arDyXF8t8E3Xn8mKZu8zlXcCnlt2Ny92gzxvw3oVBBLYB7xmxzhrgKeAy4HxgN7Bpqe1pPvq+m+aX7NJ2+zXtstcDGxj6hRx6zXfRnERdeHykYuZ2ct8x4vUvAva3Xy8EngPeXSTzm4CXtPffBnx8eJyLjfHbgQ+297cu5C0yxg8DV9F89uFu4PozYC6PzEztubxY5rFz+ZS78XQ2Xukbzb9cG9r7G4C9I9a5Crhn4PGtwK1LbT+4Tvv4HuCqof0uVdRfBH56kcldJvMSk/tG4EMDj58D3lYh89CyzcC/Da9bbIyPrUNz1dSzNL+wEx3jdp0nF/uZV5zLS2Wm6FxexjiPnMuneqt2jPoVmfkMQPv1B0esM+oj7ReP2X6pbZYUEZfQ/It6/8DT6yJiPiIeBDYWy/zLEfFIRNwZEQsfVBre1wXASwtlXnAzzTuUBesiYh54Fe1/W1Ag77FtMvMo8L/AD4zY12qP8cXt/UW/l4JzeVzminN57Di3Rs7liHgwIn5xxPpL6vIR8hUVEZ8DfmjEotu67mLEc9nDNgu2AkeB3RHHdrMPWEdzfOqDEfGqzHxqhV//VLb5J+Cjmfl8ROwB9kTEAZr/vyAiYivHx7mP1z/lcY6Ix2j+NP1qmxOacf594G+AD0TEo0uM82rlPbZNO5c3Av9K82f4JMe4y76qzeWl9lV1Lo/dV0S8BZgF3jjw9HRmPh0RlwH3j5nLJ1n1os7MaxdbFhHfiIgNmflMRGygOYE0bKmPtC+2/el8DH4r8CuZ+cVFMr+P5tjUU5POnJn/PfDwCuCbmXlFRNwI/GRm/mab+XngO+39iY9zRFxLcxxxJjNPyhIRz9CchNkcEd+ZcN6FbQ7SnKD6Os3xzK1MdowPtveX+l6qzeVFMxeey0uOczuXbwPemJnPLzyfmQvf1/6IeIDm0Ejnoj7lYyZ93ID3ceKB/feOWGctzcmESzl+YuA1S20PvIYTTwzspz0xsNQxJOBy4ADtWd32uQuBC9r764H/Ad5fITPtsbb2/i8BD7b3LwK+2mYfdQJmkpkXJuyrh54fHOc7aI4FbyqQ9x2ceDLxE1XGmOa/e3g9x09y3VB9Li+WmcJzeYnMXebyeporTDYtqxuXs3LfN5pjffe138h9wEXt8z8M/PPAejfQXGb0FHDbuO3bZbe16+9l4Gw4zVnfg8B326+3Dyy7Hdg+lPEnaC7N2d1+/a0qmYE/BB5vs30e+JGBbX6d5s/cfcA7C2X+HPANhi5dGhrnJ9pbhbzrgL9vx/Fh4LJCYzwLPNYuu4MTS/l2as7lkZmpPZcXy9xlLj8K3LzcbvQj5JJUXLWrPiRJQyxqSSrOopak4ixqSSrOopak4ixqSSrOopak4v4fXeWdi+axBHcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.mean(gradtestnp[np.sum(gradtestnp,1)!=0],axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
